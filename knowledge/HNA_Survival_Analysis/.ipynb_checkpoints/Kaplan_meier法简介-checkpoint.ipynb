{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生存分析Kaplan_meier法简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "百度文库https://wenku.baidu.com/view/edd0b0303968011ca30091e1.html\n",
    "\n",
    "维基百科https://en.wikipedia.org/wiki/Kaplan–Meier_estimator\n",
    "\n",
    "话说统计\n",
    "http://www.360doc.com/content/17/0626/11/6175644_666623573.shtml\n",
    "\n",
    "http://www.360doc.com/content/15/0707/14/26456292_483332967.shtml\n",
    "\n",
    "从一篇新英格兰文章看懂K-M曲线与Cox的关系http://www.sohu.com/a/280105039_743978 \n",
    "\n",
    "生存分析博客https://www.cnblogs.com/wwxbi/p/6136348.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaplan–Meier estimator\n",
    "Kaplan-Meier估计量[1][2]也被称为乘积极限估计量，是一种非参数统计用来估计生存期数据的生存函数。在医学研究中，它常被用来衡量病人在治疗后存活一定时间的比例。在其他领域，Kaplan-Meier估计器可以用来测量人们失业后失业的时间长短，[3]表示机器部件失效的时间，也可以用来测量水果食性动物把肉质水果从植物上摘下来之前，它们在植物上停留了多长时间。这个估算器是以爱德华·l·卡普兰(Edward L. Kaplan)和保罗·迈耶(Paul Meier)的名字命名的，他们都向《美国统计协会杂志》(Journal of The American Statistical Association)提交了类似的手稿。《华尔街日报》编辑约翰·图基(John Tukey)说服他们将自己的研究成果合并成一篇论文，这篇论文自发表以来被引用了约5.5万次\n",
    "生存函数S(t)的估计量(寿命大于t的概率)由\n",
    "![image.png](https://wikimedia.org/api/rest_v1/media/math/render/svg/fab080c10b1f78063fe3f0f2144c587f32e16c6a)\n",
    "至少发生一件事的时间ti，时间ti发生的事件数di(如死亡)，已知的幸存个体ni(尚未发生事件或被审查)直到时间ti为止。\n",
    "\n",
    "Kaplan-Meier估计量的一个图是一系列下降的水平步长，随着足够大的样本量，这些步长接近该种群的真实生存函数。连续不同的采样观测值之间的生存函数值(“喀哒”)被认为是常数。\n",
    "\n",
    "Kaplan-Meier曲线的一个重要优点是，该方法可以考虑某些类型的截尾数据，尤其是右截尾数据，即当患者退出研究、失访或在最后一次随访中无事件发生时发生的数据。在图上，垂直的小标记表示患者的生存时间被正确地删除了。当不发生截尾或截尾时，Kaplan-Meier曲线是经验分布函数的补充。\n",
    "\n",
    "在医学统计学中，一个典型的应用可能涉及到将患者分为不同的类别，例如，基因a型和基因B型。在图中，携带B基因的患者比携带A基因的患者死亡的速度要快得多。两年后，携带A基因的患者中约有80%存活了下来，而携带B基因的患者则不到一半。\n",
    "\n",
    "为了生成Kaplan-Meier估计量，每个患者(或每个受试者)至少需要两条数据:最后一次观察的状态(事件发生或右截尾)和事件发生的时间(或截尾的时间)。如果要比较两个或多个组之间的生存函数，那么需要第三个数据:每个受试者的组分配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COX 比例风险回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://baike.baidu.com/item/COX回归模型/8894307?fr=aladdin\n",
    "\n",
    "# https://www.cnblogs.com/super-yb/p/11332385.html\n",
    "\n",
    "# https://blog.csdn.net/qq_37523061/article/details/84635614\n",
    "\n",
    "# 维基百科\n",
    "#https://en.wikipedia.org/wiki/Proportional_hazards_model\n",
    "\n",
    "# http://www.360doc.com/document/17/0625/15/42499180_666425117.shtml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COx回归模型简介\n",
    "Kaplan-Meier法与寿命表法研究的是单个分组变量的生存分析，而Cox比例风险回归模型（Cox proportional hazard regression medel）研究的由是多因素生存分析的主要方法。此方法是由英国统计学家Cox提出的而因此命名。\n",
    "\n",
    "Cox模型的基本形式\n",
    "h(t,X)=h0exp(β′X)=h0exp(β1X1+β2X2+⋯+βmXm)\n",
    "其中h(t,X)是具有协变量X的个体在时刻t时的风险函数，t为生存时间，X=(X1,X2,⋯,Xm)′是可能影响生存时间的有关因素，也称协变量，这些变量可以是定量的，也可以是定性的，在整个观察期间内不随时间的变化而变化。h0(t)是所有协变量取0时的风险函数，称为基线风险函数（）。β=(β1,β2,⋯,βm)′为Cox模型的回归系数，是一组估的回归参数。由于此公式右侧的h0(t)不需要服从特定的分布是形状，具有非参数的特点，而指数部分exp(β′X)具有参数模型的形式，因此模型又称为半参数模型（semi-parametric model）。\n",
    "\n",
    "如果采用生存率表示，则模型可写为：\n",
    "\n",
    "S(t,X=S0(t)exp(β′X)=S0(t)exp(β1X1+β2X2+⋯+βmXm)\n",
    "其中S(t,X)是具有协变量X的个体在时刻t时的生存率，S0(t)为在时刻t的基线生存率。\n",
    "\n",
    "RR或HR\n",
    "两个分别具有协变量Xi和Xj的个体，其风险函数之比值为相对危险度（risk ration，RR）或风险比（hazard ration，HR），是一个与时间无关的量，即\n",
    "\n",
    "h(t,Xi/h(t,Xj=exp[β(Xi−Xj))]\n",
    "例如Xi是暴露组观察对象对应各因素的取值，Xj是非暴露组观察对象对应各因素的取值，求得β的估计时后就能救出暴露组对非暴露组的相对危险度估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比例风险模型Cox's proportional hazard's model\n",
    "比例灾害模型是统计学中的一类生存模型。生存模型将事件发生前经过的时间与一个或多个与时间量相关的协变量联系起来。在比例危害模型中，单位增加的协变量的唯一影响是与危害率相乘。例如，服用一种药物可能会使一个人发生中风的危险率降低一半，或者，改变制造组件的材料可能会使失败的危险率增加一倍。其他类型的生存模型，如加速失效时间模型，不显示成比例的危险。加速失效时间模型描述了事件的生物或机械生命历史被加速(或减速)的情况。\n",
    "\n",
    "生存模型可被视为由两部分组成:基本的基线危险函数，通常表示为lambda 0(t)，描述在协变量的基线水平上，每个时间单位的事件风险如何随时间变化;以及影响参数，描述危害如何随解释协变量而变化。一个典型的医学例子包括协变量，如治疗分配，以及患者特征，如研究开始时的年龄，性别，和其他疾病的存在，以减少变异性和/或控制混杂。\n",
    "\n",
    "比例危险条件表明，协变量与危险的关系是相乘的。在最简单的平稳系数的情况下，例如，在任何给定的时间t，药物治疗可能使受试者的危险减半，而基线危险可能变化。但是请注意，这不会使主题的生存期延长一倍;协变量对生存期的精确影响取决于lambda 0(t)的类型。\n",
    "协变量不限于二元预测因子;在一个连续的协变量x的情况下，通常假定危险指数反应;x每增加一个单位，危险就会按比例扩大。\n",
    "Cox部分似然，如下图所示，是通过使用Breslow对基线风险函数的估计，将其插入完全似然，然后观察结果是两个因素的乘积而得到的。第一个因素是如下所示的部分似然，其中基线危害已经“消除”。第二个因素没有回归系数，仅通过截尾模式依赖于数据。因此，任何比例危害模型估计的协变量的影响都可以报告为危害比。\n",
    "大卫·考克斯爵士观察到，如果比例危害假设成立(或者，假设成立)，那么就有可能在不考虑危害函数的情况下估算影响参数。这种处理生存数据的方法被称为Cox比例风险模型的应用，有时缩写为Cox模型或比例风险模型。然而，考克斯也指出，对比例危害假设的生物学解释可能相当棘手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-value理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://zhuanlan.zhihu.com/p/42821554\n",
    "# https://en.wikipedia.org/wiki/P-value\n",
    "# https://www.sohu.com/a/270616304_743978?spm=smpc.author.fd-d--1.13.1575358979511Qwlqlxg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 什么是p value？\n",
    "p value，代表在原假设条件下，实验事件可能发生的概率。\n",
    "\n",
    "举例说明：抛一枚硬币，正面朝上和反面朝上的概率是一样的，各50%，但这是有前提条件的，即硬币是均匀的（原假设），才能保证正反面出现的概率相同。现在将该硬币抛掷5次，那么在原假设成立的前提下，5次都是正面朝上的概率是0.55= 0.03125. 换个说法，抛一枚硬币得到5次都是正面朝上的结果，该硬币是均匀的概率就是p value, 仅有0.03125.\n",
    "\n",
    "因在假设检验时会设置?值（犯第一类错误的概率），若设定?=0.05，即当原假设是正确的却仍被拒绝的概率为0.05, 换名话说，有1-?=95%的把握是做出了正确的决定。\n",
    "\n",
    "现p value=0.03125 < ?，就是说这个事件发生的概率太低，小于愿承受犯第一类错误的概率，所以选择拒绝原假设，认为备择假设是对的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 白话 p值\n",
    "# https://cosx.org/2008/12/p-value-notes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上次的硬币试验，那是一次二项试验，每次试验投 100 次，记下出现正面的次数, 比如，如果\n",
    "- 每次出现的正面数都是 50，你就有把握认为这是一枚均匀的硬币；\n",
    "- 正面数等于 45 或者等于 55，你就有一点点的怀疑它是均匀的；\n",
    "- 正面数等于 30 或者等于 70，比较怀疑；\n",
    "- 正面数等于 10 或者等于 90，非常怀疑。\n",
    "\n",
    "如上，正面数和反面数的差异越大，你就越有把握认为硬币不是均匀的（拒绝原假设）。重复一下 P 值的定义，“P 值就是当原假设为真时，比所得到的样本观察结果更极端的结果出现的概率”，把这个定义套入上述硬币试验的场景中，比如你观察到 “正面数是 10 或者 90，正反面次数差异是 80”：\n",
    "- 如果原假设为真（硬币是均匀的），P 值就是你投 100 次，所得的正反面数差异大于 80 的概率。\n",
    "- 如果这个 P 值很大，表明，每次投 100 次均匀的硬币，经常有正反面差异大于 80 的情形出现。如果这个 P 值很小，表明，每次投 100 次均匀的硬币，你很难看到正反面的差异会超过 80。\n",
    "\n",
    "以前说过，10-90 是 A 博士的接受区域。如果一枚硬币投出的正反面次数，差异大于 80，——这真是一个 “极端” 的情形，连保守的 A 博士看了都摇摇头，不能接受原假设，只好认为原假设不对，硬币是有偏的。这里的逻辑是：\n",
    "- 在假定原假设为真的情况下，出现所看到的偏差（正反面差异为 80），是这么地不可能（P 值很小），以至于我们不再继续相信原假设。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让 P-value 更加的浅显易懂\n",
    "# https://blog.csdn.net/rongbaohan/article/details/53521147"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.普通逻辑\n",
    "复习一下普通逻辑的基本思路。假设以下陈述为真：\n",
    "\n",
    "你打了某种疫苗P，就不会得某种流行病Q。\n",
    "\n",
    "我们把这个先决条件表述如下：\n",
    "\n",
    "如果P 则非Q\n",
    "\n",
    "其中，\n",
    "\n",
    "P表示打了疫苗P，\n",
    "\n",
    "Q表示得流行病Q\n",
    "\n",
    "或者，更形式化一点：\n",
    "\n",
    "if P then NOT Q\n",
    "\n",
    "然后，如果观察到你得了流行病Q，那么就可以推出你没有打疫苗P——这个推断只不过是上述前提条件的逆反命题而已。我们把以上推理过程表述如下：\n",
    "\n",
    "if P then NOT Q (先决条件)\n",
    "\n",
    "Q (前提)\n",
    "\n",
    "———————–\n",
    "\n",
    "then NOT P （结论）\n",
    "\n",
    "还有，如果你没有得流行病Q，就能推断出你打了疫苗P吗？显然不能。打疫苗P是不得流行病Q的充分条件，但非必要条件：你没有得流行病Q，可能是因为打了疫苗P，也可以是因为其他任何原因。即，if P then NOT Q，不能够推出if NOT Q then P。\n",
    "\n",
    "到此为止没有任何令人惊奇的地方。下面将表明，假设检验背后的统计推断规则也只不过是我们以上日常逻辑推理的一个衍生而已。这只需要思维的一次小小的“跳跃”。\n",
    "\n",
    "1.假设检验\n",
    "在统计推断中，我们不说“你打了疫苗P，就不会得流行病Q”，而是说，比如，“你打了疫苗P，就有95%的把握不会得流行病Q”，即if P then probably NOT Q。把上面的逻辑推理规则改写成统计推断规则：\n",
    "\n",
    "if P then probably NOT Q    (先决条件)\n",
    "\n",
    "Q                                                     (前提)\n",
    "\n",
    "———————–\n",
    "\n",
    "then probably NOT P         （结论）\n",
    "\n",
    "回到以前“万能”的硬币实验，我们做实验来考察一枚硬币是不是均匀的。改写成现在我们熟悉的形式：\n",
    "\n",
    "P：硬币是均匀的。\n",
    "\n",
    "Q：在100次投掷中，得到90次正面，10次反面。\n",
    "\n",
    "我们说，如果是一个均匀的硬币，就不太可能发生这样的情形：投100次，出现90次正面，10次反面（if P then probably NOT Q）。现在如果在100次投掷实验中，观察到出现90次正面，10次反面（Q），那就可以有把握地说，这个硬币不是均匀的（NOTP）。这个推理可以写成与上面一致的统计推断的形式，其中，P是原假设H0，NOT P是备择假设Ha：\n",
    "\n",
    "H0：硬币是均匀的  （P）\n",
    "\n",
    "Ha：硬币是有偏的 （NOT P）\n",
    "\n",
    "如果原假设为真，即硬币是均匀的，就不太可能发生这样极端的事情，比如：在100次投掷实验中，观察到出现90次正面，10次反面（Q）。如果真的观察到这样极端的事情，你就有把握认为硬币不是均匀的，即拒绝原假设（P），接受备择假设（NOT P）。\n",
    "\n",
    "另外，如果在100次投掷实验中，观察到60个正面，40个反面（NOT Q）。这时你就不好下结论了，因为一个均匀的硬币可能投出这样的结果，一个有偏的硬币也可能投出这样的结果。最后，你只能说，如果实验结果是这样的，那就没有把握拒绝原假设。这枚硬币是否有偏，需要更多的证据来证明（这通常意味着更多的实验，比如，再投1000次）。\n",
    "\n",
    "总结一下。在搜集数据之前，我们把想证明的结论写成备择假设，把想拒绝的结论写成原假设。之所以写成这个形式，因为从上面不厌其烦的讨论中得知，这是方便逻辑/统计推断的形式：当我们难以拒绝原假设时，只能得到结论，原假设也许是真的，现在还不能拒绝它；而当我们能够拒绝原假设时，结论是：它就很有把握是不真的。注意，在看到数据之前，我们不知道自己想证明的结论是否能够被证据所支持。\n",
    "\n",
    "在确定假设检验的形式的同时，我们对之前一直随意说的“把握”、“可能”也做一个限定，即指定一个显著性水平α(significance level)，也叫犯第一类错误的概率(type I error，在上面的硬币实验中，就是否定一个均匀硬币的错误，也叫“弃真”错误)。\n",
    "\n",
    "根据某些保守或稳健的原则（比如，我们认为，把一个无辜的人判决为有罪，比放掉一个有罪的人，后果更为严重），我们要尽量把犯“弃真”错误的概率控制在一个很小的水平里。通常α=0.05，这时候就是说，如果拒绝了原假设，你就有95%的把握说原假设是不真的。这里，95%(=1-α)就是置信水平(confidence level)。\n",
    "\n",
    "又，放掉一个有罪的人，即把一个有罪的人判为无罪，这犯的是第二类错误β(type II error，在硬币实验中，就是把一个有偏的硬币当成均匀硬币的错误，也叫“取伪”错误)。关于第一类和第二类错误之间的权衡取舍(trade off)，详见《决策与风险》。在我们的假设检验里，我们认为犯一类错误的后果比犯第二类错误的后果更为严重。\n",
    "\n",
    "需要注意的是，在这里，我强调的是先提出需要检验的假设，然后再搜集收据。这是统计推断的原则之一。如果看到了数据之后再提出假设，你几乎可以得到所有你想要的结果，这是不好的机会主义的倾向。强调这些，是因为在学校里，我们大多是看了别人搜集好的数据之后再做统计练习。\n",
    "\n",
    "事先确定好你想拒绝/证明的假设，在看到数据之前，你不知道结果如何。\n",
    "\n",
    "2.P值（P Value）\n",
    "上面提到“极端”事件，比如，在100次硬币投掷实验中，观察到出现90次正面，10次反面（Q）。怎么样的事件才是“极端的”？简单地说，一个事件很极端，那么少比它本身“更极端”的事件就非常少（比如，只有“91次正面，9次反面”、“91次反面，9次正面”等情况才比它更极端）。\n",
    "\n",
    "但这个Q只是从一次实验中得出的。我们可以重复做这个实验，比如100次，每次都投掷100次，记录下的正面数X，它构成一个二项分布，X~B(n,p)，其中，n=100，p=0.5。根据某个中心极限定理，正态分布是二项分布的极限分布，上面的二项分布可以由均值为np=50，方差为np(1-p)=25的正态分布来近似。我们在这个近似的正态分布的两端来考察所谓“更极端”的事件，那就是正面数大于90或者小于10。\n",
    "\n",
    "重复一遍，“P值就是当原假设为真时，比所得到的样本观察结果更极端的结果出现的概率”。如果P值很小，就表明，在原假设为真的情况下出现的那个分布里面，只有很小的部分，比出现的这个事件（比如，Q）更为极端。没多少事件比Q更极端，那就很有把握说原假设不对了。\n",
    "\n",
    "在上述近似的正态分布中，P值就等于X>90 或 X<10的概率值（记做，P{X>90 or X<10}）。根据对称性，这个概率值等于2*P{X<10}=1.2442E-15。\n",
    "\n",
    "上面我们的确求出了一个非常小的P值，但如何不含糊地确定它就是很“极端”呢？ 事先确定的显著性水平α，本身就是一个判定法则。只要P值小于显著性水平α，我们就认为，在认为原假设为真的情况下出现的事件Q，是如此地极端，以至于我们不再相信原假设本身。一句话，我们的判定法则是：\n",
    "\n",
    "P值小于显著性水平α，拒绝原假设。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生存分析目的\n",
    "http://www.sohu.com/a/280105039_743978\n",
    "\n",
    "https://www.cnblogs.com/wwxbi/p/6136348.html\n",
    "\n",
    "https://www.cnblogs.com/super-yb/p/11332385.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
