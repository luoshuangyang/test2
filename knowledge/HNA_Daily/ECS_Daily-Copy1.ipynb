{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.font_manager import FontProperties \n",
    "\n",
    "font = FontProperties(fname=r\"/root/anaconda2/e nvs/python3/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/msyh.ttf\")\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "\n",
    "#print 1\n",
    "\n",
    "#import sys \n",
    "#reload(sys) \n",
    "#sys.setdefaultencoding('GB2312') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"737_Apr-Jun.csv\", encoding = \"GB18030\")\n",
    "#data1.loc[data1[u\"Fail\"]<>data1[u\"Fail\"],\"failure\"] = 0\n",
    "#data1.loc[data1[u\"Fail\"]==data1[u\"Fail\"],\"failure\"] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data1.boxplot()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1[data1[u\"环境温度(℃)\"]<100]\n",
    "data1 = data1[data1[u\"左边CONT CABIN DUCT\"]<100]\n",
    "data1 = data1[data1[u\"右边L PACK\"]<100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[u\"执行反吹左侧\"].fillna(0,inplace=True)\n",
    "data1[u\"执行反吹右侧\"].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    16062\n",
       "1.0      263\n",
       "Name: 执行反吹左侧, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[u\"执行反吹左侧\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    16170\n",
       "1.0      155\n",
       "Name: 执行反吹右侧, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[u\"执行反吹右侧\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>环境温度(℃)</th>\n",
       "      <th>左边CONT CABIN DUCT</th>\n",
       "      <th>左边L PACK</th>\n",
       "      <th>右边FWD DUCT</th>\n",
       "      <th>右边AFT DUCT</th>\n",
       "      <th>右边L PACK</th>\n",
       "      <th>执行反吹左侧</th>\n",
       "      <th>执行反吹右侧</th>\n",
       "      <th>左温差</th>\n",
       "      <th>右温差</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16325.000000</td>\n",
       "      <td>16325.000000</td>\n",
       "      <td>16325.000000</td>\n",
       "      <td>16325.000000</td>\n",
       "      <td>16325.000000</td>\n",
       "      <td>16325.000000</td>\n",
       "      <td>16325.000000</td>\n",
       "      <td>16325.000000</td>\n",
       "      <td>16325.000000</td>\n",
       "      <td>16325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.921225</td>\n",
       "      <td>4.529556</td>\n",
       "      <td>27.480551</td>\n",
       "      <td>4.643185</td>\n",
       "      <td>4.523247</td>\n",
       "      <td>26.791853</td>\n",
       "      <td>0.016110</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>5.559326</td>\n",
       "      <td>4.870628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.614574</td>\n",
       "      <td>2.023826</td>\n",
       "      <td>5.385148</td>\n",
       "      <td>1.865329</td>\n",
       "      <td>1.735627</td>\n",
       "      <td>5.172536</td>\n",
       "      <td>0.125903</td>\n",
       "      <td>0.096980</td>\n",
       "      <td>4.750771</td>\n",
       "      <td>4.460359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            环境温度(℃)  左边CONT CABIN DUCT      左边L PACK    右边FWD DUCT  \\\n",
       "count  16325.000000       16325.000000  16325.000000  16325.000000   \n",
       "mean      21.921225           4.529556     27.480551      4.643185   \n",
       "std        5.614574           2.023826      5.385148      1.865329   \n",
       "min        0.000000           0.000000      0.000000      0.000000   \n",
       "25%       18.000000           4.000000     24.000000      4.000000   \n",
       "50%       22.000000           4.000000     28.000000      4.000000   \n",
       "75%       26.000000           6.000000     31.000000      6.000000   \n",
       "max       42.000000          37.000000     84.000000     37.000000   \n",
       "\n",
       "         右边AFT DUCT      右边L PACK        执行反吹左侧        执行反吹右侧           左温差  \\\n",
       "count  16325.000000  16325.000000  16325.000000  16325.000000  16325.000000   \n",
       "mean       4.523247     26.791853      0.016110      0.009495      5.559326   \n",
       "std        1.735627      5.172536      0.125903      0.096980      4.750771   \n",
       "min        0.000000      0.000000      0.000000      0.000000    -31.000000   \n",
       "25%        4.000000     23.000000      0.000000      0.000000      3.000000   \n",
       "50%        4.000000     26.000000      0.000000      0.000000      6.000000   \n",
       "75%        6.000000     30.000000      0.000000      0.000000      8.000000   \n",
       "max       32.000000     56.000000      1.000000      1.000000     59.000000   \n",
       "\n",
       "                右温差  \n",
       "count  16325.000000  \n",
       "mean       4.870628  \n",
       "std        4.460359  \n",
       "min      -40.000000  \n",
       "25%        3.000000  \n",
       "50%        5.000000  \n",
       "75%        7.000000  \n",
       "max       32.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3f92f54910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col = [u\"环境温度(℃)\", u\"左温差\",u\"右温差\",u\"左边CONT CABIN DUCT\",u\"左边L PACK\",u\"右边FWD DUCT\",u\"右边AFT DUCT\",u\"右边L PACK\"]\n",
    "col = [u\"左温差\",u\"右温差\",u\"左边CONT CABIN DUCT\",u\"左边L PACK\",u\"右边FWD DUCT\",u\"右边AFT DUCT\",u\"右边L PACK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data1[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16325, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#import imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 执行反吹左侧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors\n",
      "0\n",
      "0.5912949995213796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.43      0.12      0.19        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.56      0.59      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3208    8]\n",
      " [  43    6]]\n",
      "1\n",
      "0.5752673524437867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3212\n",
      "         1.0       0.50      0.09      0.16        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.55      0.58      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3207    5]\n",
      " [  48    5]]\n",
      "2\n",
      "0.5786879322803758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3204\n",
      "         1.0       0.55      0.10      0.17        61\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.76      0.55      0.58      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3199    5]\n",
      " [  55    6]]\n",
      "3\n",
      "0.55234409553295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3206\n",
      "         1.0       0.36      0.07      0.11        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.53      0.55      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3199    7]\n",
      " [  55    4]]\n",
      "4\n",
      "0.5809596400105819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3218\n",
      "         1.0       0.42      0.11      0.17        47\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.55      0.58      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3211    7]\n",
      " [  42    5]]\n",
      "5\n",
      "0.5912949995213796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3215\n",
      "         1.0       0.46      0.12      0.19        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.72      0.56      0.59      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3208    7]\n",
      " [  44    6]]\n",
      "6\n",
      "0.606775403461684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3203\n",
      "         1.0       0.80      0.13      0.22        62\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.89      0.56      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3201    2]\n",
      " [  54    8]]\n",
      "7\n",
      "0.6155848179705654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3206\n",
      "         1.0       0.56      0.15      0.24        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.77      0.58      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3199    7]\n",
      " [  50    9]]\n",
      "8\n",
      "0.5726694032958534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3211\n",
      "         1.0       0.45      0.09      0.15        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.72      0.55      0.57      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3205    6]\n",
      " [  49    5]]\n",
      "9\n",
      "0.6264880251408114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3211\n",
      "         1.0       0.60      0.17      0.26        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.79      0.58      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3205    6]\n",
      " [  45    9]]\n",
      "10\n",
      "0.6190287274509346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3210\n",
      "         1.0       0.50      0.16      0.25        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.58      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3201    9]\n",
      " [  46    9]]\n",
      "11\n",
      "0.5969135802469135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3230\n",
      "         1.0       0.33      0.14      0.20        35\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.66      0.57      0.60      3265\n",
      "weighted avg       0.98      0.99      0.99      3265\n",
      "\n",
      "[[3220   10]\n",
      " [  30    5]]\n",
      "12\n",
      "0.6493743926619153\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.64      0.20      0.31        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.82      0.60      0.65      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3215    5]\n",
      " [  36    9]]\n",
      "13\n",
      "0.6084184313186753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.62      0.14      0.23        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.80      0.57      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3202    5]\n",
      " [  50    8]]\n",
      "14\n",
      "0.5603417320007182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3219\n",
      "         1.0       0.25      0.09      0.13        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.62      0.54      0.56      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3207   12]\n",
      " [  42    4]]\n",
      "15\n",
      "0.6131117980422464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.58      0.15      0.23        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.79      0.57      0.61      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3212    5]\n",
      " [  41    7]]\n",
      "16\n",
      "0.5541418291495476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3223\n",
      "         1.0       0.30      0.07      0.12        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.64      0.53      0.55      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3216    7]\n",
      " [  39    3]]\n",
      "17\n",
      "0.5432120582886009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3213\n",
      "         1.0       0.27      0.06      0.10        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.63      0.53      0.54      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3205    8]\n",
      " [  49    3]]\n",
      "18\n",
      "0.6057704457704458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3218\n",
      "         1.0       0.75      0.13      0.22        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.87      0.56      0.61      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3216    2]\n",
      " [  41    6]]\n",
      "19\n",
      "0.641135553566662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3214\n",
      "         1.0       0.56      0.20      0.29        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.77      0.60      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3206    8]\n",
      " [  41   10]]\n",
      "20\n",
      "0.6118404967149609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.73      0.14      0.23        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.86      0.57      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3204    3]\n",
      " [  50    8]]\n",
      "21\n",
      "0.496141975308642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.00      0.00      0.00        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3215    5]\n",
      " [  45    0]]\n",
      "22\n",
      "0.6101061477222468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3209\n",
      "         1.0       0.57      0.14      0.23        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.78      0.57      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3203    6]\n",
      " [  48    8]]\n",
      "23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5987629034900869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3211\n",
      "         1.0       0.50      0.13      0.21        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.56      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3204    7]\n",
      " [  47    7]]\n",
      "24\n",
      "0.634686287882017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.80      0.17      0.28        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.89      0.58      0.63      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3215    2]\n",
      " [  40    8]]\n",
      "25\n",
      "0.5702171488218816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3209\n",
      "         1.0       0.45      0.09      0.15        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.72      0.54      0.57      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3203    6]\n",
      " [  51    5]]\n",
      "26\n",
      "0.6348225866267423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3206\n",
      "         1.0       0.55      0.19      0.28        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.77      0.59      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3197    9]\n",
      " [  48   11]]\n",
      "27\n",
      "0.5929090111117761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3215\n",
      "         1.0       0.50      0.12      0.19        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.56      0.59      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3209    6]\n",
      " [  44    6]]\n",
      "28\n",
      "0.6659051698494853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3213\n",
      "         1.0       0.85      0.21      0.34        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.92      0.61      0.67      3265\n",
      "weighted avg       0.99      0.99      0.98      3265\n",
      "\n",
      "[[3211    2]\n",
      " [  41   11]]\n",
      "29\n",
      "0.5678979114374092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3211\n",
      "         1.0       0.33      0.09      0.14        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.54      0.57      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3201   10]\n",
      " [  49    5]]\n",
      "30\n",
      "0.6305375489872316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3215\n",
      "         1.0       0.53      0.18      0.27        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.76      0.59      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3207    8]\n",
      " [  41    9]]\n",
      "31\n",
      "0.5355885833265239\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3223\n",
      "         1.0       0.22      0.05      0.08        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.60      0.52      0.54      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3216    7]\n",
      " [  40    2]]\n",
      "32\n",
      "0.5867321107110711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3209\n",
      "         1.0       0.60      0.11      0.18        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.79      0.55      0.59      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3205    4]\n",
      " [  50    6]]\n",
      "33\n",
      "0.5786879322803757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.43      0.10      0.17        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.55      0.58      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3199    8]\n",
      " [  52    6]]\n",
      "34\n",
      "0.5897289669038044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3213\n",
      "         1.0       0.50      0.12      0.19        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.56      0.59      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3207    6]\n",
      " [  46    6]]\n",
      "35\n",
      "0.5497612233511046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3201\n",
      "         1.0       0.44      0.06      0.11        64\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.53      0.55      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3196    5]\n",
      " [  60    4]]\n",
      "36\n",
      "0.6118404967149609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3213\n",
      "         1.0       0.47      0.15      0.23        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.73      0.58      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3204    9]\n",
      " [  44    8]]\n",
      "37\n",
      "0.5971929682891104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3212\n",
      "         1.0       0.44      0.13      0.20        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.56      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3203    9]\n",
      " [  46    7]]\n",
      "38\n",
      "0.6155959342255013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3202\n",
      "         1.0       0.50      0.16      0.24        63\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.58      0.62      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3192   10]\n",
      " [  53   10]]\n",
      "39\n",
      "0.5739493117847201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3210\n",
      "         1.0       0.56      0.09      0.16        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.77      0.54      0.57      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3206    4]\n",
      " [  50    5]]\n",
      "40\n",
      "0.5998945057755424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3215\n",
      "         1.0       0.75      0.12      0.21        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.87      0.56      0.60      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3213    2]\n",
      " [  44    6]]\n",
      "41\n",
      "0.6476358292012425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3208\n",
      "         1.0       0.55      0.21      0.30        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.77      0.60      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3198   10]\n",
      " [  45   12]]\n",
      "42\n",
      "0.5809596400105818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.45      0.10      0.17        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.72      0.55      0.58      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3211    6]\n",
      " [  43    5]]\n",
      "43\n",
      "0.6290730699715982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3206\n",
      "         1.0       0.62      0.17      0.27        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.80      0.58      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3200    6]\n",
      " [  49   10]]\n",
      "44\n",
      "0.6055086220228889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3212\n",
      "         1.0       0.64      0.13      0.22        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.81      0.57      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3208    4]\n",
      " [  46    7]]\n",
      "45\n",
      "0.5980633281734151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3218\n",
      "         1.0       0.50      0.13      0.20        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.74      0.56      0.60      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3212    6]\n",
      " [  41    6]]\n",
      "46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6020965659695326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3209\n",
      "         1.0       0.42      0.14      0.21        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.57      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3198   11]\n",
      " [  48    8]]\n",
      "47\n",
      "0.5579431311797405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3200\n",
      "         1.0       0.36      0.08      0.13        65\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.54      0.56      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3191    9]\n",
      " [  60    5]]\n",
      "48\n",
      "0.5840888332371172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3218\n",
      "         1.0       0.50      0.11      0.18        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.74      0.55      0.58      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3213    5]\n",
      " [  42    5]]\n",
      "49\n",
      "0.5651027236690678\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.44      0.08      0.14        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.72      0.54      0.57      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3211    5]\n",
      " [  45    4]]\n",
      "LogisticRegression\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4958307597282273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.00      0.00      0.00        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3211    9]\n",
      " [  45    0]]\n",
      "1\n",
      "0.5316982214572575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.18      0.04      0.07        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.58      0.52      0.53      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3211    9]\n",
      " [  43    2]]\n",
      "2\n",
      "0.49466026930815665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3203\n",
      "         1.0       0.00      0.00      0.00        62\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.49      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n",
      "[[3196    7]\n",
      " [  62    0]]\n",
      "3\n",
      "0.5324254124254124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3222\n",
      "         1.0       0.17      0.05      0.07        43\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.58      0.52      0.53      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3212   10]\n",
      " [  41    2]]\n",
      "4\n",
      "0.5111567641334149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.17      0.02      0.03        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.57      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3203    5]\n",
      " [  56    1]]\n",
      "5\n",
      "0.513295443149818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3212\n",
      "         1.0       0.25      0.02      0.04        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.62      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3209    3]\n",
      " [  52    1]]\n",
      "6\n",
      "0.5145036945531077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3221\n",
      "         1.0       0.10      0.02      0.04        44\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.54      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3212    9]\n",
      " [  43    1]]\n",
      "7\n",
      "0.5347566912864844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3222\n",
      "         1.0       0.22      0.05      0.08        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.60      0.52      0.53      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3215    7]\n",
      " [  41    2]]\n",
      "8\n",
      "0.49536321483771256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3210\n",
      "         1.0       0.00      0.00      0.00        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3205    5]\n",
      " [  55    0]]\n",
      "9\n",
      "0.5118332323895298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3212\n",
      "         1.0       0.12      0.02      0.03        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.55      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3205    7]\n",
      " [  52    1]]\n",
      "10\n",
      "0.495285206368836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3212\n",
      "         1.0       0.00      0.00      0.00        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3204    8]\n",
      " [  53    0]]\n",
      "11\n",
      "0.5339532336482358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3219\n",
      "         1.0       0.29      0.04      0.08        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.52      0.53      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3214    5]\n",
      " [  44    2]]\n",
      "12\n",
      "0.5592397053661937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3213\n",
      "         1.0       0.36      0.08      0.13        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.54      0.56      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3206    7]\n",
      " [  48    4]]\n",
      "13\n",
      "0.5266103464274667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3213\n",
      "         1.0       0.17      0.04      0.06        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.58      0.52      0.53      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3203   10]\n",
      " [  50    2]]\n",
      "14\n",
      "0.5145036945531077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.20      0.02      0.04        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.59      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3212    4]\n",
      " [  48    1]]\n",
      "15\n",
      "0.5095991042656617\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.10      0.02      0.03        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.54      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3198    9]\n",
      " [  57    1]]\n",
      "16\n",
      "0.5239553261598576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3205\n",
      "         1.0       0.22      0.03      0.06        60\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.60      0.52      0.52      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3198    7]\n",
      " [  58    2]]\n",
      "17\n",
      "0.5415908144446427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3209\n",
      "         1.0       0.33      0.05      0.09        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.53      0.54      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3203    6]\n",
      " [  53    3]]\n",
      "18\n",
      "0.49567500772320044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3215\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3209    6]\n",
      " [  50    0]]\n",
      "19\n",
      "0.5108306913083823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.14      0.02      0.03        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.56      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3202    6]\n",
      " [  56    1]]\n",
      "20\n",
      "0.5093077977340071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3205\n",
      "         1.0       0.11      0.02      0.03        60\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.55      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3197    8]\n",
      " [  59    1]]\n",
      "21\n",
      "0.5339532336482358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3219\n",
      "         1.0       0.29      0.04      0.08        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.52      0.53      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3214    5]\n",
      " [  44    2]]\n",
      "22\n",
      "0.5466017014134169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3206\n",
      "         1.0       0.22      0.07      0.10        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.60      0.53      0.55      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3192   14]\n",
      " [  55    4]]\n",
      "23\n",
      "0.512915050509356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3213\n",
      "         1.0       0.17      0.02      0.03        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.58      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3208    5]\n",
      " [  51    1]]\n",
      "24\n",
      "0.49614197530864196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3221\n",
      "         1.0       0.00      0.00      0.00        44\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3215    6]\n",
      " [  44    0]]\n",
      "25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5331766293779883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.22      0.04      0.07        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.60      0.52      0.53      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3213    7]\n",
      " [  43    2]]\n",
      "26\n",
      "0.5102010201020103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3206\n",
      "         1.0       0.14      0.02      0.03        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.56      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3200    6]\n",
      " [  58    1]]\n",
      "27\n",
      "0.5149309166542861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3221\n",
      "         1.0       0.11      0.02      0.04        44\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.55      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3213    8]\n",
      " [  43    1]]\n",
      "28\n",
      "0.5121844410097889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3214\n",
      "         1.0       0.11      0.02      0.03        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.55      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3206    8]\n",
      " [  50    1]]\n",
      "29\n",
      "0.5125448873592481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3210\n",
      "         1.0       0.25      0.02      0.03        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.62      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3207    3]\n",
      " [  54    1]]\n",
      "30\n",
      "0.5191085271317829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3191\n",
      "         1.0       0.33      0.03      0.05        74\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.51      0.52      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n",
      "[[3187    4]\n",
      " [  72    2]]\n",
      "31\n",
      "0.5386028545857082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3205\n",
      "         1.0       0.33      0.05      0.09        60\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.52      0.54      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3199    6]\n",
      " [  57    3]]\n",
      "32\n",
      "0.569097929097929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3221\n",
      "         1.0       0.36      0.09      0.15        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.68      0.54      0.57      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3214    7]\n",
      " [  40    4]]\n",
      "33\n",
      "0.5158263953829718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3225\n",
      "         1.0       0.09      0.03      0.04        40\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.54      0.51      0.52      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3215   10]\n",
      " [  39    1]]\n",
      "34\n",
      "0.4955970956279932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3210\n",
      "         1.0       0.00      0.00      0.00        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3208    2]\n",
      " [  55    0]]\n",
      "35\n",
      "0.5309937906716428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.22      0.04      0.07        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.60      0.52      0.53      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3210    7]\n",
      " [  46    2]]\n",
      "36\n",
      "0.5136866145902291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.12      0.02      0.04        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.56      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3210    7]\n",
      " [  47    1]]\n",
      "37\n",
      "0.5074250159020111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3197\n",
      "         1.0       0.12      0.01      0.03        68\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.55      0.51      0.51      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n",
      "[[3190    7]\n",
      " [  67    1]]\n",
      "38\n",
      "0.5108306913083823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3209\n",
      "         1.0       0.12      0.02      0.03        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.55      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3202    7]\n",
      " [  55    1]]\n",
      "39\n",
      "0.5324254124254124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3219\n",
      "         1.0       0.22      0.04      0.07        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.60      0.52      0.53      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3212    7]\n",
      " [  44    2]]\n",
      "40\n",
      "0.4950510361892979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3201    7]\n",
      " [  57    0]]\n",
      "41\n",
      "0.5541810038778743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.36      0.07      0.12        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.53      0.55      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3201    7]\n",
      " [  53    4]]\n",
      "42\n",
      "0.5735269670126107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3222\n",
      "         1.0       0.44      0.09      0.15        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.72      0.55      0.57      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3217    5]\n",
      " [  39    4]]\n",
      "43\n",
      "0.5093077977340071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.08      0.02      0.03        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.53      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3197   11]\n",
      " [  56    1]]\n",
      "44\n",
      "0.5432120582886008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3210\n",
      "         1.0       0.38      0.05      0.10        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.68      0.53      0.54      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3205    5]\n",
      " [  52    3]]\n",
      "45\n",
      "0.5114908133341313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.25      0.02      0.03        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.62      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3204    3]\n",
      " [  57    1]]\n",
      "46\n",
      "0.513295443149818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3219\n",
      "         1.0       0.09      0.02      0.04        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.54      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3209   10]\n",
      " [  45    1]]\n",
      "47\n",
      "0.5118332323895299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3211\n",
      "         1.0       0.14      0.02      0.03        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.56      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3205    6]\n",
      " [  53    1]]\n",
      "48\n",
      "0.5408134563456346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3210\n",
      "         1.0       0.27      0.05      0.09        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.63      0.53      0.54      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3202    8]\n",
      " [  52    3]]\n",
      "49\n",
      "0.49559709562799314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3216\n",
      "         1.0       0.00      0.00      0.00        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3208    8]\n",
      " [  49    0]]\n",
      "SGD\n",
      "0\n",
      "0.6838145202376391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3209\n",
      "         1.0       0.38      0.38      0.38        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.68      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3175   34]\n",
      " [  35   21]]\n",
      "1\n",
      "0.6299768158740027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3215\n",
      "         1.0       0.28      0.26      0.27        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.62      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3182   33]\n",
      " [  37   13]]\n",
      "2\n",
      "0.6476358292012425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3216\n",
      "         1.0       0.40      0.24      0.30        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.62      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3198   18]\n",
      " [  37   12]]\n",
      "3\n",
      "0.5826537856772145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3207\n",
      "         1.0       0.21      0.16      0.18        58\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.60      0.57      0.58      3265\n",
      "weighted avg       0.97      0.97      0.97      3265\n",
      "\n",
      "[[3173   34]\n",
      " [  49    9]]\n",
      "4\n",
      "0.6623228875788603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3219\n",
      "         1.0       0.37      0.30      0.33        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.68      0.65      0.66      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3195   24]\n",
      " [  32   14]]\n",
      "5\n",
      "0.7350765202627012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3207\n",
      "         1.0       0.44      0.53      0.48        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.76      0.74      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3167   40]\n",
      " [  27   31]]\n",
      "6\n",
      "0.6613773076125286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3210\n",
      "         1.0       0.36      0.31      0.33        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.65      0.66      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3180   30]\n",
      " [  38   17]]\n",
      "7\n",
      "0.6047933184046481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3209\n",
      "         1.0       0.35      0.16      0.22        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.58      0.60      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3192   17]\n",
      " [  47    9]]\n",
      "8\n",
      "0.6222214141200428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3217\n",
      "         1.0       0.26      0.25      0.26        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.62      0.62      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3183   34]\n",
      " [  36   12]]\n",
      "9\n",
      "0.6631060679563057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3210\n",
      "         1.0       0.37      0.31      0.34        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.68      0.65      0.66      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3181   29]\n",
      " [  38   17]]\n",
      "10\n",
      "0.6033926305501204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3210\n",
      "         1.0       0.32      0.16      0.22        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.58      0.60      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3191   19]\n",
      " [  46    9]]\n",
      "11\n",
      "0.6184559052664381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3196\n",
      "         1.0       0.33      0.20      0.25        69\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.65      0.60      0.62      3265\n",
      "weighted avg       0.97      0.97      0.97      3265\n",
      "\n",
      "[[3167   29]\n",
      " [  55   14]]\n",
      "12\n",
      "0.6832191385260784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3218\n",
      "         1.0       0.35      0.40      0.38        47\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.70      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3183   35]\n",
      " [  28   19]]\n",
      "13\n",
      "0.6594531418553513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3212\n",
      "         1.0       0.32      0.34      0.33        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.66      0.66      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3174   38]\n",
      " [  35   18]]\n",
      "14\n",
      "0.666663525316923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3215\n",
      "         1.0       0.35      0.34      0.34        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.67      0.67      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3183   32]\n",
      " [  33   17]]\n",
      "15\n",
      "0.6062266328974346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.39      0.16      0.22        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.58      0.61      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3193   14]\n",
      " [  49    9]]\n",
      "16\n",
      "0.6169427191166321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3211\n",
      "         1.0       0.31      0.20      0.24        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.60      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3186   25]\n",
      " [  43   11]]\n",
      "17\n",
      "0.6908375872038329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3206\n",
      "         1.0       0.37      0.42      0.39        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.68      0.71      0.69      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3163   43]\n",
      " [  34   25]]\n",
      "18\n",
      "0.6228799268167601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3217\n",
      "         1.0       0.25      0.27      0.26        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.62      0.63      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3177   40]\n",
      " [  35   13]]\n",
      "19\n",
      "0.6043768314307219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3209\n",
      "         1.0       0.29      0.18      0.22        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.59      0.60      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3184   25]\n",
      " [  46   10]]\n",
      "20\n",
      "0.6358940045769466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3210\n",
      "         1.0       0.32      0.25      0.28        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.62      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3180   30]\n",
      " [  41   14]]\n",
      "21\n",
      "0.6290730699715983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3225\n",
      "         1.0       0.29      0.25      0.27        40\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.62      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3200   25]\n",
      " [  30   10]]\n",
      "22\n",
      "0.6677859177859178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3208\n",
      "         1.0       0.38      0.32      0.35        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.65      0.67      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3179   29]\n",
      " [  39   18]]\n",
      "23\n",
      "0.6358940045769466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3205\n",
      "         1.0       0.36      0.23      0.28        60\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.61      0.64      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3180   25]\n",
      " [  46   14]]\n",
      "24\n",
      "0.6948598130841122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3209\n",
      "         1.0       0.41      0.39      0.40        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.69      0.69      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3177   32]\n",
      " [  34   22]]\n",
      "25\n",
      "0.6183944498812907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3219\n",
      "         1.0       0.26      0.24      0.25        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.62      0.61      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3187   32]\n",
      " [  35   11]]\n",
      "26\n",
      "0.6533465983492134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3197\n",
      "         1.0       0.37      0.28      0.32        68\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.68      0.63      0.65      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3165   32]\n",
      " [  49   19]]\n",
      "27\n",
      "0.6070032394299859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3204\n",
      "         1.0       0.36      0.16      0.22        61\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.58      0.61      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3186   18]\n",
      " [  51   10]]\n",
      "28\n",
      "0.6848893796262218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3217\n",
      "         1.0       0.38      0.38      0.38        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.68      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3188   29]\n",
      " [  30   18]]\n",
      "29\n",
      "0.6713367985651012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3208\n",
      "         1.0       0.40      0.32      0.35        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.65      0.67      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3181   27]\n",
      " [  39   18]]\n",
      "30\n",
      "0.6036161626310325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3222\n",
      "         1.0       0.26      0.19      0.22        43\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.62      0.59      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3199   23]\n",
      " [  35    8]]\n",
      "31\n",
      "0.7041064854148966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3220\n",
      "         1.0       0.35      0.51      0.42        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.75      0.70      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3178   42]\n",
      " [  22   23]]\n",
      "32\n",
      "0.6467000185288123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3213\n",
      "         1.0       0.30      0.31      0.30        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.65      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3176   37]\n",
      " [  36   16]]\n",
      "33\n",
      "0.6798908843443257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3205\n",
      "         1.0       0.42      0.33      0.37        60\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.66      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3177   28]\n",
      " [  40   20]]\n",
      "34\n",
      "0.6912017414053758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3219\n",
      "         1.0       0.34      0.46      0.39        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.72      0.69      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3179   40]\n",
      " [  25   21]]\n",
      "35\n",
      "0.6832191385260785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3213\n",
      "         1.0       0.39      0.37      0.38        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.68      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3183   30]\n",
      " [  33   19]]\n",
      "36\n",
      "0.599388900859489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3206\n",
      "         1.0       0.24      0.19      0.21        59\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.61      0.59      0.60      3265\n",
      "weighted avg       0.97      0.97      0.97      3265\n",
      "\n",
      "[[3172   34]\n",
      " [  48   11]]\n",
      "37\n",
      "0.6483639848491762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3207\n",
      "         1.0       0.48      0.22      0.31        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.73      0.61      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3193   14]\n",
      " [  45   13]]\n",
      "38\n",
      "0.5739892029422797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3218\n",
      "         1.0       0.21      0.13      0.16        47\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.60      0.56      0.57      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3195   23]\n",
      " [  41    6]]\n",
      "39\n",
      "0.6514178166599558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3208\n",
      "         1.0       0.36      0.28      0.31        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.64      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3179   29]\n",
      " [  41   16]]\n",
      "40\n",
      "0.6273411154345007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3207\n",
      "         1.0       0.30      0.24      0.27        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.62      0.63      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3174   33]\n",
      " [  44   14]]\n",
      "41\n",
      "0.6775569202039791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3209\n",
      "         1.0       0.40      0.34      0.37        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.67      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3180   29]\n",
      " [  37   19]]\n",
      "42\n",
      "0.6153809907502956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3211\n",
      "         1.0       0.27      0.22      0.24        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.63      0.61      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3178   33]\n",
      " [  42   12]]\n",
      "43\n",
      "0.6414583257073831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3211\n",
      "         1.0       0.31      0.28      0.29        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.63      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3178   33]\n",
      " [  39   15]]\n",
      "44\n",
      "0.6140902021772938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3205\n",
      "         1.0       0.30      0.20      0.24        60\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.60      0.61      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3177   28]\n",
      " [  48   12]]\n",
      "45\n",
      "0.6287019081136729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3216\n",
      "         1.0       0.25      0.29      0.27        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.62      0.64      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3175   41]\n",
      " [  35   14]]\n",
      "46\n",
      "0.633960602878768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3210\n",
      "         1.0       0.27      0.29      0.28        55\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.63      0.64      0.63      3265\n",
      "weighted avg       0.98      0.97      0.98      3265\n",
      "\n",
      "[[3167   43]\n",
      " [  39   16]]\n",
      "47\n",
      "0.6732746721877156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3216\n",
      "         1.0       0.39      0.33      0.36        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.66      0.67      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3191   25]\n",
      " [  33   16]]\n",
      "48\n",
      "0.6788538176464616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3218\n",
      "         1.0       0.35      0.38      0.37        47\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.69      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3185   33]\n",
      " [  29   18]]\n",
      "49\n",
      "0.5682530447086205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3208\n",
      "         1.0       0.19      0.12      0.15        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.59      0.56      0.57      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3178   30]\n",
      " [  50    7]]\n",
      "RBF SVM\n",
      "0\n",
      "0.5752673524437867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3210\n",
      "         1.0       0.62      0.09      0.16        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.80      0.54      0.58      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3207    3]\n",
      " [  50    5]]\n",
      "1\n",
      "0.5614773104516116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3214\n",
      "         1.0       0.40      0.08      0.13        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.54      0.56      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3208    6]\n",
      " [  47    4]]\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5518495642028687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.50      0.06      0.11        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.74      0.53      0.55      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3214    3]\n",
      " [  45    3]]\n",
      "3\n",
      "0.5486921381934675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3214\n",
      "         1.0       0.50      0.06      0.11        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.53      0.55      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3211    3]\n",
      " [  48    3]]\n",
      "4\n",
      "0.556604938271605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3221\n",
      "         1.0       0.50      0.07      0.12        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.74      0.53      0.56      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3218    3]\n",
      " [  41    3]]\n",
      "5\n",
      "0.5766253715562472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3214\n",
      "         1.0       0.45      0.10      0.16        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.72      0.55      0.58      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3208    6]\n",
      " [  46    5]]\n",
      "6\n",
      "0.610042501624034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.75      0.13      0.23        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.87      0.57      0.61      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3218    2]\n",
      " [  39    6]]\n",
      "7\n",
      "0.5136866145902291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3212\n",
      "         1.0       0.33      0.02      0.04        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3210    2]\n",
      " [  52    1]]\n",
      "8\n",
      "0.5440580924451892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3209\n",
      "         1.0       0.50      0.05      0.10        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.53      0.54      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3206    3]\n",
      " [  53    3]]\n",
      "9\n",
      "0.5364506172839506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       1.00      0.04      0.08        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.99      0.52      0.54      3265\n",
      "weighted avg       0.99      0.99      0.98      3265\n",
      "\n",
      "[[3217    0]\n",
      " [  46    2]]\n",
      "10\n",
      "0.5638559518477484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3211\n",
      "         1.0       0.80      0.07      0.14        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.89      0.54      0.56      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3210    1]\n",
      " [  50    4]]\n",
      "11\n",
      "0.542370980853867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3224\n",
      "         1.0       0.67      0.05      0.09        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.83      0.52      0.54      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3223    1]\n",
      " [  39    2]]\n",
      "12\n",
      "0.5657004420079853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3200\n",
      "         1.0       0.83      0.08      0.14        65\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.91      0.54      0.57      3265\n",
      "weighted avg       0.98      0.98      0.97      3265\n",
      "\n",
      "[[3199    1]\n",
      " [  60    5]]\n",
      "13\n",
      "0.5857330420583432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.71      0.10      0.18        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.85      0.55      0.59      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3214    2]\n",
      " [  44    5]]\n",
      "14\n",
      "0.6037446489253717\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3219\n",
      "         1.0       0.60      0.13      0.21        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.79      0.56      0.60      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3215    4]\n",
      " [  40    6]]\n",
      "15\n",
      "0.5486921381934675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3215\n",
      "         1.0       0.43      0.06      0.11        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.53      0.55      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3211    4]\n",
      " [  47    3]]\n",
      "16\n",
      "0.5125448873592482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3209\n",
      "         1.0       0.33      0.02      0.03        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3207    2]\n",
      " [  55    1]]\n",
      "17\n",
      "0.5303109415625932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3212\n",
      "         1.0       0.40      0.04      0.07        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.52      0.53      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3209    3]\n",
      " [  51    2]]\n",
      "18\n",
      "0.6012354725907642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3226\n",
      "         1.0       0.56      0.13      0.21        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.77      0.56      0.60      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3222    4]\n",
      " [  34    5]]\n",
      "19\n",
      "0.5331766293779883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.40      0.04      0.07        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.52      0.53      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3213    3]\n",
      " [  47    2]]\n",
      "20\n",
      "0.546752263684915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3212\n",
      "         1.0       0.50      0.06      0.10        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.53      0.55      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3209    3]\n",
      " [  50    3]]\n",
      "21\n",
      "0.5581696566656356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.67      0.07      0.12        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.83      0.53      0.56      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3205    2]\n",
      " [  54    4]]\n",
      "22\n",
      "0.5449292844309176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3209\n",
      "         1.0       0.60      0.05      0.10        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.79      0.53      0.54      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3207    2]\n",
      " [  53    3]]\n",
      "23\n",
      "0.5638559518477484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3212\n",
      "         1.0       0.67      0.08      0.14        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.83      0.54      0.56      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3210    2]\n",
      " [  49    4]]\n",
      "24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5874341874341874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3221\n",
      "         1.0       0.45      0.11      0.18        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.72      0.56      0.59      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3215    6]\n",
      " [  39    5]]\n",
      "25\n",
      "0.5486921381934676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3213\n",
      "         1.0       0.60      0.06      0.11        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.79      0.53      0.55      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3211    2]\n",
      " [  49    3]]\n",
      "26\n",
      "0.556604938271605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.60      0.07      0.12        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.79      0.53      0.56      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3218    2]\n",
      " [  42    3]]\n",
      "27\n",
      "0.5626481195260175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.36      0.08      0.13        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.54      0.56      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3209    7]\n",
      " [  45    4]]\n",
      "28\n",
      "0.5347566912864844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3215\n",
      "         1.0       1.00      0.04      0.08        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.99      0.52      0.53      3265\n",
      "weighted avg       0.99      0.99      0.98      3265\n",
      "\n",
      "[[3215    0]\n",
      " [  48    2]]\n",
      "29\n",
      "0.5423900015465513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3209\n",
      "         1.0       0.38      0.05      0.09        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.68      0.53      0.54      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3204    5]\n",
      " [  53    3]]\n",
      "30\n",
      "0.5467522636849149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3211\n",
      "         1.0       0.60      0.06      0.10        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.79      0.53      0.55      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3209    2]\n",
      " [  51    3]]\n",
      "31\n",
      "0.5309937906716429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3214\n",
      "         1.0       0.33      0.04      0.07        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.52      0.53      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3210    4]\n",
      " [  49    2]]\n",
      "32\n",
      "0.5372217824675254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3201\n",
      "         1.0       0.43      0.05      0.08        64\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.52      0.54      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3197    4]\n",
      " [  61    3]]\n",
      "33\n",
      "0.5477068326158305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3210\n",
      "         1.0       1.00      0.05      0.10        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.99      0.53      0.55      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3210    0]\n",
      " [  52    3]]\n",
      "34\n",
      "0.5561196744674467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3206\n",
      "         1.0       0.57      0.07      0.12        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.78      0.53      0.56      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3203    3]\n",
      " [  55    4]]\n",
      "35\n",
      "0.5158263953829719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.33      0.02      0.04        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.51      0.52      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3215    2]\n",
      " [  47    1]]\n",
      "36\n",
      "0.5408134563456345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3202\n",
      "         1.0       1.00      0.05      0.09        63\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.99      0.52      0.54      3265\n",
      "weighted avg       0.98      0.98      0.97      3265\n",
      "\n",
      "[[3202    0]\n",
      " [  60    3]]\n",
      "37\n",
      "0.5486921381934675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3214\n",
      "         1.0       0.50      0.06      0.11        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.53      0.55      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3211    3]\n",
      " [  48    3]]\n",
      "38\n",
      "0.5347566912864845\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.50      0.04      0.08        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.74      0.52      0.53      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3215    2]\n",
      " [  46    2]]\n",
      "39\n",
      "0.5331766293779883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3213\n",
      "         1.0       1.00      0.04      0.07        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.99      0.52      0.53      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3213    0]\n",
      " [  50    2]]\n",
      "40\n",
      "0.5690416370819451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3204\n",
      "         1.0       0.71      0.08      0.15        61\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.85      0.54      0.57      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3202    2]\n",
      " [  56    5]]\n",
      "41\n",
      "0.5316982214572576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3214\n",
      "         1.0       0.40      0.04      0.07        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.52      0.53      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3211    3]\n",
      " [  49    2]]\n",
      "42\n",
      "0.5153715534234213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3219\n",
      "         1.0       0.17      0.02      0.04        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.58      0.51      0.52      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3214    5]\n",
      " [  45    1]]\n",
      "43\n",
      "0.5603417320007181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3210\n",
      "         1.0       0.57      0.07      0.13        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.78      0.54      0.56      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3207    3]\n",
      " [  51    4]]\n",
      "44\n",
      "0.5840888332371172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.56      0.10      0.18        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.77      0.55      0.58      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3213    4]\n",
      " [  43    5]]\n",
      "45\n",
      "0.529005667181865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.67      0.04      0.07        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.82      0.52      0.53      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3207    1]\n",
      " [  55    2]]\n",
      "46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5705224990277491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.80      0.08      0.15        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.89      0.54      0.57      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3215    1]\n",
      " [  45    4]]\n",
      "47\n",
      "0.6194855282807669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.58      0.16      0.25        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.79      0.58      0.62      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3215    5]\n",
      " [  38    7]]\n",
      "48\n",
      "0.529005667181865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3214\n",
      "         1.0       0.22      0.04      0.07        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.60      0.52      0.53      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3207    7]\n",
      " [  49    2]]\n",
      "49\n",
      "0.5372217824675254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3200\n",
      "         1.0       0.50      0.05      0.08        65\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.52      0.54      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3197    3]\n",
      " [  62    3]]\n",
      "Decision Tree\n",
      "0\n",
      "0.5260515200190374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3205\n",
      "         1.0       0.40      0.03      0.06        60\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.52      0.53      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3202    3]\n",
      " [  58    2]]\n",
      "1\n",
      "0.6107348943678764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3212\n",
      "         1.0       0.36      0.17      0.23        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.58      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3196   16]\n",
      " [  44    9]]\n",
      "2\n",
      "0.6563967386129583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3206\n",
      "         1.0       0.44      0.25      0.32        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.62      0.66      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3187   19]\n",
      " [  44   15]]\n",
      "3\n",
      "0.6582903873081865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3213\n",
      "         1.0       0.41      0.27      0.33        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.63      0.66      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3193   20]\n",
      " [  38   14]]\n",
      "4\n",
      "0.681296289517674\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3202\n",
      "         1.0       0.49      0.30      0.37        63\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.65      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3182   20]\n",
      " [  44   19]]\n",
      "5\n",
      "0.6962790697674419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3223\n",
      "         1.0       0.42      0.38      0.40        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.71      0.69      0.70      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3201   22]\n",
      " [  26   16]]\n",
      "6\n",
      "0.5823837209302326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3197\n",
      "         1.0       0.58      0.10      0.18        68\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.78      0.55      0.58      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3192    5]\n",
      " [  61    7]]\n",
      "7\n",
      "0.5393203706738035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3203\n",
      "         1.0       0.50      0.05      0.09        62\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.52      0.54      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3200    3]\n",
      " [  59    3]]\n",
      "8\n",
      "0.6766124526024059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3216\n",
      "         1.0       0.44      0.31      0.36        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.72      0.65      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3197   19]\n",
      " [  34   15]]\n",
      "9\n",
      "0.6429151025937738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3206\n",
      "         1.0       0.45      0.22      0.30        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.72      0.61      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3190   16]\n",
      " [  46   13]]\n",
      "10\n",
      "0.6213925475567353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3217\n",
      "         1.0       0.28      0.23      0.25        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.61      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3189   28]\n",
      " [  37   11]]\n",
      "11\n",
      "0.5581696566656356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.25      0.08      0.12        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.62      0.54      0.56      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3205   12]\n",
      " [  44    4]]\n",
      "12\n",
      "0.6330038759689922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3214\n",
      "         1.0       0.38      0.22      0.28        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.68      0.61      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3196   18]\n",
      " [  40   11]]\n",
      "13\n",
      "0.6525680812352049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3219\n",
      "         1.0       0.33      0.30      0.31        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.65      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3190   29]\n",
      " [  32   14]]\n",
      "14\n",
      "0.5875918467512594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3202\n",
      "         1.0       0.35      0.13      0.19        63\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.56      0.59      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3187   15]\n",
      " [  55    8]]\n",
      "15\n",
      "0.5991696200901222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3206\n",
      "         1.0       0.44      0.14      0.21        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.57      0.60      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3196   10]\n",
      " [  51    8]]\n",
      "16\n",
      "0.7143731956959146\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3227\n",
      "         1.0       0.48      0.39      0.43        38\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.74      0.69      0.71      3265\n",
      "weighted avg       0.99      0.99      0.99      3265\n",
      "\n",
      "[[3211   16]\n",
      " [  23   15]]\n",
      "17\n",
      "0.6538662273906024\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3211\n",
      "         1.0       0.55      0.22      0.32        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.77      0.61      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3201   10]\n",
      " [  42   12]]\n",
      "18\n",
      "0.6358940045769466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3201\n",
      "         1.0       0.40      0.22      0.28        64\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.61      0.64      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3180   21]\n",
      " [  50   14]]\n",
      "19\n",
      "0.6344012441679627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3209\n",
      "         1.0       0.32      0.25      0.28        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.62      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3179   30]\n",
      " [  42   14]]\n",
      "20\n",
      "0.666663525316923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3205\n",
      "         1.0       0.44      0.28      0.34        60\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.64      0.67      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3183   22]\n",
      " [  43   17]]\n",
      "21\n",
      "0.6389871738168952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3219\n",
      "         1.0       0.42      0.22      0.29        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.61      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3205   14]\n",
      " [  36   10]]\n",
      "22\n",
      "0.6348225866267422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3218\n",
      "         1.0       0.34      0.23      0.28        47\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.61      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3197   21]\n",
      " [  36   11]]\n",
      "23\n",
      "0.6912893080077996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3223\n",
      "         1.0       0.38      0.40      0.39        42\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.70      0.69      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3195   28]\n",
      " [  25   17]]\n",
      "24\n",
      "0.622009344052242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3211\n",
      "         1.0       0.40      0.19      0.25        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.59      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3196   15]\n",
      " [  44   10]]\n",
      "25\n",
      "0.6208191390523381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3223\n",
      "         1.0       0.30      0.21      0.25        42\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.60      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3202   21]\n",
      " [  33    9]]\n",
      "26\n",
      "0.6314988347548105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3209\n",
      "         1.0       0.30      0.25      0.27        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.62      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3177   32]\n",
      " [  42   14]]\n",
      "27\n",
      "0.6172845708161694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3224\n",
      "         1.0       0.27      0.22      0.24        41\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.63      0.61      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3200   24]\n",
      " [  32    9]]\n",
      "28\n",
      "0.6309529790013062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3218\n",
      "         1.0       0.37      0.21      0.27        47\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.68      0.60      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3201   17]\n",
      " [  37   10]]\n",
      "29\n",
      "0.6006148777583873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3217\n",
      "         1.0       0.29      0.17      0.21        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.58      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3197   20]\n",
      " [  40    8]]\n",
      "30\n",
      "0.6429151025937738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3211\n",
      "         1.0       0.38      0.24      0.30        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.68      0.62      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3190   21]\n",
      " [  41   13]]\n",
      "31\n",
      "0.6348265809982747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3222\n",
      "         1.0       0.41      0.21      0.28        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.70      0.60      0.63      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3209   13]\n",
      " [  34    9]]\n",
      "32\n",
      "0.6848893796262218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3222\n",
      "         1.0       0.35      0.42      0.38        43\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.70      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3188   34]\n",
      " [  25   18]]\n",
      "33\n",
      "0.6123115997592985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3210\n",
      "         1.0       0.41      0.16      0.23        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.58      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3197   13]\n",
      " [  46    9]]\n",
      "34\n",
      "0.5646441966897217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.33      0.09      0.14        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.54      0.56      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3198   10]\n",
      " [  52    5]]\n",
      "35\n",
      "0.6366859014100179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3212\n",
      "         1.0       0.44      0.21      0.28        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.60      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3198   14]\n",
      " [  42   11]]\n",
      "36\n",
      "0.6750233281493001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3217\n",
      "         1.0       0.35      0.38      0.36        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.68      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3183   34]\n",
      " [  30   18]]\n",
      "37\n",
      "0.6411768707839003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3205\n",
      "         1.0       0.45      0.22      0.29        60\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.72      0.61      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3189   16]\n",
      " [  47   13]]\n",
      "38\n",
      "0.6673047786569914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3211\n",
      "         1.0       0.41      0.30      0.34        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.64      0.67      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3188   23]\n",
      " [  38   16]]\n",
      "39\n",
      "0.5887646602473418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3202\n",
      "         1.0       0.36      0.13      0.19        63\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.56      0.59      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3188   14]\n",
      " [  55    8]]\n",
      "40\n",
      "0.6889905732268353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3212\n",
      "         1.0       0.49      0.32      0.39        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.66      0.69      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3194   18]\n",
      " [  36   17]]\n",
      "41\n",
      "0.6848893796262218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3211\n",
      "         1.0       0.44      0.33      0.38        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.66      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3188   23]\n",
      " [  36   18]]\n",
      "42\n",
      "0.6348265809982747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3219\n",
      "         1.0       0.47      0.20      0.28        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.73      0.60      0.63      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3209   10]\n",
      " [  37    9]]\n",
      "43\n",
      "0.6502629907066768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3222\n",
      "         1.0       0.32      0.30      0.31        43\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.65      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3194   28]\n",
      " [  30   13]]\n",
      "44\n",
      "0.6766124526024059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3213\n",
      "         1.0       0.48      0.29      0.36        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.64      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3197   16]\n",
      " [  37   15]]\n",
      "45\n",
      "0.6454886985689252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3204\n",
      "         1.0       0.44      0.23      0.30        61\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.61      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3186   18]\n",
      " [  47   14]]\n",
      "46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6532923470703511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3202\n",
      "         1.0       0.36      0.29      0.32        63\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.64      0.65      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3170   32]\n",
      " [  45   18]]\n",
      "47\n",
      "0.6006148777583873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3218\n",
      "         1.0       0.28      0.17      0.21        47\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.63      0.58      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3197   21]\n",
      " [  39    8]]\n",
      "48\n",
      "0.664409148927025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3211\n",
      "         1.0       0.48      0.26      0.34        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.63      0.66      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3196   15]\n",
      " [  40   14]]\n",
      "49\n",
      "0.5899477544458958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3209\n",
      "         1.0       0.39      0.12      0.19        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.56      0.59      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3198   11]\n",
      " [  49    7]]\n",
      "AdaBoost\n",
      "0\n",
      "0.5899635063457589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3206\n",
      "         1.0       0.32      0.14      0.19        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.57      0.59      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3189   17]\n",
      " [  51    8]]\n",
      "1\n",
      "0.6394755003450655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3211\n",
      "         1.0       0.36      0.24      0.29        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.62      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3188   23]\n",
      " [  41   13]]\n",
      "2\n",
      "0.5823837209302325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3218\n",
      "         1.0       0.21      0.15      0.17        47\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.60      0.57      0.58      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3192   26]\n",
      " [  40    7]]\n",
      "3\n",
      "0.6602838497695432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3217\n",
      "         1.0       0.38      0.29      0.33        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.68      0.64      0.66      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3194   23]\n",
      " [  34   14]]\n",
      "4\n",
      "0.6456589147286822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3214\n",
      "         1.0       0.41      0.24      0.30        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.62      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3197   17]\n",
      " [  39   12]]\n",
      "5\n",
      "0.6136235366941577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.35      0.18      0.24        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.59      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3205   15]\n",
      " [  37    8]]\n",
      "6\n",
      "0.6600984044686483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3209\n",
      "         1.0       0.43      0.27      0.33        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.63      0.66      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3189   20]\n",
      " [  41   15]]\n",
      "7\n",
      "0.6314988347548105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3206\n",
      "         1.0       0.33      0.24      0.27        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.61      0.63      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3177   29]\n",
      " [  45   14]]\n",
      "8\n",
      "0.6476358292012425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3211\n",
      "         1.0       0.48      0.22      0.30        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.73      0.61      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3198   13]\n",
      " [  42   12]]\n",
      "9\n",
      "0.6313962349355084\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3216\n",
      "         1.0       0.31      0.24      0.27        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.62      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3189   27]\n",
      " [  37   12]]\n",
      "10\n",
      "0.6290730699715982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3211\n",
      "         1.0       0.48      0.19      0.27        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.73      0.59      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3200   11]\n",
      " [  44   10]]\n",
      "11\n",
      "0.6744427307307987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.54      0.27      0.36        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.77      0.63      0.67      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3205   11]\n",
      " [  36   13]]\n",
      "12\n",
      "0.6043768314307217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3202\n",
      "         1.0       0.36      0.16      0.22        63\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.58      0.60      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3184   18]\n",
      " [  53   10]]\n",
      "13\n",
      "0.6347242071225442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3206\n",
      "         1.0       0.44      0.20      0.28        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.60      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3191   15]\n",
      " [  47   12]]\n",
      "14\n",
      "0.6934093617241737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3202\n",
      "         1.0       0.58      0.30      0.40        63\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.78      0.65      0.69      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3188   14]\n",
      " [  44   19]]\n",
      "15\n",
      "0.5899477544458958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3215\n",
      "         1.0       0.29      0.14      0.19        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.57      0.59      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3198   17]\n",
      " [  43    7]]\n",
      "16\n",
      "0.6429151025937738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3215\n",
      "         1.0       0.34      0.26      0.30        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.63      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3190   25]\n",
      " [  37   13]]\n",
      "17\n",
      "0.5950387596899225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3210\n",
      "         1.0       0.32      0.15      0.20        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.57      0.60      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3193   17]\n",
      " [  47    8]]\n",
      "18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6476358292012425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3213\n",
      "         1.0       0.44      0.23      0.30        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.72      0.61      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3198   15]\n",
      " [  40   12]]\n",
      "19\n",
      "0.6888157562777868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3220\n",
      "         1.0       0.42      0.36      0.39        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.67      0.69      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3198   22]\n",
      " [  29   16]]\n",
      "20\n",
      "0.6525680812352049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3216\n",
      "         1.0       0.35      0.29      0.31        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.64      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3190   26]\n",
      " [  35   14]]\n",
      "21\n",
      "0.5971929682891104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3219\n",
      "         1.0       0.30      0.15      0.20        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.57      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3203   16]\n",
      " [  39    7]]\n",
      "22\n",
      "0.6382030938344931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3211\n",
      "         1.0       0.40      0.22      0.29        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.61      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3193   18]\n",
      " [  42   12]]\n",
      "23\n",
      "0.5941791015484453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.32      0.14      0.20        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.57      0.59      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3201   15]\n",
      " [  42    7]]\n",
      "24\n",
      "0.6796398479326222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3215\n",
      "         1.0       0.43      0.32      0.37        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.66      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3194   21]\n",
      " [  34   16]]\n",
      "25\n",
      "0.6169427191166321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3207\n",
      "         1.0       0.34      0.19      0.24        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.59      0.62      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3186   21]\n",
      " [  47   11]]\n",
      "26\n",
      "0.6366859014100179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3217\n",
      "         1.0       0.37      0.23      0.28        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.68      0.61      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3198   19]\n",
      " [  37   11]]\n",
      "27\n",
      "0.5852972488632191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.32      0.12      0.18        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.56      0.59      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3204   13]\n",
      " [  42    6]]\n",
      "28\n",
      "0.644621387186443\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3213\n",
      "         1.0       0.50      0.21      0.30        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.60      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3202   11]\n",
      " [  41   11]]\n",
      "29\n",
      "0.6818565674938288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3208\n",
      "         1.0       0.55      0.28      0.37        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.77      0.64      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3195   13]\n",
      " [  41   16]]\n",
      "30\n",
      "0.5956656346749226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3226\n",
      "         1.0       0.23      0.18      0.20        39\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.61      0.59      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3202   24]\n",
      " [  32    7]]\n",
      "31\n",
      "0.6425613219726309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3211\n",
      "         1.0       0.52      0.20      0.29        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.76      0.60      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3201   10]\n",
      " [  43   11]]\n",
      "32\n",
      "0.6062266328974346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3210\n",
      "         1.0       0.35      0.16      0.22        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.58      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3193   17]\n",
      " [  46    9]]\n",
      "33\n",
      "0.6173445469546954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3221\n",
      "         1.0       0.36      0.18      0.24        44\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.68      0.59      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3207   14]\n",
      " [  36    8]]\n",
      "34\n",
      "0.6912905588292326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3208\n",
      "         1.0       0.47      0.33      0.39        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.73      0.66      0.69      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3187   21]\n",
      " [  38   19]]\n",
      "35\n",
      "0.6483639848491762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3210\n",
      "         1.0       0.43      0.24      0.31        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.62      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3193   17]\n",
      " [  42   13]]\n",
      "36\n",
      "0.601787180758942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3228\n",
      "         1.0       0.30      0.16      0.21        37\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.65      0.58      0.60      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3214   14]\n",
      " [  31    6]]\n",
      "37\n",
      "0.6051752266309687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3215\n",
      "         1.0       0.35      0.16      0.22        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.58      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3200   15]\n",
      " [  42    8]]\n",
      "38\n",
      "0.6187273747102144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3216\n",
      "         1.0       0.31      0.20      0.25        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.60      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3194   22]\n",
      " [  39   10]]\n",
      "39\n",
      "0.5886083139684999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3215\n",
      "         1.0       0.28      0.14      0.19        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.63      0.57      0.59      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3197   18]\n",
      " [  43    7]]\n",
      "40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6703611051905365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3208\n",
      "         1.0       0.42      0.30      0.35        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.65      0.67      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3185   23]\n",
      " [  40   17]]\n",
      "41\n",
      "0.656229600148554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3208\n",
      "         1.0       0.54      0.23      0.32        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.76      0.61      0.66      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3197   11]\n",
      " [  44   13]]\n",
      "42\n",
      "0.6421625158467263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3206\n",
      "         1.0       0.39      0.24      0.29        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.62      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3184   22]\n",
      " [  45   14]]\n",
      "43\n",
      "0.6136235366941577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.35      0.18      0.24        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.59      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3205   15]\n",
      " [  37    8]]\n",
      "44\n",
      "0.5758087566584383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3207\n",
      "         1.0       0.25      0.12      0.16        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.62      0.56      0.58      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3186   21]\n",
      " [  51    7]]\n",
      "45\n",
      "0.6400025415762631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3211\n",
      "         1.0       0.41      0.22      0.29        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.61      0.64      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3194   17]\n",
      " [  42   12]]\n",
      "46\n",
      "0.6213925475567353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3216\n",
      "         1.0       0.29      0.22      0.25        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.61      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3189   27]\n",
      " [  38   11]]\n",
      "47\n",
      "0.6496614049310887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3210\n",
      "         1.0       0.52      0.22      0.31        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.75      0.61      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3199   11]\n",
      " [  43   12]]\n",
      "48\n",
      "0.5924431096047933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.33      0.14      0.20        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.57      0.59      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3191   16]\n",
      " [  50    8]]\n",
      "49\n",
      "0.6465072972153654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3215\n",
      "         1.0       0.36      0.26      0.30        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.63      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3192   23]\n",
      " [  37   13]]\n",
      "Naive Bayes\n",
      "0\n",
      "0.6091738618524333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3216\n",
      "         1.0       0.17      0.39      0.24        49\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.58      0.68      0.61      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3124   92]\n",
      " [  30   19]]\n",
      "1\n",
      "0.6305551357052536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3211\n",
      "         1.0       0.20      0.50      0.28        54\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.59      0.73      0.63      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3101  110]\n",
      " [  27   27]]\n",
      "2\n",
      "0.632500751156502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3208\n",
      "         1.0       0.21      0.42      0.28        57\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.60      0.70      0.63      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3120   88]\n",
      " [  33   24]]\n",
      "3\n",
      "0.6126639132821833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3219\n",
      "         1.0       0.17      0.46      0.25        46\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.58      0.71      0.61      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3115  104]\n",
      " [  25   21]]\n",
      "4\n",
      "0.6219878335949764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3217\n",
      "         1.0       0.19      0.44      0.26        48\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.59      0.70      0.62      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3126   91]\n",
      " [  27   21]]\n",
      "5\n",
      "0.6424813730391106\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3206\n",
      "         1.0       0.24      0.42      0.30        59\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.61      0.70      0.64      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3125   81]\n",
      " [  34   25]]\n",
      "6\n",
      "0.6164402276775652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3216\n",
      "         1.0       0.17      0.47      0.25        49\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.58      0.72      0.62      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3107  109]\n",
      " [  26   23]]\n",
      "7\n",
      "0.6495738036380759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3208\n",
      "         1.0       0.23      0.51      0.32        57\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.61      0.74      0.65      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3112   96]\n",
      " [  28   29]]\n",
      "8\n",
      "0.6338290379741156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3214\n",
      "         1.0       0.21      0.45      0.29        51\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.60      0.71      0.63      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3127   87]\n",
      " [  28   23]]\n",
      "9\n",
      "0.6091738618524333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3206\n",
      "         1.0       0.19      0.32      0.24        59\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.59      0.65      0.61      3265\n",
      "weighted avg       0.97      0.96      0.97      3265\n",
      "\n",
      "[[3124   82]\n",
      " [  40   19]]\n",
      "10\n",
      "0.6006534919886075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3218\n",
      "         1.0       0.15      0.40      0.22        47\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.57      0.69      0.60      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3113  105]\n",
      " [  28   19]]\n",
      "11\n",
      "0.6476698749744421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3212\n",
      "         1.0       0.23      0.49      0.31        53\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.61      0.73      0.65      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3125   87]\n",
      " [  27   26]]\n",
      "12\n",
      "0.6486990882906044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      3205\n",
      "         1.0       0.25      0.43      0.32        60\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.62      0.70      0.65      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3126   79]\n",
      " [  34   26]]\n",
      "13\n",
      "0.6173230192217534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3211\n",
      "         1.0       0.19      0.37      0.25        54\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.59      0.67      0.62      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3127   84]\n",
      " [  34   20]]\n",
      "14\n",
      "0.6275807003535987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3216\n",
      "         1.0       0.20      0.43      0.27        49\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.60      0.70      0.63      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3132   84]\n",
      " [  28   21]]\n",
      "15\n",
      "0.6147244660423304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3217\n",
      "         1.0       0.18      0.42      0.25        48\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.58      0.69      0.61      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3124   93]\n",
      " [  28   20]]\n",
      "16\n",
      "0.629223786085235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3209\n",
      "         1.0       0.20      0.46      0.28        56\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.60      0.72      0.63      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3105  104]\n",
      " [  30   26]]\n",
      "17\n",
      "0.6477000962273229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3213\n",
      "         1.0       0.22      0.54      0.31        52\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.61      0.75      0.65      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3115   98]\n",
      " [  24   28]]\n",
      "18\n",
      "0.5986301684754852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3211\n",
      "         1.0       0.17      0.31      0.22        54\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.58      0.64      0.60      3265\n",
      "weighted avg       0.97      0.96      0.97      3265\n",
      "\n",
      "[[3125   86]\n",
      " [  37   17]]\n",
      "19\n",
      "0.6291261841836232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3211\n",
      "         1.0       0.21      0.43      0.28        54\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.60      0.70      0.63      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3122   89]\n",
      " [  31   23]]\n",
      "20\n",
      "0.6048295889471073\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3199\n",
      "         1.0       0.18      0.35      0.23        66\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      3265\n",
      "   macro avg       0.58      0.66      0.60      3265\n",
      "weighted avg       0.97      0.95      0.96      3265\n",
      "\n",
      "[[3091  108]\n",
      " [  43   23]]\n",
      "21\n",
      "0.6166220468742661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98      3214\n",
      "         1.0       0.18      0.47      0.26        51\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.58      0.72      0.62      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3101  113]\n",
      " [  27   24]]\n",
      "22\n",
      "0.644087750680264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      3215\n",
      "         1.0       0.23      0.46      0.30        50\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.61      0.72      0.64      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3137   78]\n",
      " [  27   23]]\n",
      "23\n",
      "0.6629346316641301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      3216\n",
      "         1.0       0.26      0.49      0.34        49\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.63      0.73      0.66      3265\n",
      "weighted avg       0.98      0.97      0.98      3265\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3148   68]\n",
      " [  25   24]]\n",
      "24\n",
      "0.6028783251747728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3215\n",
      "         1.0       0.16      0.38      0.23        50\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.58      0.67      0.60      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3116   99]\n",
      " [  31   19]]\n",
      "25\n",
      "0.624598463193049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3209\n",
      "         1.0       0.20      0.43      0.27        56\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.59      0.70      0.62      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3111   98]\n",
      " [  32   24]]\n",
      "26\n",
      "0.6138776443948135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3220\n",
      "         1.0       0.17      0.44      0.25        45\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.58      0.71      0.61      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3123   97]\n",
      " [  25   20]]\n",
      "27\n",
      "0.6671656365353249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3210\n",
      "         1.0       0.26      0.56      0.35        55\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.62      0.77      0.67      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3120   90]\n",
      " [  24   31]]\n",
      "28\n",
      "0.6040127607572938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98      3214\n",
      "         1.0       0.15      0.47      0.23        51\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      3265\n",
      "   macro avg       0.57      0.71      0.60      3265\n",
      "weighted avg       0.98      0.95      0.96      3265\n",
      "\n",
      "[[3083  131]\n",
      " [  27   24]]\n",
      "29\n",
      "0.649377147766323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3208\n",
      "         1.0       0.23      0.54      0.32        57\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.61      0.76      0.65      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3102  106]\n",
      " [  26   31]]\n",
      "30\n",
      "0.5953642948013769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98      3211\n",
      "         1.0       0.15      0.37      0.21        54\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      3265\n",
      "   macro avg       0.57      0.67      0.60      3265\n",
      "weighted avg       0.98      0.95      0.96      3265\n",
      "\n",
      "[[3098  113]\n",
      " [  34   20]]\n",
      "31\n",
      "0.5983114117420145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98      3208\n",
      "         1.0       0.15      0.39      0.22        57\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      3265\n",
      "   macro avg       0.57      0.67      0.60      3265\n",
      "weighted avg       0.97      0.95      0.96      3265\n",
      "\n",
      "[[3088  120]\n",
      " [  35   22]]\n",
      "32\n",
      "0.5848927666134274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3215\n",
      "         1.0       0.14      0.30      0.19        50\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.56      0.64      0.58      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3122   93]\n",
      " [  35   15]]\n",
      "33\n",
      "0.6009793218074272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3217\n",
      "         1.0       0.16      0.35      0.22        48\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.58      0.66      0.60      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3128   89]\n",
      " [  31   17]]\n",
      "34\n",
      "0.608773642945031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3217\n",
      "         1.0       0.16      0.44      0.24        48\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.58      0.70      0.61      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3110  107]\n",
      " [  27   21]]\n",
      "35\n",
      "0.6486690304238133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3210\n",
      "         1.0       0.23      0.51      0.32        55\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.61      0.74      0.65      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3116   94]\n",
      " [  27   28]]\n",
      "36\n",
      "0.651856892487127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3213\n",
      "         1.0       0.24      0.50      0.32        52\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.61      0.74      0.65      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3129   84]\n",
      " [  26   26]]\n",
      "37\n",
      "0.6019880847544735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3207\n",
      "         1.0       0.17      0.31      0.22        58\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.58      0.64      0.60      3265\n",
      "weighted avg       0.97      0.96      0.97      3265\n",
      "\n",
      "[[3122   85]\n",
      " [  40   18]]\n",
      "38\n",
      "0.5935787476280836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3222\n",
      "         1.0       0.14      0.37      0.21        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.57      0.67      0.59      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3126   96]\n",
      " [  27   16]]\n",
      "39\n",
      "0.6256242646853359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3216\n",
      "         1.0       0.19      0.45      0.27        49\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.59      0.71      0.63      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3124   92]\n",
      " [  27   22]]\n",
      "40\n",
      "0.6082032801585846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3213\n",
      "         1.0       0.17      0.38      0.24        52\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.58      0.68      0.61      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3116   97]\n",
      " [  32   20]]\n",
      "41\n",
      "0.6229589883620168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3202\n",
      "         1.0       0.21      0.37      0.27        63\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.60      0.67      0.62      3265\n",
      "weighted avg       0.97      0.96      0.97      3265\n",
      "\n",
      "[[3115   87]\n",
      " [  40   23]]\n",
      "42\n",
      "0.6068774081016349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98      3207\n",
      "         1.0       0.17      0.40      0.24        58\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      3265\n",
      "   macro avg       0.58      0.68      0.61      3265\n",
      "weighted avg       0.97      0.95      0.96      3265\n",
      "\n",
      "[[3094  113]\n",
      " [  35   23]]\n",
      "43\n",
      "0.6067956989247312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3223\n",
      "         1.0       0.16      0.43      0.23        42\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.58      0.70      0.61      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3128   95]\n",
      " [  24   18]]\n",
      "44\n",
      "0.5953377928358382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3229\n",
      "         1.0       0.14      0.39      0.21        36\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.57      0.68      0.60      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3144   85]\n",
      " [  22   14]]\n",
      "45\n",
      "0.6914960629921261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3202\n",
      "         1.0       0.31      0.57      0.40        63\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.65      0.77      0.69      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3121   81]\n",
      " [  27   36]]\n",
      "46\n",
      "0.6507923813451453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      3204\n",
      "         1.0       0.25      0.43      0.32        61\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.62      0.70      0.65      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3128   76]\n",
      " [  35   26]]\n",
      "47\n",
      "0.624674334575759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3201\n",
      "         1.0       0.21      0.36      0.27        64\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.60      0.67      0.62      3265\n",
      "weighted avg       0.97      0.96      0.97      3265\n",
      "\n",
      "[[3117   84]\n",
      " [  41   23]]\n",
      "48\n",
      "0.6521285584377934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3201\n",
      "         1.0       0.24      0.48      0.32        64\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.62      0.73      0.65      3265\n",
      "weighted avg       0.97      0.96      0.97      3265\n",
      "\n",
      "[[3105   96]\n",
      " [  33   31]]\n",
      "49\n",
      "0.5638740850827066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3222\n",
      "         1.0       0.10      0.26      0.15        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.55      0.61      0.56      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3127   95]\n",
      " [  32   11]]\n",
      "XGBoost\n",
      "0\n",
      "0.5432120582886008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.60      0.05      0.10        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.79      0.53      0.54      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3205    2]\n",
      " [  55    3]]\n",
      "1\n",
      "0.6036161626310326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3201\n",
      "         1.0       0.80      0.12      0.22        64\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.89      0.56      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3199    2]\n",
      " [  56    8]]\n",
      "2\n",
      "0.6226577610889052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3215\n",
      "         1.0       0.43      0.18      0.25        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.71      0.59      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3203   12]\n",
      " [  41    9]]\n",
      "3\n",
      "0.5507616707616708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.30      0.07      0.11        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.53      0.55      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3213    7]\n",
      " [  42    3]]\n",
      "4\n",
      "0.5860276404209459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3206\n",
      "         1.0       0.39      0.12      0.18        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.56      0.59      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3195   11]\n",
      " [  52    7]]\n",
      "5\n",
      "0.5794693456980937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.45      0.10      0.17        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.72      0.55      0.58      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3210    6]\n",
      " [  44    5]]\n",
      "6\n",
      "0.5874341874341874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3225\n",
      "         1.0       0.33      0.12      0.18        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.66      0.56      0.59      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3215   10]\n",
      " [  35    5]]\n",
      "7\n",
      "0.5857330420583432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.45      0.11      0.18        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.72      0.55      0.59      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3214    6]\n",
      " [  40    5]]\n",
      "8\n",
      "0.556604938271605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3223\n",
      "         1.0       0.38      0.07      0.12        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.68      0.53      0.56      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3218    5]\n",
      " [  39    3]]\n",
      "9\n",
      "0.5506004610990675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3198\n",
      "         1.0       0.80      0.06      0.11        67\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.89      0.53      0.55      3265\n",
      "weighted avg       0.98      0.98      0.97      3265\n",
      "\n",
      "[[3197    1]\n",
      " [  63    4]]\n",
      "10\n",
      "0.5702171488218816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3212\n",
      "         1.0       0.36      0.09      0.15        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.55      0.57      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3203    9]\n",
      " [  48    5]]\n",
      "11\n",
      "0.5239553261598577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3202\n",
      "         1.0       0.33      0.03      0.06        63\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.52      0.52      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3198    4]\n",
      " [  61    2]]\n",
      "12\n",
      "0.5702171488218816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3215\n",
      "         1.0       0.29      0.10      0.15        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.55      0.57      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3203   12]\n",
      " [  45    5]]\n",
      "13\n",
      "0.6020965659695326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.47      0.14      0.21        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.73      0.57      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3198    9]\n",
      " [  50    8]]\n",
      "14\n",
      "0.5910201846300844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3222\n",
      "         1.0       0.50      0.12      0.19        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.74      0.56      0.59      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3217    5]\n",
      " [  38    5]]\n",
      "15\n",
      "0.5719978676361348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3223\n",
      "         1.0       0.36      0.10      0.15        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.68      0.55      0.57      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3216    7]\n",
      " [  38    4]]\n",
      "16\n",
      "0.507425015902011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3190\n",
      "         1.0       1.00      0.01      0.03        75\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.99      0.51      0.51      3265\n",
      "weighted avg       0.98      0.98      0.97      3265\n",
      "\n",
      "[[3190    0]\n",
      " [  74    1]]\n",
      "17\n",
      "0.5956656346749226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.54      0.12      0.20        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.76      0.56      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3202    6]\n",
      " [  50    7]]\n",
      "18\n",
      "0.6020383288328832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.41      0.14      0.21        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.57      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3206   10]\n",
      " [  42    7]]\n",
      "19\n",
      "0.609192650667305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3222\n",
      "         1.0       0.37      0.16      0.23        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.68      0.58      0.61      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3210   12]\n",
      " [  36    7]]\n",
      "20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5614773104516116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3214\n",
      "         1.0       0.40      0.08      0.13        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.54      0.56      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3208    6]\n",
      " [  47    4]]\n",
      "21\n",
      "0.5581696566656356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.67      0.07      0.12        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.83      0.53      0.56      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3205    2]\n",
      " [  54    4]]\n",
      "22\n",
      "0.6020234032179425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3209\n",
      "         1.0       0.32      0.16      0.21        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.58      0.60      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3190   19]\n",
      " [  47    9]]\n",
      "23\n",
      "0.5825454398632598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3215\n",
      "         1.0       0.32      0.12      0.17        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.56      0.58      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3202   13]\n",
      " [  44    6]]\n",
      "24\n",
      "0.5379035824856258\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3206\n",
      "         1.0       0.27      0.05      0.09        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.63      0.52      0.54      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3198    8]\n",
      " [  56    3]]\n",
      "25\n",
      "0.6131117980422462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.64      0.14      0.23        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.81      0.57      0.61      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3212    4]\n",
      " [  42    7]]\n",
      "26\n",
      "0.5129150505093559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3212\n",
      "         1.0       0.20      0.02      0.03        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.59      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3208    4]\n",
      " [  52    1]]\n",
      "27\n",
      "0.5852972488632191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3213\n",
      "         1.0       0.40      0.12      0.18        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.56      0.59      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3204    9]\n",
      " [  46    6]]\n",
      "28\n",
      "0.5945733624929994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.50      0.12      0.20        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.56      0.59      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3210    6]\n",
      " [  43    6]]\n",
      "29\n",
      "0.5840888332371172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3227\n",
      "         1.0       0.26      0.13      0.18        38\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.63      0.56      0.58      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3213   14]\n",
      " [  33    5]]\n",
      "30\n",
      "0.5423900015465511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3216\n",
      "         1.0       0.20      0.06      0.09        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.59      0.53      0.54      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3204   12]\n",
      " [  46    3]]\n",
      "31\n",
      "0.5910201846300843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3225\n",
      "         1.0       0.38      0.12      0.19        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.69      0.56      0.59      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3217    8]\n",
      " [  35    5]]\n",
      "32\n",
      "0.5393203706738033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3212\n",
      "         1.0       0.20      0.06      0.09        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.59      0.53      0.54      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3200   12]\n",
      " [  50    3]]\n",
      "33\n",
      "0.5592397053661937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.22      0.09      0.13        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.60      0.54      0.56      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3206   14]\n",
      " [  41    4]]\n",
      "34\n",
      "0.6051752266309687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.50      0.14      0.22        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.74      0.57      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3200    8]\n",
      " [  49    8]]\n",
      "35\n",
      "0.5066901608817395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3190\n",
      "         1.0       0.25      0.01      0.03        75\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.61      0.51      0.51      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n",
      "[[3187    3]\n",
      " [  74    1]]\n",
      "36\n",
      "0.615457448945894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3224\n",
      "         1.0       0.31      0.20      0.24        41\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.59      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3206   18]\n",
      " [  33    8]]\n",
      "37\n",
      "0.5767592592592593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3222\n",
      "         1.0       0.57      0.09      0.16        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.78      0.55      0.58      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3219    3]\n",
      " [  39    4]]\n",
      "38\n",
      "0.6073226465989725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3225\n",
      "         1.0       0.30      0.17      0.22        40\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.59      0.61      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3209   16]\n",
      " [  33    7]]\n",
      "39\n",
      "0.5532503830115588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3215\n",
      "         1.0       0.21      0.08      0.12        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.60      0.54      0.55      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3200   15]\n",
      " [  46    4]]\n",
      "40\n",
      "0.5234630694383016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3201\n",
      "         1.0       0.33      0.03      0.06        64\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.52      0.52      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3197    4]\n",
      " [  62    2]]\n",
      "41\n",
      "0.5158263953829719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3218\n",
      "         1.0       0.25      0.02      0.04        47\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.62      0.51      0.52      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3215    3]\n",
      " [  46    1]]\n",
      "42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5372217824675254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3213\n",
      "         1.0       0.16      0.06      0.08        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.57      0.53      0.54      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3197   16]\n",
      " [  49    3]]\n",
      "43\n",
      "0.5987629034900868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3218\n",
      "         1.0       0.33      0.15      0.21        47\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.57      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3204   14]\n",
      " [  40    7]]\n",
      "44\n",
      "0.5651027236690678\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.40      0.08      0.14        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.54      0.57      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3211    6]\n",
      " [  44    4]]\n",
      "45\n",
      "0.5927316678710299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.47      0.12      0.19        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.73      0.56      0.59      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3200    8]\n",
      " [  50    7]]\n",
      "46\n",
      "0.4958307597282273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3214\n",
      "         1.0       0.00      0.00      0.00        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3211    3]\n",
      " [  51    0]]\n",
      "47\n",
      "0.6245466607695709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.41      0.19      0.26        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.59      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3204   13]\n",
      " [  39    9]]\n",
      "48\n",
      "0.5762793462607589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3212\n",
      "         1.0       0.29      0.11      0.16        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.55      0.58      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3197   15]\n",
      " [  47    6]]\n",
      "49\n",
      "0.5651027236690678\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3214\n",
      "         1.0       0.57      0.08      0.14        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.78      0.54      0.57      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3211    3]\n",
      " [  47    4]]\n",
      "GradientBoost\n",
      "0\n",
      "0.4958307597282273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3211\n",
      "         1.0       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3211    0]\n",
      " [  54    0]]\n",
      "1\n",
      "0.4955970956279932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3208    0]\n",
      " [  57    0]]\n",
      "2\n",
      "0.49645280690931526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3219\n",
      "         1.0       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3219    0]\n",
      " [  46    0]]\n",
      "3\n",
      "0.4956750077232005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3209\n",
      "         1.0       0.00      0.00      0.00        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3209    0]\n",
      " [  56    0]]\n",
      "4\n",
      "0.4955970956279932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3208    0]\n",
      " [  57    0]]\n",
      "5\n",
      "0.4958307597282273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3211\n",
      "         1.0       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3211    0]\n",
      " [  54    0]]\n",
      "6\n",
      "0.4969958403943922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3226\n",
      "         1.0       0.00      0.00      0.00        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3226    0]\n",
      " [  39    0]]\n",
      "7\n",
      "0.49544119919641477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3206\n",
      "         1.0       0.00      0.00      0.00        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3206    0]\n",
      " [  59    0]]\n",
      "8\n",
      "0.49551915945611863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.00      0.00      0.00        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n",
      "[[3207    0]\n",
      " [  58    0]]\n",
      "9\n",
      "0.4958307597282273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3211\n",
      "         1.0       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3211    0]\n",
      " [  54    0]]\n",
      "10\n",
      "0.4955970956279932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3208    0]\n",
      " [  57    0]]\n",
      "11\n",
      "0.4955970956279932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3208    0]\n",
      " [  57    0]]\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4963751349683788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3218\n",
      "         1.0       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3218    0]\n",
      " [  47    0]]\n",
      "13\n",
      "0.49528520636883594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3204\n",
      "         1.0       0.00      0.00      0.00        61\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n",
      "[[3204    0]\n",
      " [  61    0]]\n",
      "14\n",
      "0.4966080789392538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3221\n",
      "         1.0       0.00      0.00      0.00        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3221    0]\n",
      " [  44    0]]\n",
      "15\n",
      "0.4963751349683788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3218\n",
      "         1.0       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3218    0]\n",
      " [  47    0]]\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4951291170558218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3202\n",
      "         1.0       0.00      0.00      0.00        63\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n",
      "[[3202    0]\n",
      " [  63    0]]\n",
      "17\n",
      "0.4956750077232005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3209\n",
      "         1.0       0.00      0.00      0.00        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3209    0]\n",
      " [  56    0]]\n",
      "18\n",
      "0.4957528957528958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3210\n",
      "         1.0       0.00      0.00      0.00        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3210    0]\n",
      " [  55    0]]\n",
      "19\n",
      "0.49466026930815665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3196\n",
      "         1.0       0.00      0.00      0.00        69\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.49      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n",
      "[[3196    0]\n",
      " [  69    0]]\n",
      "20\n",
      "0.4962974390620179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.00      0.00      0.00        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3217    0]\n",
      " [  48    0]]\n",
      "21\n",
      "0.49590859966033657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3212\n",
      "         1.0       0.00      0.00      0.00        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3212    0]\n",
      " [  53    0]]\n",
      "22\n",
      "0.4962974390620179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.00      0.00      0.00        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3217    0]\n",
      " [  48    0]]\n",
      "23\n",
      "0.4960642074394197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3214\n",
      "         1.0       0.00      0.00      0.00        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3214    0]\n",
      " [  51    0]]\n",
      "24\n",
      "0.49653045489591363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.00      0.00      0.00        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3220    0]\n",
      " [  45    0]]\n",
      "25\n",
      "0.4959864155603581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3213\n",
      "         1.0       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3213    0]\n",
      " [  52    0]]\n",
      "26\n",
      "0.49536321483771256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3205\n",
      "         1.0       0.00      0.00      0.00        60\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n",
      "[[3205    0]\n",
      " [  60    0]]\n",
      "27\n",
      "0.49505103618929786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3201\n",
      "         1.0       0.00      0.00      0.00        64\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n",
      "[[3201    0]\n",
      " [  64    0]]\n",
      "28\n",
      "0.49520717377860235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3203\n",
      "         1.0       0.00      0.00      0.00        62\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3203    0]\n",
      " [  62    0]]\n",
      "29\n",
      "0.4966856790504085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3222\n",
      "         1.0       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3222    0]\n",
      " [  43    0]]\n",
      "30\n",
      "0.4956750077232005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3209\n",
      "         1.0       0.00      0.00      0.00        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3209    0]\n",
      " [  56    0]]\n",
      "31\n",
      "0.4957528957528958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3210\n",
      "         1.0       0.00      0.00      0.00        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3210    0]\n",
      " [  55    0]]\n",
      "32\n",
      "0.49614197530864196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3215\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3215    0]\n",
      " [  50    0]]\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49505103618929786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3201\n",
      "         1.0       0.00      0.00      0.00        64\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n",
      "[[3201    0]\n",
      " [  64    0]]\n",
      "34\n",
      "0.496219719179139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3216\n",
      "         1.0       0.00      0.00      0.00        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3216    0]\n",
      " [  49    0]]\n",
      "35\n",
      "0.49520717377860235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3203\n",
      "         1.0       0.00      0.00      0.00        62\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n",
      "[[3203    0]\n",
      " [  62    0]]\n",
      "36\n",
      "0.4962974390620179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.00      0.00      0.00        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3217    0]\n",
      " [  48    0]]\n",
      "37\n",
      "0.4955970956279932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3208    0]\n",
      " [  57    0]]\n",
      "38\n",
      "0.4963751349683788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3218\n",
      "         1.0       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3218    0]\n",
      " [  47    0]]\n",
      "39\n",
      "0.4959864155603581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3213\n",
      "         1.0       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3213    0]\n",
      " [  52    0]]\n",
      "40\n",
      "0.4957528957528958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3210\n",
      "         1.0       0.00      0.00      0.00        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3210    0]\n",
      " [  55    0]]\n",
      "41\n",
      "0.49653045489591363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3220\n",
      "         1.0       0.00      0.00      0.00        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3220    0]\n",
      " [  45    0]]\n",
      "42\n",
      "0.4962974390620179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3217\n",
      "         1.0       0.00      0.00      0.00        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3217    0]\n",
      " [  48    0]]\n",
      "43\n",
      "0.49528520636883594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3204\n",
      "         1.0       0.00      0.00      0.00        61\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.96      0.98      0.97      3265\n",
      "\n",
      "[[3204    0]\n",
      " [  61    0]]\n",
      "44\n",
      "0.4959864155603581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3213\n",
      "         1.0       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3213    0]\n",
      " [  52    0]]\n",
      "45\n",
      "0.4959864155603581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3213\n",
      "         1.0       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3213    0]\n",
      " [  52    0]]\n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4970733210104744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3227\n",
      "         1.0       0.00      0.00      0.00        38\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3227    0]\n",
      " [  38    0]]\n",
      "47\n",
      "0.49645280690931526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3219\n",
      "         1.0       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3219    0]\n",
      " [  46    0]]\n",
      "48\n",
      "0.49645280690931526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3219\n",
      "         1.0       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.99      0.98      3265\n",
      "\n",
      "[[3219    0]\n",
      " [  46    0]]\n",
      "49\n",
      "0.4960642074394197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3214\n",
      "         1.0       0.00      0.00      0.00        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3214    0]\n",
      " [  51    0]]\n",
      "QDA\n",
      "0\n",
      "0.6847319497373571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      3208\n",
      "         1.0       0.31      0.49      0.38        57\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.65      0.74      0.68      3265\n",
      "weighted avg       0.98      0.97      0.98      3265\n",
      "\n",
      "[[3147   61]\n",
      " [  29   28]]\n",
      "1\n",
      "0.6472034253143698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3220\n",
      "         1.0       0.30      0.31      0.30        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.65      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3187   33]\n",
      " [  31   14]]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7072934949909541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      3206\n",
      "         1.0       0.36      0.53      0.43        59\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.68      0.75      0.71      3265\n",
      "weighted avg       0.98      0.97      0.98      3265\n",
      "\n",
      "[[3151   55]\n",
      " [  28   31]]\n",
      "3\n",
      "0.5532503830115587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3210\n",
      "         1.0       0.29      0.07      0.12        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.53      0.55      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3200   10]\n",
      " [  51    4]]\n",
      "4\n",
      "0.510512225593432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3215\n",
      "         1.0       0.07      0.02      0.03        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.53      0.51      0.51      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3201   14]\n",
      " [  49    1]]\n",
      "5\n",
      "0.6545704612780364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      3212\n",
      "         1.0       0.27      0.42      0.32        53\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.63      0.70      0.65      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3151   61]\n",
      " [  31   22]]\n",
      "6\n",
      "0.5372217824675254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.23      0.05      0.08        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.61      0.52      0.54      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3197   10]\n",
      " [  55    3]]\n",
      "7\n",
      "0.6486534901388684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.95      0.97      3209\n",
      "         1.0       0.21      0.71      0.32        56\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      3265\n",
      "   macro avg       0.60      0.83      0.65      3265\n",
      "weighted avg       0.98      0.95      0.96      3265\n",
      "\n",
      "[[3058  151]\n",
      " [  16   40]]\n",
      "8\n",
      "0.6713031342355276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3211\n",
      "         1.0       0.34      0.37      0.35        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.68      0.67      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3172   39]\n",
      " [  34   20]]\n",
      "9\n",
      "0.6031038534786661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3220\n",
      "         1.0       0.21      0.22      0.22        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.60      0.61      0.60      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3183   37]\n",
      " [  35   10]]\n",
      "10\n",
      "0.653292347070351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3209\n",
      "         1.0       0.32      0.32      0.32        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.65      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3170   39]\n",
      " [  38   18]]\n",
      "11\n",
      "0.6383594566353187\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      3212\n",
      "         1.0       0.23      0.42      0.29        53\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.61      0.70      0.64      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3137   75]\n",
      " [  31   22]]\n",
      "12\n",
      "0.6759604980049546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      3200\n",
      "         1.0       0.31      0.46      0.37        65\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.65      0.72      0.68      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3132   68]\n",
      " [  35   30]]\n",
      "13\n",
      "0.6544577420691966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      3216\n",
      "         1.0       0.25      0.47      0.32        49\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.62      0.72      0.65      3265\n",
      "weighted avg       0.98      0.97      0.98      3265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3146   70]\n",
      " [  26   23]]\n",
      "14\n",
      "0.6760541331898718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      3204\n",
      "         1.0       0.32      0.43      0.37        61\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.65      0.70      0.68      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3149   55]\n",
      " [  35   26]]\n",
      "15\n",
      "0.6471553341782349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3207\n",
      "         1.0       0.32      0.29      0.31        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.64      0.65      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3171   36]\n",
      " [  41   17]]\n",
      "16\n",
      "0.5317635658914729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3206\n",
      "         1.0       0.14      0.05      0.08        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.56      0.52      0.53      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3188   18]\n",
      " [  56    3]]\n",
      "17\n",
      "0.6936669272869429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      3212\n",
      "         1.0       0.33      0.51      0.40        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.66      0.75      0.69      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3157   55]\n",
      " [  26   27]]\n",
      "18\n",
      "0.5423900015465511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3222\n",
      "         1.0       0.14      0.07      0.09        43\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.57      0.53      0.54      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3204   18]\n",
      " [  40    3]]\n",
      "19\n",
      "0.6047933184046481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3207\n",
      "         1.0       0.38      0.16      0.22        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.68      0.58      0.60      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3192   15]\n",
      " [  49    9]]\n",
      "20\n",
      "0.6506866245030319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      3212\n",
      "         1.0       0.27      0.38      0.31        53\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.63      0.68      0.65      3265\n",
      "weighted avg       0.98      0.97      0.98      3265\n",
      "\n",
      "[[3158   54]\n",
      " [  33   20]]\n",
      "21\n",
      "0.6814825088357912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      3207\n",
      "         1.0       0.33      0.43      0.38        58\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.66      0.71      0.68      3265\n",
      "weighted avg       0.98      0.97      0.98      3265\n",
      "\n",
      "[[3157   50]\n",
      " [  33   25]]\n",
      "22\n",
      "0.6395517856814292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      3209\n",
      "         1.0       0.25      0.36      0.29        56\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.62      0.67      0.64      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3149   60]\n",
      " [  36   20]]\n",
      "23\n",
      "0.6491252310507667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98      3218\n",
      "         1.0       0.21      0.70      0.32        47\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3265\n",
      "   macro avg       0.60      0.83      0.65      3265\n",
      "weighted avg       0.98      0.96      0.97      3265\n",
      "\n",
      "[[3092  126]\n",
      " [  14   33]]\n",
      "24\n",
      "0.5291653356455073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3210\n",
      "         1.0       0.10      0.05      0.07        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.54      0.52      0.53      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3183   27]\n",
      " [  52    3]]\n",
      "25\n",
      "0.5937258910846548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3214\n",
      "         1.0       0.27      0.16      0.20        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.63      0.58      0.59      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3192   22]\n",
      " [  43    8]]\n",
      "26\n",
      "0.6708465165332838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      3209\n",
      "         1.0       0.27      0.52      0.36        56\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.63      0.75      0.67      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3132   77]\n",
      " [  27   29]]\n",
      "27\n",
      "0.5359077225311386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3213\n",
      "         1.0       0.14      0.06      0.08        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.56      0.53      0.54      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3195   18]\n",
      " [  49    3]]\n",
      "28\n",
      "0.5392452936693856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3210\n",
      "         1.0       0.12      0.07      0.09        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.55      0.53      0.54      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3181   29]\n",
      " [  51    4]]\n",
      "29\n",
      "0.62754028847438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3208\n",
      "         1.0       0.27      0.26      0.27        57\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.63      0.63      0.63      3265\n",
      "weighted avg       0.97      0.97      0.97      3265\n",
      "\n",
      "[[3168   40]\n",
      " [  42   15]]\n",
      "30\n",
      "0.6251536393965179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3216\n",
      "         1.0       0.28      0.24      0.26        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.63      0.62      0.63      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3185   31]\n",
      " [  37   12]]\n",
      "31\n",
      "0.66207979907634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      3211\n",
      "         1.0       0.28      0.43      0.34        54\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.64      0.70      0.66      3265\n",
      "weighted avg       0.98      0.97      0.98      3265\n",
      "\n",
      "[[3152   59]\n",
      " [  31   23]]\n",
      "32\n",
      "0.6758110044114101\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      3223\n",
      "         1.0       0.28      0.52      0.36        42\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.75      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3166   57]\n",
      " [  20   22]]\n",
      "33\n",
      "0.49512911705582185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3211\n",
      "         1.0       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.50      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3202    9]\n",
      " [  54    0]]\n",
      "34\n",
      "0.6744633949628278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      3204\n",
      "         1.0       0.30      0.48      0.36        61\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.64      0.73      0.67      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3135   69]\n",
      " [  32   29]]\n",
      "35\n",
      "0.6124064264146375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      3212\n",
      "         1.0       0.20      0.30      0.24        53\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.59      0.64      0.61      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3148   64]\n",
      " [  37   16]]\n",
      "36\n",
      "0.6485509447394813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      3215\n",
      "         1.0       0.24      0.46      0.31        50\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.61      0.72      0.65      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3141   74]\n",
      " [  27   23]]\n",
      "37\n",
      "0.622009344052242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3210\n",
      "         1.0       0.42      0.18      0.25        55\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.59      0.62      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3196   14]\n",
      " [  45   10]]\n",
      "38\n",
      "0.6534276868642194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3224\n",
      "         1.0       0.38      0.27      0.31        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3265\n",
      "   macro avg       0.69      0.63      0.65      3265\n",
      "weighted avg       0.98      0.99      0.98      3265\n",
      "\n",
      "[[3206   18]\n",
      " [  30   11]]\n",
      "39\n",
      "0.6785393681406191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      3204\n",
      "         1.0       0.34      0.41      0.37        61\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.66      0.70      0.68      3265\n",
      "weighted avg       0.98      0.97      0.98      3265\n",
      "\n",
      "[[3155   49]\n",
      " [  36   25]]\n",
      "40\n",
      "0.7017564463931517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      3211\n",
      "         1.0       0.33      0.56      0.42        54\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.66      0.77      0.70      3265\n",
      "weighted avg       0.98      0.97      0.98      3265\n",
      "\n",
      "[[3151   60]\n",
      " [  24   30]]\n",
      "41\n",
      "0.6401972286180442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3211\n",
      "         1.0       0.22      0.44      0.30        54\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.61      0.71      0.64      3265\n",
      "weighted avg       0.98      0.97      0.97      3265\n",
      "\n",
      "[[3128   83]\n",
      " [  30   24]]\n",
      "42\n",
      "0.6722651797741166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3225\n",
      "         1.0       0.30      0.42      0.35        40\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.65      0.71      0.67      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3186   39]\n",
      " [  23   17]]\n",
      "43\n",
      "0.568724407459095\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3209\n",
      "         1.0       0.24      0.11      0.15        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.61      0.55      0.57      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3190   19]\n",
      " [  50    6]]\n",
      "44\n",
      "0.49458204334365324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3208\n",
      "         1.0       0.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.49      0.50      0.49      3265\n",
      "weighted avg       0.97      0.98      0.97      3265\n",
      "\n",
      "[[3195   13]\n",
      " [  57    0]]\n",
      "45\n",
      "0.6164540666489853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      3207\n",
      "         1.0       0.23      0.28      0.25        58\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3265\n",
      "   macro avg       0.61      0.63      0.62      3265\n",
      "weighted avg       0.97      0.97      0.97      3265\n",
      "\n",
      "[[3152   55]\n",
      " [  42   16]]\n",
      "46\n",
      "0.7007032262852104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3214\n",
      "         1.0       0.39      0.43      0.41        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.69      0.71      0.70      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3180   34]\n",
      " [  29   22]]\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6155959342255013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3206\n",
      "         1.0       0.42      0.17      0.24        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.70      0.58      0.62      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3192   14]\n",
      " [  49   10]]\n",
      "48\n",
      "0.6778329430132709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3206\n",
      "         1.0       0.35      0.39      0.37        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.67      0.69      0.68      3265\n",
      "weighted avg       0.98      0.98      0.98      3265\n",
      "\n",
      "[[3163   43]\n",
      " [  36   23]]\n",
      "49\n",
      "0.5968396319607124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3208\n",
      "         1.0       0.29      0.16      0.20        57\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3265\n",
      "   macro avg       0.64      0.58      0.60      3265\n",
      "weighted avg       0.97      0.98      0.98      3265\n",
      "\n",
      "[[3186   22]\n",
      " [  48    9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1944x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = .02  # step size in the mesh\n",
    "maxiteration = 50\n",
    "\n",
    "names = [\"Nearest Neighbors\", \n",
    "         \"LogisticRegression\",\n",
    "         \"SGD\",\n",
    "         #\"Linear SVM\", \n",
    "         \"RBF SVM\", \n",
    "         #\"Gaussian Process\",\n",
    "         \"Decision Tree\", \n",
    "         #\"Random Forest\", \n",
    "         #\"Neural Net\", \n",
    "         \"AdaBoost\",\n",
    "         \"Naive Bayes\",\n",
    "         \"XGBoost\",\n",
    "         \"GradientBoost\",\n",
    "         \"QDA\"]\n",
    "\n",
    "classifiers = [ \n",
    "    KNeighborsClassifier(2),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(penalty='l1', alpha=0.001, loss='squared_hinge'),\n",
    "    #SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(min_samples_split=90, max_depth=9),\n",
    "    #RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    #MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(n_estimators=100, learning_rate=1),\n",
    "    GaussianNB(),\n",
    "    xgb.XGBClassifier(random_state=1,learning_rate=0.01, subsample= 0.8, colsample_bytree= 1.0, max_depth= 5, gamma=1.5, \n",
    "                      min_child_weight= 1),\n",
    "    GradientBoostingClassifier(learning_rate=0.01,random_state=1, loss='deviance', min_samples_leaf= 0.1, \n",
    "                               n_estimators= 10, min_samples_split= 0.1, max_features='log2', max_depth= 3),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "\n",
    "datasets = [[data1[col], data1[u\"执行反吹左侧\"]]]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 5))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "    cv_scores = {\"name\": [], \"test_score\": []}\n",
    "    order = []\n",
    "    \n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "\n",
    "        print(name)\n",
    "        order.append(name)\n",
    "        #ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        \n",
    "        for j in range(maxiteration):\n",
    "            print(j)\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=.2)\n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            #score = clf.score(X_test, y_test)\n",
    "            \n",
    "            #X_test = StandardScaler().fit_transform(X_test)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            score = f1_score(y_test, y_pred, average='macro')\n",
    "            print(score)\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "            cv_scores[\"name\"].append(name)\n",
    "            cv_scores[\"test_score\"].append(score)\n",
    "            \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2515544472980943\n",
      "{'penalty': 'none', 'alpha': 0.001, 'loss': 'squared_hinge'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "    \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"penalty\" : [\"l2\", \"l1\", \"none\"],\n",
    "}\n",
    "\n",
    "model = SGDClassifier(max_iter=1000)\n",
    "clf = GridSearchCV(model, param_grid=params, cv=3, n_jobs=-1,scoring='f1')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3569388486426744\n",
      "{'min_samples_split': 10, 'max_depth': 17}\n"
     ]
    }
   ],
   "source": [
    "parameters={'min_samples_split' : range(10,500,20),'max_depth': range(1,20,2)}\n",
    "clf_tree=DecisionTreeClassifier()\n",
    "clf=GridSearchCV(clf_tree, parameters, cv=3, n_jobs=-1, scoring='f1')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26672539906511433\n",
      "{'n_estimators': 50, 'learning_rate': 1}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    " 'n_estimators': [16, 32, 50, 100],\n",
    " 'learning_rate' : [0.01,0.05,0.1,0.3,1],\n",
    " }\n",
    "clf_ada = AdaBoostClassifier()\n",
    "clf=GridSearchCV(clf_ada, parameters, cv=3, n_jobs=-1, scoring='f1')\n",
    "\n",
    "y_train = y_train.rename(\"ResultRight\")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 864 candidates, totalling 2592 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 456 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 904 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1480 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2184 tasks      | elapsed:   14.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "{'loss': 'deviance', 'min_samples_leaf': 0.1, 'n_estimators': 10, 'min_samples_split': 0.1, 'max_features': 'log2', 'max_depth': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2592 out of 2592 | elapsed:   15.9s finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    #\"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    #\"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    #\"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "    }\n",
    "\n",
    "clf_gbc = GradientBoostingClassifier()\n",
    "clf=GridSearchCV(clf_gbc, parameters, cv=3, n_jobs=-1, scoring='f1',verbose=3)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 405 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 472 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 760 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1112 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1215 out of 1215 | elapsed:   34.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2763768139868101\n",
      "{'subsample': 0.6, 'colsample_bytree': 1.0, 'max_depth': 5, 'gamma': 1, 'min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "clf_xgb = xgb.XGBClassifier()\n",
    "clf=GridSearchCV(clf_xgb, parameters, cv=3, n_jobs=-1, scoring='f1',verbose=3)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqMAAAHKCAYAAAA3jEJnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3Xt0VPW9///nJwmES0ACAUQCRgy3ahUBkbZWaREUa72h1ltPqLXWn5X4LR5/llWP4qV4dGntCbX9ShXMolbPz9uRU0kFK7jQyl1AQSLhPlyTEDBAgCTz+f3xmWEmISEzITs7mbwea82aPfvy2e9BJO+89+dirLWIiIiIiPghye8ARERERKTtUjIqIiIiIr5RMioiIiIivlEyKiIiIiK+UTIqIiIiIr5RMioiIiIivlEyKiIiIiK+UTIqIiIiIr5RMioiIiIivknxO4CmlJGRYbOysvwOQ0RERKTNW7lyZYm1tmdD5yVUMpqVlcWKFSv8DkNERESkzTPGbIvlPD2mFxERERHfKBkVEREREd8oGRURERER3ygZFRERERHfKBkVEREREd8oGRURERER3ygZFRERERHfKBkVEREREd8oGRURERER3ygZFRERERHfKBkVEREREd8oGRURERER36T4HYCIX/Ly8igqKor5/EAgAEBmZmZc98nOziY3Nzeua0RERNoKJaMiMaqoqPA7BBERkYSjZFTarHirleHz8/LyvAhHRESkTVKfURERERHxjZJREREREfGNklERERER8Y2SURERERHxjZJREREREfGNklERERER8Y2SURERERHxjZJREREREfGNklERERER8Y2SURERERHxjZJREREREfGNklERERER8Y2SURERERHxjZJREREREfGNklERERER8Y2SURERERHxjZJREREREfGNklERERER8Y2SURERERHxjZJREREREfGNklERERER8Y2SURERERHxTYrfAYiIeC0vL4+ioqKYzw8EAgBkZmbGfE12dja5ublxxyYi0tYpGRURqaWiosLvEERE2gwloyKS8OKtWIbPz8vL8yIcERGJoj6jIiIiIuIbJaMiIiIi4hsloyIiIiLiGyWjIiIiIuIbJaMiIiIi4hsloyIiIiLiG03tJCIiItIKJOoCHkpGRURERBJQa1nAQ8moiIiISCuQqAt4qM+oiIiIiPhGyaiIiIiI+EbJqIiIiIj4RsmoiIiIiPjG02TUGHOVMabQGFNkjPlNHcdfMMasDr2+NsYciDqWY4zZGHrleBmniIiIiPjDs9H0xphk4EVgHBAAlhtj5lpr14fPsdb+Our8ycBFoe3uwGPASMACK0PXlnkVr4iIiIg0Py8ro6OAImvtZmvtceAN4LpTnH8b8Hpo+0pggbV2fygBXQBc5WGsIiIiIuIDL5PRvsCOqM+B0L6TGGPOBs4BPmrEtfcYY1YYY1YUFxefdtAiIiIi0ny8TEZNHftsPefeCrxlra2O91pr7Uxr7Uhr7ciePXs2IkwRERER8YuXyWgA6Bf1ORPYVc+5txJ5RB/vtSIiIiLSSnmZjC4HBhpjzjHGtMclnHNrn2SMGQykA59F7f4AGG+MSTfGpAPjQ/tEREREJIF4NpreWltljLkfl0QmA7OsteuMMU8AK6y14cT0NuANa62Nuna/MeZJXEIL8IS1dr9XsYqIiIiIPzxLRgGstfOAebX2PVrr87R6rp0FzPIsOBERERHxnVZgEhERERHfeFoZFRERf+Tl5VFUVBTz+YFAAIDMzMy47pOdnU1ubm5c14iIRFMyKiIiVFRU+B2CiLRRSkZFRBJQvNXK8Pl5eXlehCMiUi8loyIikjCao3uCuiaINC0loyIi0mape4KI/5SMiohIwlD3BJHWR1M7iYiIiIhvlIyKiIiIiG+UjIqIiIiIb5SMioiIiIhvlIyKiIiIiG+UjIqIiIiIb5SMioiIiIhvlIyKiIiIiG+UjIqIiIiIb5SMioiIiIhvlIyKiIiIiG+UjIqIiIiIb5SMioiIiIhvlIyKiIiIiG+UjIqIiIiIb5SMioiIiIhvlIyKiIiIiG+UjIqIiIiIb5SMioiIiIhvlIyKiIiIiG9S/A5ApKnk5eVRVFTkWfsbN24EIDc317N7AGRnZ3t+DxERkZZCyagkjKKiIj5f9zl08+gGQff2+c7PPboBcMC7pkVEpOXwuoACraeIomRUEks3CI4J+h1FoyUtUs8ZEZG2oKioiM/Xf0V1z96e3SMp1BtzRfF+z+6RXLz3tNtQMioiIiLig+qevTk88ad+h3FaOr8957TbUBlGRERERHyjZFREREREfKNkVERERER8o2RURERERHyjAUy1NGaqhUAgAEBmZmbM12guSRERERElo02ioqLC7xBEREREWiUlo7U0ploZviYvL6+pwxERERFJaOozKiIiIiK+UWVURFodr5fRay1L6ImIJAIloyLS6hQVFbHui6/o1qmXJ+0HjxsAdm4q9aR9gANH9nnWtohIa6JkVERapW6devGDIbf6HUajLdzwht8hiIi0COozKiIiIiK+UTIqIiIiIr5RMioiIiIivlEyKiIiIiK+UTIqIiIiIr5RMioiIiIivlEyKiIiIiK+UTIqIiIiIr5RMioiIiIivlEyKiIiIiK+8TQZNcZcZYwpNMYUGWN+U885txhj1htj1hlj/ha1v9oYszr0mutlnCIiIiLiD8/WpjfGJAMvAuOAALDcGDPXWrs+6pyBwFTge9baMmNMr6gmKqy1w7yKT0RERET852VldBRQZK3dbK09DrwBXFfrnF8AL1prywCstfs8jEdEREREWhgvk9G+wI6oz4HQvmiDgEHGmE+NMUuMMVdFHetgjFkR2n+9h3GKiIiIiE88e0wPmDr22TruPxAYA2QCi40x51trDwD9rbW7jDEDgI+MMV9YazeddBNj7gHuAejfv39Txi8iIiIiHvMyGQ0A/aI+ZwK76jhnibW2EthijCnEJafLrbW7AKy1m40xi4CLgJOSUWvtTGAmwMiRI2snuyIiCSEvL4+ioiLP2t+4cSMAubm5nt0DIDs72/N7iEjr4mUyuhwYaIw5B9gJ3ArcXuuc/wFuA141xmTgHttvNsakA0estcdC+78HPOthrCIiLVpRURFfrllDl/be/LNdVVUNwLav1nnSPkD58SrP2hZpbQKBAMnflNP57Tl+h3Jakov3Ejh25LTa8CwZtdZWGWPuBz4AkoFZ1tp1xpgngBXW2rmhY+ONMeuBauAha22pMea7wEvGmCCuX+t/Ro/CFxFpi7q0T2FU73S/w2i0ZXvL/A5BRFogLyujWGvnAfNq7Xs0atsCU0Kv6HP+BXzby9hE4hU0QSo6VtCxoiNJVutFiIhI42VmZrKneD+HJ/7U71BOS+e355DZs/tptaGfqCIxOtb+GNXJ1Rxrf8zvUERERBKGp5VRkeYUCATgICQtavrfsYKpQSqvqAQDlSmVdFzUkaRjHvwudwACNtD07YqIiLRQSkZFYnB00NGTPnf6opNP0Yi0DV7PIADNM4uAZhAQOTUlo5IwMjMzKTbFBMcEm7TdoAlyPO14ZObcZDiedZz2Ge2bvO9o0qIkMvtmNmmbIq1VUVERhV9+Rb8uZ3p2j3ZV7v/hI9u8GVy1o3yPJ+2KJBIloyINqK+P6LH2x+h4rGMzRyPStvTrciYPjvqZ32E02vPLZvsdgkiLpwFMIg2oTqk+eT0xE9ovIiIip0WVUZEGpB1O8zsEERGRhKXKqIiIiIj4RsmoiIiIiPhGyaiIiIiI+EbJqIhILYdTvmHugJkcSSn3OxQRkYSnAUwi0uoEAgEOHiln4YY3PGl/7/AABzvvZ277mfT+sq8n9zhwZB82UBHz+YFAgPLjVSzb6818mM2h/HiVWylNRCSKKqMiIlGqOlTyTVYZGPgmaz9VHSr9DklEJKGpMioirU5mZibmWCk/GHJrk7e9+Kz3MElJWKoxSUl0+G5Xvr/ruia/z8INb9A3s0fM52dmZlJdfpBRvdObPJbmsmxvGZmZWmFMRGpSZVREJORwyjcUdl9JMMktaBBMqqaw+0r1HRUR8VCDyahx7jTGPBr63N8YM8r70EREmteqXgux2Br7LJaVvT7yKaLmU9G+in+O2E5F+yq/QxGRNiaWyuifgO8At4U+lwMvehaRiIhP9nbefqIqGhZMqmZv5+0+RdR81g0ooTi9gnUDSvwORUTamFj6jF5irR1ujPkcwFpbZoxp73FcIiLN7qaNk/0OwRcV7avYctY3YGDLWd9w3uYMOh7XkAIRaR6xVEYrjTHJ4J5dGWN6AkFPoxIRkWazbkDJie4JFqvqqIg0q1iS0TzgXaCXMeZ3wCfAdE+jEhGRZhGuigaT3edgsquOqu+oiDSXBp/DWGtfM8asBMYCBrjeWvuV55GJiIjnoquiYeHq6MgNZ/oUlYi0JadMRo0xScBaa+35wIbmCUlERJpLyRlHT1RFw4LJbr+ISHM4ZTJqrQ0aY9YYY/pbaxN/OKmISBtz1dIsv0MQEY/Y4DfYY3/FpN6JSerqdzj1imW4ZB9gnTFmGXA4vNNae61nUYmIiIjIabGVCyC4BVv5ISb1Rr/DqVcsyejjnkchIiIiIk3GBr+BquWAharl2HZXtNjqaCwDmD42xvQGLg7tWmat3edtWCIiIt4rSzrIH7rn8+v9k+gWbJk/qBuSl5dHUVFRzOcHAgEAMjMzY74mOzub3NzcuGMT/9jKBXBicGKwRVdHY1kO9BZgGXAzcAuw1Bhzk9eBiYiIeO3trh+wIXUzb3X9h9+hNJuKigoqKir8DkM8FKmKhleUq3bV0eA3foZVr1ge0/8WuDhcDQ1Nev8h8JaXgYmIiHipLOkgCzsvwxrLok7LuOmbq1pldTTeimX4/Ly8PC/CkRagZlU0rOVWR2OZ9D6p1mP50hivE5EEUFJSwuTJkyktLfU7FJEm9XbXD7ChBQWDJtimqqOS4Kq3EamKntgJ1Vt9CKZhsVRG/2GM+QB4PfT5J0CBdyGJSEuSn5/P2rVryc/PZ8qUKX6HI9IkwlXRKuN+YFeZ6lZdHRWJltSpdf1b3WCF01r7EPAScAFwITDTWvv/eh2YiPivpKSEgoICrLUUFBSoOioJI7oqGqbqqIg/GqyMGmPOAeZZa98Jfe5ojMmy1m71OjgR8Vd+fj7Wun5HwWBQ1VFpVoFAgMPl5Ty/bHaTt/3FDzecqIqGVZlqPqlaycFlh+u5Kn47yvfQOdB07Ykkolge078JfDfqc3Vo38V1ny4iiWLBggVUVlYCUFlZyfz585WMSkL49kdD/A5BREJiSUZTrLXHwx+stceNMe09jElEWohx48Yxb948KisradeuHePHj/c7JGlDMjMzOVJdxoOjfuZ3KI32/LLZdMpM9zsMkRYtlmS02BhzrbV2LoAx5jqgxNuwRBrpACQt8miyh0Oh9zRvmgfgANDXw/bjlJOTQ0GBG6+YlJRETk6OzxGJiEiiiSUZvRd4zRjzR8AAO4B/8zQqkUbIzs72tP2NGzcCMLDvQO9u0tf77xGPjIwMJkyYwNy5c5kwYQI9evTwOyQREUkwsSwHugkYbYxJA4y1ttz7sETi5/VSdW11ouicnBy2bt2qqqiIiHgiluVAHzDGdAUOAy8YY1YZY9RxTKSNyMjIYMaMGaqKioiIJ2LpXHeXtfYbYDzQC/gZ8J+eRiUiIiIibUIsfUZN6P1qYLa1do0xxpzqAhERrx04so+FG97wpO1DR8sASOvg3SjoA0f20RdVm0VEYklGVxpj5gPnAFONMV2g1rIVLVheXh5FRUWe3iM8sMXLPovZ2dme94kUqUtJSQmPP/4406ZNazGP6r0frLYfgL7nevd9+9KjRQ1WExHxSyzJ6M+BYcBma+0RY0wP3KN6AIwx51lr13kV4OkqKiri8y/WE+zU3bN7mONuhZqVm/Z40n7Skf2etCsSi5a4Nr0Gq4mIJI5YRtMHgVVRn0uB6AWq5wDDmz60phPs1J2j37rG7zAarcP6v/sdgrRRtdemz8nJaTHVURERSQxNMTu4+o+KJKi61qYXERFpSk2RjNomaENEWqC61qYXERFpSh6tmygiiWDcuHG0a9cOQGvTi4iIJ5oiGT3eBG2ISAuUk5NDeCY3rU0vIiJeiGUFpn+eap+1dnRTByUiLUN4bXpjjNamFxERT9Q7mt4Y0wHoBGQYY9KJDFTqCpzVDLGJSAugtelFRMRLp5ra6ZfA/8ElniuJJKPfAC96HJeItBDhtelF/LCjfA/PL5vtWfv7QvM49/JoLuod5XsYjHcreYkkgnqTUWvtfwH/ZYyZbK3VTyIREZ+VH69i2d4yT9o+UlUNQKeUZE/aBxd/PJpjharKjSUAdDrbm4RxMOlaaUukAbGswLTHGNPFWltujHkEN8H9U9baVQ1dKCItS2OWxw0EAgBkZmbGfI2Wr2163i+B6pY1PnvgQE/vE8/3aI6/Q1ptS8R/sSSj/2GtfdMYcylwJfAc8GfgEk8jE5EWoaKiwu8QBC2BKiKJK5ZktDr0/iPgz9ba94wx02Jp3BhzFfBfQDLwsrX2P+s45xZgGm7y/DXW2ttD+3OAR0KnPWWt1dIvIqepMQmNkhQREfFSLMnoTmPMS8AVwDPGmFRimxIqGTfQaRwQAJYbY+Zaa9dHnTMQmAp8z1pbZozpFdrfHXgMGIlLUleGrvWms5SIiIiI+CKWSe9vAT4ArrLWHgC6Aw/FcN0ooMhau9laexx4A7iu1jm/AF4MJ5nW2n2h/VcCC6y1+0PHFgBXxXBPEREREWlFGkxGrbVHgH3ApaFdVcDGGNruC+yI+hwI7Ys2CBhkjPnUGLMk9Fg/1msBMMbcY4xZYYxZUVxcHENYIiIiItJSNPiY3hgTflw+GJgNtAP+CnyvoUvr2GfruP9AYAyQCSw2xpwf47Vup7UzgZkAI0eOrPMcERERkZYmuXgvnd+e41n7SQdc78ZgN+/muk0u3gs9T2+e3lj6jN4AXASsArDW7jLGdInhugDQL+pzJrCrjnOWWGsrgS3GmEJcchrAJajR1y6K4Z4iIiIiLV5zzD+78UApAANPM1k8pZ7dT/u7xJKMHrfWWmOMBTDGdI6x7eXAQGPMOcBO4Fbg9lrn/A9wG/CqMSYD99h+M7AJmB5ahhRgPG6gU9wCgQBJRw7SYf3fG3N5i5B0pJRAIL7JokVERKTl0jy6EbEko/9faDR9N2PML4C7gL80dJG1tsoYcz9u8FMyMMtau84Y8wSwwlo7N3RsvDFmPW4KqYestaUAxpgncQktwBPW2v3xfjkRERERadliSUZ7Am/h1qQfDDyKm+apQdbaecC8Wvsejdq2wJTQq/a1s4BZsdznVDIzM9l7LIWj37rmdJuql005RFW//yVlx48xVWlN3n6H9X8nM/PMJm9XRERansaslBaP8GpbXlfmtBKbxCqWZHSctfZh3PRKABhjngce9iyqVqa652fYTgGqe35Gyu5xfocjIiKtWFFREV9++SVpaU1f3ACorKwEYOvWrZ60D3Do0CHP2pbEU28yaoz5f4D7gAHGmLVRh7oAn3odWGthUw4RTP8SDATTv8QWf8eT6qiIiLQdaWlpDB8+3O8wGm3VqlV+h9DyLF4M06bBsmVQXQ0XXABTp8J1tadgr8PKlTB9umvjwAFIT4fhw2HWLOjTp+a5Bw7AsGGwbRt5QMGoUZFjr74KP/tZ/fd57DEXI8Dvfgfvvw+rV0N4WeiFC2HMmJrXrFsHTz4Jn3wCxcXQpQsMGgT33NPw9wo5VWX0b0AB8DTwm6j95eq/GVHd8zMis05ZVUdFRESkpoUL4corobISMjIgNRWWLoXrr4c5c+DOO+u/9v334cYb4fhxSEuDoUPh2DH46CMoLT05Gf3FL2Dbtrrb6tkTLrmk5r59+2DLFrcd3dabb8KmTdC7N9RXRT9yBH7wA5eEtm8P553nzv3sM/jsM26DM071xxJW76T31tqD1tqt1trbrLXbol5KRENOVEWTqt2OpGpXHU3R4wkREREJmTLFJaJZWbB5s0vYwknhgw+6Y3WpqIC77nKJ6O23w549sGYNbNgABw+6CmS0l16Ct96CW2+tu70f/QiWLKn5uvBCdywjA37608i5f/+7u8djj9X/vb76yiWi4Cqqq1a55DnkbGhf/8URsSwHKvWoWRUNs6H9IiIi0ubt3u0edQOMH+8eY6ekwLXXun379sGKFXVf++GH7jhAcrKrPHbpAqNHu8po+6hcb906+PWv4TvfcY/NY7FhA7z3ntt+4AHo1ClyLDMTkhpIEwcPdpVTcMno8OEu4U1Ohhtv5EUojSUMJaOnIdhpZ6QqGpZU7faLtxYvhrFj3f+UnTq5/zHD/0M1ZOVKmDgRevVy/yP37g0TJrh/MGo7cMD9JmsMeTNmMGHp0rrbjDoPYyJ9bsKqq+GZZ2DIEPd4pmdP91im9qOUHTvg7rtdWx06RPoF/f73YLXAmIhIqxP973yvXpHtcBIHsH173ddu2BDZnjPH/fxo39494r/mGpg/3x07etRVQ1NT4fXXXbIbi2eecT9b0tLgV7+K7ZpoaWnw6afw7W+76u3nn0NZGXTtCiNGcAiCsTQTY7RSl/abJvkdQtvUUvrexHPeL38Jr7zitgcOhEAAXnvNfZfPP4/8A3XVVbB+vftt9PzzYe9ed/zzz6FdO5g8ueFYRESk5aivkBBLgaEqasGbSZNg9myX7J17rnt/4QVXbZ06Fb780j2iP/vs+vt4Rtuxw/0cArj3Xlf8iFdFhYvriy9cd4PHH3cJ8o03wm9/y1To1WAbqDIqrVFL6XsT63lr1kQS0QcfhK+/dv10jIFdu+Dpp92x0lKXiIKrjq5Z45LQsPp+cxYRkZYrKyuyHX7kXnu7f/+6r83MjGyPHu3e09MjP6/CA4/CPytyclyh5bzzTlw2bsWKmu2EPf+8+3mZmuoe7zfG3/7mRtED/Pzn0Lkz3HDDiQLLFdA1lmaUjErr0tL63sRy3ryodR8mTnTvF1wA4bV8w8e7d3fVUICXX3ZTc1x0kUtaf/hDl8iKiEjr0qeP+/ccXNWwvNxVPOfOdft69YIRI+Ddd11XriFDYGeou9/YsZFH7uFuYgcOuKIGuD6b0Q4fdq8jR07sSgkGofa8r/v3u58z4BLYs85q3HcrK4tsL1vm3jdtcsUV4EiMj+mVjErr0pL63sR6XkMxh+M1xiXFY8ZAMOgqo3v3QseO7h+y7t3rbl9ERFq2555zPyO2boUBA1y1NJxcPvus+1l08CAUFrpX+AnfWWfBQw+57dmzXfKZne2SwNRUeOQRd2zRIvfYP/wKV0wJzTN64EDNePLyXNKanBxpv7Y77nD3evjh+vdde62LA9yTxwsucD+vqqvBGGZDSSx/PEpGpXVpyr43hYVQVOQeeVjr+t5ApO/Nyy+7vjf1ifW8WGO2Fu67z/2jcuut7h+mTz91ienvf+/uJyIirc/Yse7p3JgxrstYaSmMGgVvv+0qk6cyfTq8+KJ7crZtm0v+rr/eDca9+OL4Yzl8GP74R7d9002Rp3S17dzpqpzR3Ql27XL79u51nwcNco/pb7rJJc6Fha6bwLhxMH8+b7ul5BukAUzSunjV92bp0rr73uTk1EgaT/S9CQROeR7Tp7skNRA4OeZzz60Zczjejz5yfU8B/u3f3GjE737X/aa5bBl88IHr4yMiIq3P5Ze7Qav1mTTJvepy333uFausLLCW3NxcACZEH+vcGUpiKFguWhTbvUaOdBPknwZVRqV1aYl9b+o4j8rKyHkTov4ZePtt9752ravKAlx9tXuvq+9NWVnkvM6dT/EHIyIi0jopGZXWp6X0vTnFeTz2WOS8YcMiv+0+/7y77+jR7pozz4TfhFbb/eEPoUcPtz1tmhtgde65rqM5uP44IiIiCUbJqLQ+LanvTaxeftnde+BAl7R26gS33ebW7w0PZOreHf71L/jZzyLTViUnw6WXwn//t5urtC3yeoGD225z/13S0txcrmeeyc/ff5++4SXu4mlvzx64/363UEFGhlu4YMAAN4ffjh012yosdHPiZmW5v4dZWe6XpcOHG/OnJCLSaikZldYp3Pfm0CGXkC5d6ibZDZs0KVKxjO6zCa7fzRdfuNHwO3e6R/pRc7KdJNz3ZvJkCsLzmZ7iPKw9eQWm5GQ3AOnrr908pyUlbn622rENGgSzZrmEtaLCrfm7eDHccktDfyKJaeFCl4h+9JFL7Lp3jyxw8Ne/nvra9993fW7fecf9WQ4d6voIhxc4CHvnHTfyc8gQNxBt714u3LyZye+8U3MEaiztbd3qftn54gu3yla3bu6/5UsvuWvLy915hYWun9Vrr7lrhw51iexzz7nkdtGilpGAR68qFv2KHvDw6qt1n1PXamS/+537c+jUKXI81n5pIpKwNIBJRFqu6AUO1q5101xdeqlLSB98EH7yE5dM1VZ7gYOZMyN9bo8erbne8sGDLtENu/NOeO01Oh0/7n55GDUq9vbOOMONUp00yR2vqnK/SLz7rhvM9uGHbkLoWbMifYpXrnS/hMyf71YWW7wYrrjCJcherTD2zjvQt69LwA8cgE2buBAYGAi4z9261Wx36FA3oC6sX7/Ids+ekUUnwvbti3RbiV7V7M033Ujc3r1jWyFGRNoEVUZFpGVqrgUOOnRw1btLLnEVv9DyeN906gTf+lZ87Q0d6tZ3DieqKSnwve/VvBe4RDPMmJrv4eNerjB28KBre8UKN0DujjsAIgl4bX/6k1s1LPyKHjn7ox/VPLZkCVx4oTuWkQE//Wnk3L//3d37scfq/g4i0iYpGRWRlqk5FjgIKypyMxhs2gTAnvR0/uvGG111sTHthR086AbLgatCXnGF277llkhFd8QIt9LWj39c81q/E/BoEye673zuuS7hrd3/NdqGDZEuBQ884B7Jh2Vm1qxKi4igZFREWqrmWOAg7K9/dRXHdevg+9/nzLIy7iooiDxKj7c9cI+pL73UtTlggHuEHk5AR42CggK47DKXOG7f7iaNjn4U7ncCHpaW5h7pZ2S4aurs2S6B3rOn7jieecb9maSluSpJz+guAAAgAElEQVSxiEgDlIyKSMvk1QIHUHMarrCUFFcV/Pd/B6Bvaalb5rUx7X38sUs4v/zSnf+vf7mENNrYse68sjLXn/PZZ+GbehYr8SMBB/c4vqzM9dcNBCJLABYXwyuvnBzDjh0nqqzce6+7t4hIA5SMikjL1BwLHCxe7F5h1dWuX2NYODGLZ8GEmTPdUnglJW6qsUWLalY2wxYudEu9gpvOqfbqKn4n4OCmOwt/b2NO9C0F6q7QPv+8S3BTU+HXv647ThGRWjSaXkRarueeg6uuiixwkJoaSThrL3AAJy9w8PTT7rHyp5+66mPtBQ5WrnRJU7dublqnXbtc1Q84kppKp5tuiq+9JUsi88GmpLhH55dfHvk+//EfbsAPwM03u2S0Xz+XKIanfTrzTPcIPJyAd+xYdwI+darb989/usfo4YS5qsolzL/8Zf0JOMD3v+/e60vAly+H9evdNFDt27vqanSies45Nf9b7d/v5tMFl4SfdVbd/02lQYFAgPLyclatWuV3KI1WXl5OIBDwOwxpJVQZlUYpKSlh8uTJlEbP1yjS1Lxe4GDECDedUseO8NVX7jH5gAF89q1v8fwtt9ScwiiW9o4ejZwfTgqjX9HzeF5zjRt1H+7redll8NZb7vF5E6wwVta7N4f69IGyMiqTk3muQwdyc3N557e/hcsu40iHDgR69qS8Sxf4y18AKE9J4dG1a8nNzeUv06bBpElUdurErh49ONCli0vGgbK0NKZu2kRubi55eXnunnl5rsKbnByJo7Y77nADpsKP++vbJyJtiiqj0ij5+fmsXbuW/Px8pkyZ4nc4ksjCCxzUZ9KkyHKrtd1338mPv6N9//vwj3+ctPv13NzGtTdmTGz9O8FNFl+fDz90o92XL3eVylGjXLIWvbBDXaZPd4/r//xnumzYwKHUVNYMGMD7o0ezJ7TU7PaePfmqf3/OKi3lzP37scZQ0rUrq9PTeXfQIJK7dAFgR69eLLrwQgYGAnQ7dIiU6mr2pKez/uyz+XDECA537Bi57+HDbn5VcAOxoifFj7Zz54kBUyfs2uXe9+499XdrQzIzM6mqqmL48OF+h9Joq1atIjO664jIKbSJZDTpyH46rP97wyc2kjnqBh3YDl0bOLNxko7sB870pO3GKCkpoaCgAGstBQUF5OTk0CO8prqInL4mSMBTgG6h14UN3C4DuCL0OpUzQ68f1nWwpKSBq9FqSyJSp4RPRrPr+w29CW3c6Pp6DTzXq4TxzGb5HrHKz8/Hhqo/wWBQ1VERERFptIRPRnPre9zmwT1O9J1KcAsWLKAy1E+tsrKS+fPnKxkVERGRRtEAJonbuHHjSAlN95KSksL48eN9jkhERGJVkVzBx2d+zNHkow2fLNIMlIxK3HJycgiG5kcMBoPkNDSqWUREWoyvun1FSYcSvur2ld+hiABKRkVERNqMiuQKtqVtAwPb0rapOiotgpJRiVt+fj5JSe6vTlJSEvn5+T5HJCIisYiuhlqsqqPSIigZlbgtWLCAqtA62FVVVcyfP9/niEREpCHhqmgwKdTNKimo6qi0CAk/ml6a3rhx45g3bx6VlZW0a9eu1Q5gysvLo6ioKObzN27cCMQ/Q0N2dnazzOogInIqdVVBw9XRi0ov8iEiEUeVUYlbTk4OxhjAPaZvKwOYOnbsSMfoVWdERFqR/an7T1RFw4JJQUpTtayz+EuVUYlbRkYGEyZMYO7cuUyYMKHVrr6kaqVIC7N4sVsGddkyqK6GCy6AqVPhuusavnblSrcc6uLFcOAApKfD8OEwaxb06ePO+d3v4P33YfVqqKgAIPuGGyiqvWxlYSE8+SR88gns3u2uv/lmF1vnzvHfN57zPHTFrobW2BLxh5JRaZScnBy2bt3aZqqiIuKxhQvhyiuhshIyMiA1FZYuheuvhzlz4M4767/2/ffhxhvh+HFIS4OhQ+HYMfjoIygtjSR7b74JmzZB796wdWvdbRUWwsiRcOhQpK0NG+C551w8CxdCcnJ89431PJE2So/ppVEyMjKYMWNGq62KikgLM2WKS0SzsmDzZpcsXnKJO/bgg+5YXSoq4K67XKJ3++2wZw+sWeMSyIMHYdCgyLl//7vb99hj9ccxa5ZLRMFVM1evhrlz3efFi+Htt+O7bzzxibRRqoyKtGLxDsJqjMYO3IqHBnm1cbt3u6QPYPx46NLFbV97ratG7tsHK1bAd75z8rUffuiOAyQn803//rQvL2dP9+78Y9Qo1mdlnXTJqK++IlxnDQQCbKyoOPH377pPPmFs6NiTTz1FcbduDN6+nV+F9n32+OMs37OH3HPOqXFfzjvPVTnPOw8efRSuvrrO+Oo9T6QNUzIq0ooVFRWxYfVqzvTwHuHHJwfCyUIT2+NJq9KqbNsW2e7VK7Ldu3dke/v2upPRDRsi23PmUN2rF9XJyWTt3cs9//u//N/rrmND//713jo1NbXGwMTPs7O5fM0aUoJBHnrjDUrOOIPeZWUnjncLV01r3ZdBg6B9e5c8X3MN/OMfLrGO9TyRNkzJqEgrdybwc4zfYTTaK1i/QxC/2Xr+DtS3P1pozmMAJk0iffZsKCuDc88lqayM+44dg7y8mte8+qqrWAJPPvkkjBlT8/g//wlPPEGHtWvJDAbh1luhoAD272foBRcwNDcXnn66xn2Jui9lZfDCCy7JrBVfveeJtGHqMyoiIv6KfpQefqRde7u+6mb0SPjRo917enqkL+aWLfHHM3YsfPyxSxZLS+HZZ2H/fnds6ND47utFfCIJRsmoiIj4q08fGDbMbc+fD+XlrqIYHjjUqxeMGAHvvgtDhrjXzp3u2NixkBJ6yLd0qXs/cAC+/tptDx4cfzwLF0IwNB/n4cNw331u2xg3CCme+3oRn0iCUTIqIiL+e+45l7Rt3QoDBrhqaTh5e/ZZ18/y4EE39VJhYWR0/VlnwUMPue3Zs11yl53tqpqpqfDII5F73HGHO/bww6fed/PNbnqpCy90ifJ777n9jz4aSZpjvW888Ym0UeozKkD8o7IDgQAAmbUniz4FjZgWkXqNHev6cU6bBsuXu+mVRo1ySeKNN5762unT3ePwP/8ZNm6EHj3c/KRPPeVGrYft3OnmGY22a5d737s3su+aa1y/0Q0bXMJ42WWQmwsTJzbuvrGeJ9JGKRmVRqkIrV4i0hrE+8tWY6az0i9bTeDyy90j8vpMmuRedbnvvsjj9PosWhRbHK++Gtt5sd43nvNE2iAlowLEP4dk+Py82qNURRJA9FQ/IiLiLSWjIpLwVLEUEWm5NIBJRERERHyjZFRETulgxyB/uPobvukY9DsUERFJQEpGReSUCi6qYNOZVRQM06A1ERFpekpGRaReBzsGWTrwGNbAkkHHVB0VEZEmp2RUROpVcFEF4fQzCKqOiohIk/M0GTXGXGWMKTTGFBljflPH8UnGmGJjzOrQ6+6oY9VR++d6GaeInCxcFa0OzblRnaLqqIiIND3PpnYyxiQDLwLjgACw3Bgz11q7vtap/22tvb+OJiqstcO8ik9ETi26KhoWro7+5LPOfoQk0mYcOnSIVatWedL2kSNHAOjUqZMn7YOLXyRWXs4zOgoostZuBjDGvAFcB9RORkWkBdraq+pEVTSsOgW29K7yJyCRNiI7O9vT9sMrjGVlZXl6H6+/hyQOL5PRvsCOqM8B4JI6zptojLkM+Br4tbU2fE0HY8wKoAr4T2vt/9R1E2PMPcA9AP3792+q2EXavN/8zxl+hyDSJnm9SINW0JOWxstk1NSxz9b6/L/A69baY8aYe4F84IehY/2ttbuMMQOAj4wxX1hrN53UoLUzgZkAI0eOrN2+SEILBAKUA6+c9L9W67EbOBQI+B2GiIj4xMsBTAGgX9TnTGBX9AnW2lJr7bHQx78AI6KO7Qq9bwYWARd5GKuIiIiI+MDLyuhyYKAx5hxgJ3ArcHv0CcaYPtba3aGP1wJfhfanA0dCFdMM4HvAsx7GKtIqZWZmcqCkhJ/X+SCidXgFS7fMTL/DEBERn3iWjFprq4wx9wMfAMnALGvtOmPME8AKa+1cINcYcy2uX+h+YFLo8qHAS8aYIK56+591jMIXERERkVbOy8oo1tp5wLxa+x6N2p4KTK3jun8B3/YyNhERERHxn1ZgEhERERHfJFQyOqy8HMaOhS5doFMnGD0a3nuv4QuzssCYk1+150grLIQ773Tnp6a694ceon1lZeScV1+tu63wa9q0yLnV1fDMMzBkiGuvZ0/X/rZtNe87ZkzdbaV4WtgWERER8VziZDPG/ODPxsDXX0NGhkvuli6F66+HOXNckteQoUOha9fI535RkwEUFsLIkXDoEKSluXM3bIDnnuPes85ixg03uPN69oRLak2num8fbNnitvv0iez/5S/hlVfc9sCBEAjAa6/BwoXw+efQq1fNdgYMcO2HKRkVERGRVi6RKqO/b2etq1Zu3gxbt0aSwgcfhOjqZX3+9CdYsiTyevPNyLFZs1wiCrByJaxeDXPnApC9axfDNoWmQP3Rj2q2sWQJXHihO5aRAT/9qdtesyaSiD74oEuilyxxFc9du+Dpp0+O7z/+o2a7n3wS1x+QiMSmpKSEyZMnU1pa6ncoIiIJLzGSUWP6AG4d+/Hj3WP6lBS49lp3fN8+WLGi4XYmTnQV1XPPhbvugh1RC0hVV0ffr+Y7MGT79rrb3LAh0lXggQdc9wGAeVHjuiZOdO8XXBDpGjCvxrgvZ8oUaN8e+veHm2+G9ZpgQMQL+fn5rF27lvz8fL9DERFJeImRjMLZJ7aiH2337h3Zri9ZDEtLg759XfVy82aYPRtGjIA9e9zxW26Bdu3c9ogRcNFF8OMfn7i8W7hqWtszz4C1rv1f/SqyP7pfaF0x1463Y0f3iL9vX5ckv/UWXHwxfPHFqb+XiMSlpKSEgoICrLUUFBSoOioi4rFESUbrnvHbxrhE4ptvQlkZrF3r+m0+/LDbX1wceZQ+ahQUFMBll0FysksWb7oJuncHoDqpjj/KHTtcH1CAe++F9PSGY6tr/wsvwP79sG6d63v64otu/5EjoLWFRZpUfn4+NvT/YTAYVHVURMRjiZKMbj2xtW8fdW7371//1RdfHBkMZAzccUfkWHSFcuxY+Phjl7iWlsKzz7okEdgTSkpreP5511c1NRV+/euax7Ky6o4zvB0d70UXQYcOkc/hfqe14xOR07ZgwQIqQ33MKysrmT9/vs8RiYgktsRIRt2SoqsBmD8fysuhqurEACN69XKP1t99102jNGQI7Nzpji1fDvn5cPx4uC14/fVI2+ecE9leuBCCQbd9+DDcdx8AQWDloEE1Y9q/H15+2W3n5MBZZ9U8PmFCZPvtt9372rVQVOS2r77avW/ZAjNmRAZPAfztb3XHJyKnbdy4cbQLdclp164d48eP9zkiEZHElhjJqPPvVeBG0Q8Y4CqPS5e6I88+6wb+HDzopmgqLIyMrt+5EyZNclM6nX++m84pPJI9MxPuvjtyh5tvdn1KL7zQ9d8MDUz6YNQodkZPuQTu8fnhw+6R/kMPnRztsGHuvuAqqIMHu3lRrYUzz4Tf/MYdO3gQcnPdI/4hQ9x3u/ded+yMM06uuIrIacnJycGEBicmJSWRk5Pjc0QiIoktcZJRa/9536BBboL4igr3GH3UKFd1PNUPkxEj3Cj3wYPdlEplZS7pmzLFTeGUkRE595proHNnN0IeXP/Rt96ioPa8oocPwx//6LZvuunkyfPDXn4Zpk93c4xu2eJG2t92G3z2WWQg09lnw9Sp7lF9aSns3u3au/tuNxfp4MGN+uMSkbplZGQwYcIEjDFMmDCBHj16+B2SiEhCS6hZ01d16eIepddn0qRINTKsXz/4wx9OfMzLy6OoqMhVTp96qua5XbtCeHL7sI8/ZuPGjQDk5uZG9t9+e2Q7en9Idna2O3/qVPeqT3q6S1inT6//HGnT9gCvEONgvUYIjyX3KiXbA3TzqO3GysnJYevWraqKiog0g4RKRv3SsWNHv0OQNiq7vqp7EyoO/bLVbeBAT9rvRvN8j3hkZGQwY8YMv8MQEWkTlIzWkltHFVOkpWqOv6/he+RpGjEREfGAktEEdKKrgYfq7JrQxE50ZRAREZGEpWQ0ARUVFfH1l6von1bd8MmN1L7SjX07unW5J+1vP5TsSbsiIiLSsigZTVD906p5ZGQ9S5S2Ak+tSPM7BBEREWkGiTO1k4iIiIi0OkpGRURERMQ3SkZFRERExDdKRkVEaikpKWHy5MmUlpY2fLKIiJwWJaMiIrXk5+ezdu1a8vPz/Q5FRCThKRkVEYlSUlJCQUEB1loKCgpUHRUR8ZiSURGRKPn5+VhrAQgGg6qOioh4TMmoiEiUBQsWUFlZCUBlZSXz58/3OSIRkcSmZFREJMq4ceNo164dAO3atWP8+PE+RyQiktiUjIqIRMnJycEYA0BSUhI5OTk+RyQJbfFiGDsWunSBTp1g9Gh4772Gr8vKAmNOfmVnR8559dU6z8mbMYO8GTNg2rSaba5cCRMnQq9e0L499O4NEybA7t3x3XfPHrj/fhg+HDIyoEMHGDAA7r0Xduxo/J+VJCwtByoiEiUjI4MJEyYwd+5cJkyYQI8ePfwOSRLVwoVw5ZVQWemSttRUWLoUrr8e5syBO+9suI2hQ6Fr18jnfv0i2z17wiWX1Dx/3z7YssVt9+kT2f/++3DjjXD8OKSluXaPHYOPPoLS0prnNnTfrVvhxRchJcUlqSkp7p4vveTus369S75FQpSMSqPsT4ZnMuDhYuge9DsakaaVk5PD1q1bVRUVb02Z4hLRrCxYuxY6doRLL3UJ6YMPwk9+AqEuI/X6059gzJi6j/3oR+4V7YYbYMsWDnXoQNpPf+r2VVTAXXe5RPT222HmTOjc2R07ehSS6niIeqr7nnEG/PGPMGmSa6eqCm65Bd59FwIB+PBDF4dIiB7TS6O83hXWpcIbZ/gdiUjTy8jIYMaMGaqKind274bVq932+PGuUpiSAtde6/bt2wcrVjTczsSJrqJ67rkuoTzVY/ANG050AVg0bJjrFgAuOdy3z20nJ8N557l4Ro92ldH27eO779Ch8KtfRRLalBT43vcixzt0aPh7SZuiZFTitj8ZPkwDa2BBGuzX3yIRkfhs2xbZ7tUrst27d2R7+/ZTt5GWBn37ukf8mzfD7NkwYoTrs1mXZ54Baznarh2Lv/3tyP4NGyLbc+a4JLN9e1ehveYaqD2jRLz3PXjQnQMwZAhcccWpv5e0OUojJG6vd4WgG99B0Kg6KiISt9BctjHvr+3NN6GszD3eDwTg4Yfd/uJieOWVk8/fsQNeew2AT88/n4ro6mRVVWR70iQoLISiIkhPd/G88ELj77tli+t6sG6dG8T0/vsNdz2QNkfJqMQlXBWtCiWjVaqOiojELysrsh1+RF57u3//+q+/+GL3+BvcaPY77ogcq6ui+vzzrn9qaioLhw2reSwzM7I9erR7T0+HQYPcdnjAU7z3/fhjGDUKvvzStfuvf7mEVKQWpRASl+iqaJiqoyIicerTB8JJ4fz5UF7uKpRz57p9vXq5R9/vvusebQ8ZAjt3umPLl0N+vhtwBK56+frrkbbPOafmvfbvh5dfdts5OXyTllbz+NixkQRz6VL3fuAAfP212x48OP77zpwJ48ZBSQnk5MCiRTW7IIhEUTIqcdmQGqmKhlUZ+CrVn3hERFqt555zSeDWra5imJUVSQaffdb12zx40D02Lyx0lU1wSemkSW5qpfPPd9MqPf20O5aZCXffXfM+eXlw+LAbnPTQQyfHcdZZkf2zZ7vkMzvbPY5PTYVHHonvvkuWwC9/6eJNSXF9Ui+/3FVHR492j+pFomhqJ4nLjHr6p4uISJzGjnUj2adNc1XHQ4fcY+2HH3ZzftZnxAh44AE3T+mOHW4+0CFD4Oqr3bUZGZFzDx920ywB3HRTzcnpo02f7hLKP/8ZNm6EHj3cfKdPPeVG18dz36NHI+1WVUUS7LDi4rj+mCTxKRkVERHxy+WXu+SuPpMmuVe0fv3gD3+Irf3Ond2j8ljcd5971SfW+44ZE/tALBH0mF5EREREfKTKaAIKBAIcLk/mqRVpDZ/cQm0rT6ZzIOB3GCIiIuIxJaMibUheXh5FRUVxXbNx40YAcnNzY74mOzs7rvNFRKTtUjKagDIzMzlatZtHRh7yO5RGe2pFGh2i574T33Ts2NHvEEREJIEpGRVpQ1StFBGRlkYDmERERETEN6qMJqjth7wdwLT3iPs9pnenoCftbz+UzCBPWhYREZGWRMloAsqub1LjJnQ8NKilQ9ZAT9ofRPN8DxEREfGXktEE1Bz9AsP3yMvL8/xeIiIikrjUZ1REREREfKNkVERERER8o2RURERERHyjZFREREREfKNkVERERER8o2RURERERHzjaTJqjLnKGFNojCkyxvymjuOTjDHFxpjVodfdUcdyjDEbQ68cL+MUEREREX94Ns+oMSYZeBEYBwSA5caYudba9bVO/W9r7f21ru0OPAaMBCywMnRtmVfxioiIiEjz87IyOgoostZuttYeB94Arovx2iuBBdba/aEEdAFwlUdxioiIiIhPvExG+wI7oj4HQvtqm2iMWWuMecsY0y/Oa0VERESkFfMyGTV17LO1Pv8vkGWtvQD4EMiP41p3ojH3GGNWGGNWFBcXNzrY01FSUsLkyZMpLS315f4iIiIirZWXyWgA6Bf1ORPYFX2CtbbUWnss9PEvwIhYr41qY6a1dqS1dmTPnj2bJPB45efns3btWvLz8xs+WURERERO8GwAE7AcGGiMOQfYCdwK3B59gjGmj7V2d+jjtcBXoe0PgOnGmPTQ5/HAVA9jbbSSkhIKCgqw1lJQUEBOTg49evTwOywREZGElZeXR1FRUVzXbC3eyu6Ruxm+czipVakxXZOdnU1ubm5jQpQ4eJaMWmurjDH34xLLZGCWtXadMeYJYIW1di6Qa4y5FqgC9gOTQtfuN8Y8iUtoAZ6w1u73KtbTkZ+fj7WuB0EwGCQ/P58pU6b4HJWIiEjrEW9yGQgEqKioiOsexRcWc6zHMdaUrSF9ZXrDF4TuE09cSl4bx8vKKNbaecC8WvsejdqeSj0VT2vtLGCWl/E1hQULFlBZWQlAZWUl8+fPVzIq3lm8GKZNg2XLoLoaLrgApk6F6xqYqCIrC7ZtO3n/uedCXf/QHjgAw4ZFrnnsMXffsHXr4Mkn4ZNPoLgYunSBQYPgnntg0qSaba1cCdOnu9gPHID0dBg+HGbNgj593DmFhZH2du92+2++2d2zc+eY/mhE2qp4E7mNGzcCxJU0eZ1kLVq0iJKSEs/aD3YMcmzgMTBw+JzDpCxPIami4Z6Khw8fjiuuQCCgZLQRPE1G24Jx48Yxb948KisradeuHePHj/c7pEZJhH/MEt7ChXDllVBZCRkZkJoKS5fC9dfDnDlw550NtzF0KHTtGvncr1/d5/3iF3UnrwBHjsAPfuCS0Pbt4bzzYOtW+Owz9+rRA378Y3fu++/DjTfC8eOQlubuf+wYfPQRlJa6pLOwEEaOhEOHIuds2ADPPee+38KFkJwc1x+ViNSvY8eOfodwkm7dusVV6Tx27BjBYDDm849cdKTG56MXHSVtSVqD1yUlJZGaGtsjfXDfw0uJ+rNayehpysnJoaCgAHB/aXNy2sZiUS3xH7OEN2WKS0SzsmDtWujYES691CVsDz4IP/kJtGt36jb+9CcYM+bU57z0Erz1Ftx6K7zxxsnHv/rKJaLgKpdTp7ok9Lvfdfu2b3fvFRVw110uEb39dpg5M1LlPHoUkkJViVmzXCIKroo6aBDMn+8S78WL4e234ZZbGvjDEWm7EuGX/Fmz4nsQGk9SdizlGEsGL4kM2U6BysGVDD4+uMG+o629iNJaflYrGT1NGRkZTJgwgblz5zJhwoRWO3ipNf/P1ibs3g2rV7vt8ePdY3GAa691yei+fbBiBXznO6duZ+JEl/hlZsLll8Pjj9esjq5bB7/+tWvnySfrTkYHD4bevWHvXpeMvvmmq4wmJ7vuAuHH9B9+6OICd+y881w19Lzz4NFH4eqr3bHq6kjbxtR8B/jgAyWjIlJDPD+znlzyJMkbk2tUUpNTkul3Sz8eGf2IF+F5JlF/Vnu6Nn1bkZOTwwUXXNBmqqLig+hH5r16RbZ7945shyuS9UlLg7593SP+zZth9mwYMQL27HHHjx511dDUVHj9dUip53fVtDT49FP49rdd1fPzz6GszD3+HzECOnVy523YELlmzhzXbvv2Lnm+5hpX/QSXaIYruiNGwEUXRR7zAwQCp/5eIiKnsGbfGiqDlTX2VQYrWb1vtU8RSW1KRptARkYGM2bMaLVVUWkFbJ1rPtS/v7Y333QJ49q1Lrl7+GG3v7gYXnnFbU+dCl9+CS+/DGefXX9bFRWu+vnFF657wKFD8M47rv3f/hb++Ed3XlVV5JpJk1zf0KIiN4DJWnjhBXds1CgoKIDLLnMV1O3b4aaboHt3d7x9+9i+o4hIHd669i2+yPnipNdb177ld2gSomRUpDXIyopshx99197u37/+6y++OFLpNAbuuCNyLFxR/fxz956T46qf550XOWf6dPdoH+Bvf3Oj3gF+/nPXD/SGGyIV2w8+cO/h8wFGj3bv6emuTyjAli2R42PHwscfu4S2tBSefRb2h2ZzGzq0/u8lIiKtnpJRkdagTx831RK4x9vl5a7yOHeu29erl3vE/e67MGSIe+3c6Y4tXw75+e6ROriq5OuvR9o+55ya9zp82L2ORI0+rayMDDIqK4vsX7bMvW/a5JJIiAxSGjs2kgAvXereDxyAr79224MHR9pZuBDC/bkOH4b77nPbxrjBTyIikrCUjIq0Fs8955K7rVthwABXLQ0nec8+6x5nHzzoHocXFjvfwdoAACAASURBVLoEElxSOmmS69N5/vluwNLTT7tjmZlw991ue9Eil6iGX9GVy8cec4kkuEFT4alO7rrLzXU6bJgbiGQM/Oxn7thZZ8FDD7nt2bNd8pmd7ZLZ1FR4JGrgwM03u76sF17oEu/33nP7H300koSLiEhCUjIq0lqMHetGqI8Z4/ptlpa6/pZvv+0erddnxAh44AGXDO7a5ZLBIUPcVFErV7okMB6DBrnH9Dfd5BLOwkL3WH/cOFe1veqqyLnTp8OLL7okeNs2l4Ref72778UXR8675hpXUQ0PerrsMje9VPRE+yIikpCMjXUARCswcuRIu2LFCr/DEBEREWnzjDErrbUjGzpPlVERERER8Y2SURERERHxjZJREREREfGNklERERER8Y2SURERERHxjZJREREREfFNQk3tZIwpBrb5dPsMoMSne/tF37ntaIvfW9+57WiL37stfmdom9/bz+98trW2Z0MnJVQy6idjzIpY5tJKJPrObUdb/N76zm1HW/zebfE7Q9v83q3hO+sxvYiIiIj4RsmoiIiIiPhGyWjTmel3AD7Qd2472uL31nduO9ri926L3xna5vdu8d9ZfUZFRERExDeqjIqIiIiIb5SMioiIiIhvlIyKiIiIiG9S/A6gtTLGfA9Yba09bIy5ExgO/Je11q9J90VOmzFmyqmOW2t/31yxNDdjTEfg/+Amab7XGJMNDLTWFvgcmqeMMedYa7c0tC+RGGM6AxXW2qAxZhAwBCiw1lb6HJqnjDE3W2vfbGhfImmL37kuxpje1tq9fsdRHw1gaiRjzFrgQuACYA7wCnCjtfZyXwPzWOgf7oeAs4n6ZcZa+0PfgmoGxpieANbaYr9j8ZIxJgisBgqAY4CJPm6tfdyPuJqDMeZ14Avgdmvt+caYTsCn1tqLfA7NU8aYVdba4bX2rbTWjvArJq8ZY1YC3wfSgSXACuCItfYOXwPzWD3/rU/al0ja4ncOM8acAUwEbgeGWmv7+hxSvVQZbbwqa601xlyHq4i+YozJ8TuoZvAm8H+BvwDVPsfiKWOMAR4D7sclZUnGmCpghrX2CV+D885w4FbgR8BK4HXgn7Zt/NY60Fp7mzHmZgBr7ZHQ34GEZIwZApwHnGHM/9/efcfLWVX7H/98adKlCIpgaEJAehMQQQKIgoDAFRCpCggKUoQrXC5IEX8KqOCVpqCUS1GQcmlCkKrSCQSkI72GiEBoiYTv74+1J5kczjnJmWTmyXlmvV+veWXmmZlz1pNz5syevddeS1s33TU3MGs1UXWMys93N+L1fJyke6sOql0kbQJsCiws6X+a7pobeL+aqNqrG88ZJqzwbEEMQFcF5gK2BG6pMq7JycFo68ZI+i9gR2A9STMCM1ccUye8b/vUqoPokP2BdYA1GkuWkpYATpV0gO0TKo2uDWzfR8yMHiLpc8D2wK8kHWz78mqja7txkmYFDLFUDYyrNqS2GgpsBswDbN50fAywRyURdY4krQ3sAOxWjtX5/fBFYvZ3C+JDZsMY4IBKImq/rjtnSecB6wHDgZOAG4AnbN9UZVxTIpfpWyTpE8Qnj7ts/0XSEGB92+dUHFpbSToSGAVcSizjAmD7tapiapcyU/JF26N7HF8AGF7n5dtyjtsC2wD/Bg63fXu1UbWXpC8DhwCfIdIUvgDsZvv6SgNrM0lr276t6jg6SdIXgAOJNIxjy4fM/W3vW3FobSVp5kZerKR5gU/Zvr/isNqqm85Z0khiFe8c4A+2n5P0pO0lKg5tsnIw2oIyC3qt7Y2qjqXTJPW2qcGD4Zd9oCT93fbyA71vMJP0TWA7Ypn2j8CFtkdVG1XnlEH454g/6Ld2w7lLOg44BngXuIbIhd/f9rmVBtYBkuaw/XbVcXSKpJuImcKZiBWQV4Gbbfe7cXEw67ZzLuk33yD+jo8iNuetYPvlSgObjCzt1ALb44F3SnJwV7G9eC+X2g1Ei/6WaOu6fPtbYCFiKetLwBmSLm9cqg2tIzYElrd9GfARSbXdxNNkY9tvEkv2zwONTYq1JWltSQ8BD5fbK0k6peKwOuGj5We9NXBm2aRW90mVrjpn24/Y/qHtocD3iQ3Wd0q6teLQ+lXnHJl2ew94QNJ1wIRP1t2wzAN8h8hLAbgJ+HVNS6KsJOnNXo6L+m7wGFZ1AFWRdBKR970e8GPidX0asEaVcXVAI9d9U+AC26/VeN9Ww4nEh63LAWyPlLRe/0+phZkkLUSk4Px31cF0SDeeMwC27wLuknQgE9+zp0s5GG3dVeXSbU4l3rwaswg7lWO7VxZRm9ieseoYKrAGJdeo6kAq8DnbqzZ2VZdB2SxVB9UBV0h6hFim/25JVXiv4pjaruTTNR+qdXWQ4mjgWiJX9q6SK/t4xTG1W1eds6RhwPeIDYoQs/8nTe+bmDJndCqUN6qly81Hazo7OAlJI22vNLljdSRpYaAxQH3Rdu3Kg0g6Afga8BRR1uminhu46krSHcDawN1lUDo/8Oc6b1RrKBs73rQ9vtRXnXt6zzGbGpL+CPyC2HG8FrAvsLrtr1caWEpTQdJXiN/po4ERxCreqsBhwD62r64wvH5lzmiLJK1PfLo6mZglfKxLlnnGS1qycaN8yqzljIKk/5L0w6ZDtxGz4cOpaU6d7QOAIcDhREOH+yX9SdLOkuaqNrq2Oxm4GFhA0lHAX4Fjqw2p/UrqzU7AH8ogbTfgn9VG1XZ7AXsDCxN5siuX27UmaRFJl0oaJekVSRdLWqTquNqpy875P4EtbZ9pe6Tt+2z/jqgzenDFsfUrZ0ZbVDp4fMP2o+X20kS+Va03PEjaEDgTeJL41LUo8E3bN1YaWBtIGgGs29htK+le26uUago32/58tRG2XznXjYCfAkNtz15xSG0laTnifEXMiv694pDaTtIZROrN2eXQTsB427VLvWmQNF8dy9FNTtnjcD6xqQWiTvYOtr9YXVTt1U3nLOkR28sM9L7pQeaMtm7mxkAUwPZjZYah1mxfL2kpIh9FwCO2x07maYNWj7IvvyzHxpcuF7UmaQWiG9N2xEzZodVG1D5l0D2ipJs8WHU8HbZGjzSbG0q9wjq7Q9J9wO+Aa7qkwxjAArbPbLp9lqT9K4umM7rpnPsrUzZdlzDLwWjr7pb0WyZ+2tqBSbs81IqkDWzfoEnbBgIsKQnbl1QSWHvN2Vww2fZZAJI+QrSUq53yQePrROel8cDvidI/T1YaWJuVDxgPSVrY9gtVx9Nh4yUtafsfUO/UmyZLEzPg3wJOkvQH4Czbj1UbVtuNlrQjkQ8O8Tqve0pGN53zkn2U4BMwXZdgzGX6FpUByd7A54kf9C3AKXWdJZR0lO0jJJ3Zy922/a2OB9Vmkv4f8Aki8fudcmwOIrfwJdv/VWV87SDpSeKP9u9tP1B1PJ1UlvPWJHKDm8u19fwAVivdlHrTm7L7+FxgDmAkcEhdO1IpOgWeRGzUA/gbsJ/tZ6qLqr266ZwVncUgfpeXIlobP0qpjmH75opCm6wcjE6Fspt+WeADYjd9XQuhd6WydPtjomxV4w/XEKIw/GF13E3fU9lRvh7wrO3azvzDhEHZh9S9HShM+HDdFak3MOH3ekciP/YV4jV9ObGR6SLbi1cYXkotKWOS44CdgaeJ1/OCwK9s/1TSKrbvrTDEPuVu+haVEgr/IPIITwKekLRJtVG1n6T9JM2tcIakEZI2rjquNlmV+Pl+CtgVOAu4F5id+i7TXylp+XJ9IeDvxFLm/9Y1z0rScIhBZ2+XquNrt5LrvifwQ6KKwh5dkP9+G/Ea3tL2V2xfYvt923cTjQ5qqct2lgNdd84/A+YEFrW9ailLtyywhKRTgek2nS5nRlukKBK9me0nyu0lgaum591q00KjpqikLxFpCocTLdZWrTi0aa7spt+oFD9fj8if/B4xe7Ks7a9VGmAbSHrQ9nLl+qHAMrYbZZ3+ZnvFaiOc9hpVEqqOoypdupteXbRpaYJu2lne0E3nLOkJYKmev9tllW80sInt2ysJbjJyZrR1oxoD0eJJYFQlkUjrIl2PNAbpHaTbkb46Bc97Gsm9XJ7o8bj/RroV6R3DikjeGfYgBqEjiaUAkC5AehzpLaR/I72MdAnSyn18/3l6xHBkj/uHIp1bHjO2/Hs8kbfZCTM2lX/ZDviN7YttHw58ukMxdFpz44YNgasBbI8h0lHq6KOStu7rUnVwHbCG7V1s31Au36T+LVA/Jul4SVdLuqFxqTqoDlig1KB8v1zOAhaoOqg266Zz/qC3D1m2xwOvTq8DUcjd9APW9Ob0oKSrgQuJJOFtgLsqCGgY0epsZuKTz1hiE8ZlSDthnzsFX+VhoLkHe89WkNsASxK5VYsRV9YCGjNmjUHK1sALwCPAPOU5WwEbIC2G/XqPr3s6sVmit/MaCtxNLDm8VWJcBjgIWBNpGPECa6cZJc1UckM3BL7ddF9dXzvPSfoeUQh8VeAagFLKqq5Ltx8FNqPxoWpSZjpe2ppGunE3/XnAH4if+17ALsCrlUbUGd20s7yhm875IUk72z6n+WA5/4crimmK5DL9APWxm7yh87vKo4/2ykSy8opEf+m/EgPSUcAi9NWmVHqaGAwOo7++tZFf8yKRFH0mwMOw+bL2lZLmAxaxfT/SrNjvNT3vXKLkFcCa2Hc23bcnkZv1e6KUEMBR2EeW+48FflCOD8V+jMhNvbYc2w77wj5jngYk/TewKTHIHwKsatuSPg2cbXuddn7/KkhakGgltxBwsu3h5fgwYDXbP6syvnaQNKKOaSZTqht300u6x/Zqku5vpJ5Iutn2Fyb33MGsx85yA7dS053lDd10zoqW1ZcQ44B7iPNdA5gN2Gp6LltX19mdtilLWNOH2GDSWAIfTiylQtQZW5PYRbc6kazfn4uR5iRmw24GjsCeODtqP1++7oRDy8Jb5dNWY5MP2O+VpfZNgPmJmVGIGdWHmuJeDjihxHU4EwejzWZsuu4e/wJ8iZiVbhvbP5Z0PTEwG960/DEDkTtaO7ZHETNFPY/fCNR1cNLbjGjX6LZGFkXjA/pLZTPqi0BdN7VMYPtZYIuq4+ikbjrnMthcU9IGwHLE6/lPg2EjZg5GWyRpASJvcjGa/h87PDPavMTdnK/6StP1IfQ/GH2LWFqfnyiKuwSwGdKK2C/39aTzYqC5H1ES5RygMaPwaeCzTQ99GNgS+y0ApFmJ2dCxxHJJXwOBC4F9iaXhe5D+QewKbOjIG0dvOTZdUBi72+xUdQBVkbQo8Lbt0ZJmJ+omLw5cVm1kbXeMpI8CBwK/InbWH1BtSO2j+Lu7HfAv4Aqih/l6REWYH9keXWF4bdGN59xg+wZgUOVA5wam1v0fkWv2Z+Cqpksn9TWQm9KZnm2AeYllqkWAY8vxBYDd+nviLbAO8EvbvwTmmnCHvSMxgFwO+AsxgLyozLwC/ARYHtid/pZJYkl/k/hWjCcG1X8EGhuKsqZrmibcBf3neyPpcOIN63ZJxwAnAh8D9pN0YqXBtZntK22/YfvvtofZXs12b51r6uIcYGOiTNtNxETGScAYomRdHXXjOQ9aOTPautltH1xxDE83XV+wj+vP9vls+66m60Y6D2ic05D+vvEz8SI/tJSMmHRjS2z4eQjpZ8C6RC7r9sSGpUYJnbORzmbSgfOhSLtjL1K+zvXAxOUF6ZNMzEGdrpOxUxoEtic+LM5O/J34hO13JM0E3FdpZG3Sy2zZD4i/UXWfLfuM7eXLz/b5ptzYaySNrDKwNurGcx60cma0dVdK2rTSCOyXmPimsTHSXMQLr5EfM4pY4t4K6ZFyWRgAaQ2kXYiODSCJeHNqeKq/b705HOtYxl8YOL6Ul1p3wgNikLpZ01Pm7PEl5iiX2ZuOzTzJ46RhSDOU63MApzTOnKgbl6axRgH4cr127U7TJN6zPc5R5eIfLi1vS/WIuq489Jwta2xuqfts2TiY8LN9scd9da2c0I3nPGjlzOgASRpDDIZEzAyOJZLhReym73RnnoOI8juLEbthxxIDRIAfYI8jcqOGlmONWcyFiT++vy51Redpet7zwBkTvkPMmK5J03L8bnAE0n7vwP/NDkfGIU5Aep1onflJJtZye51YYgd7/UmilxZj4sB34m76cBEwA9JzRB5b4/sfjV3LmZvpQHP9vW2ItIquIGkd4nd5UeJvY+M1vUSVcbXRPKVUnYC5m8rWiUhBqqNunS1bRNL/ED/bxnXK7YX7ftqg1o3nPGjlYHSAbM81+Ud1kH090kbEm+gaxMzincCx2P3VR7yH2AU/jGh3+RGiPujV5bnNy1ULM3FnPACzxoan+d+KQfBl5ftfSyzJL0sM2J8kZh9+Osnu/Cl3JVHfcxlikH0L8D/YF7fwtdKU6eZab78lNrHcQ3fMnNwMbF6u39J0vXG7jibMlknqptmy/2y6fneP+3rerotuPOdBK+uMtkhSb3UJ3wCeKcsCtSTpPmK3/B2NFoqSHrC9QrWRpWlBMbN9CzF7sC49BiW2a1siRdIdttesOo7UPpJGEdU8ROSO/r5xF7Ct7Y9XFVtqD0nb2L5ocsdStXIw2iJJtxM1Nh8oh1YARhIzhns1ioXXTeMNu9HPuyx3jahjz/JuJKnfot+2b+5ULJ0m6adEfdtLiJl4AGyPqCyoDim1NpcDZm0cs310dRG1h6Rd+rvf9tmdiqWTJH0eWKLRmUfSH4H5yt3HlFJAtdRbU4tub3QxPcpl+tY9Dexm+0EASZ8hlgV+RLyZ1XIwCtws6VBgNklfBL5L7EpNNVDnweYUaMyKrt50zMAGFcTSMZJOIzYSDiNyxb9GpPrUTl0Hm1PgKCZt1DEU2JXYRHoog6wm5ZSQtAnRQW/hpnxRiJqytV29HKxyZrRFku6zvXJvx3q7ry4Uu9t3I3akisgTPcP5i1QLpRPPoUTpm18Q5bgapW92s525VjXTaInZ9O+cwCW2N646tjRtSLrL9hpNty+xvXW5/reatjZeiehQeDTww6a7xgA32v5XJYGlXuXMaOselXQqE3OOtgMek/QRJraaq5VSU/RsR2H706uOJ7XFmUT5m7mBO4D9ga2IAenJTJw9rJ3SkecIoksLxAafo22/UV1UHfFu+fcdRS3ffxLVK1J9zNN8ozEQLWqZJ2t7JDBS0vm2a/meXCdZZ7R1uwJPEG/WBxA7x3clBqLDKouqjWyPBxZQozZpqqM5bf/G9s+Ad21fZPs929cRFRfq7HfErMm25fImMTivuyslzQMcD4wgUpB+3+8z0mDzSMkLnoSkzYBHK4inkz4r6TpJj0l6UtJTkp6sOqg0qVymTwMi6dfExq3Lgbcbx23/orKg0jTTnNjfM8m/7kn//aXeVBVTp5WVnVnrPhssaWngVODjpe7oisAWto+pOLS2KOk3VwK3Eh84AFYDPgdsZvuxqmJrN0mP0EvJNtv/rCyo9CG5TD9Aki60va2kB+ilJmMX7Cp/sVxmoLknfaqLZSTdT+QDL1muU27Xtfh7w7uSPm/7rzChCP67k3nOoNVU5L63+3D/dYoHu9OJDae/BrB9v6TzgVoORoH3iBrQOxBVEyDKtu1F1Keu7WAUeMP2n6oOIvUvB6MDt1/5d7N+H1VTto+qOobUVstWHUCFvgOcXXJHBbxGpN7UVaPI/YLEDFljR/UwollFnQejs9u+M7ogT1DnHdY3A6cBv2jUwZb0caJ6wlBiQFpXN0o6ni4s2TaY5GB0gBz94LH9jKRFgaVs/1nSbHTB/6ekK/jwjPAbREeLX9t+r/NRpWnF9jO9HS+b175OtHqtJUeL2ZUkzV1uv1lxSG1l+5sAkq4k2mS+VG4vRGxWq7PRkpak/C2T9DXgpWpDaqvVgJ8C90raj6iL/X3gOGDnKgPrgK4s2TbYZM5oiyTtAXwbmM/2kiUn5zTbG1YcWltJ+iXRv/yCcmg74GVgNmBu2ztVFVuaemUgtjfRAvZy4DpgH+Ag4D7bX60wvLaQtKPtcyV9v7f7654PLenvtpdvuj0D8IDt5fp52qAmaQngN8SM8L+Ap4Ad+vowVhdlIHoCkWq1lu3nKw4pJSB300+NvYF1iB232H6cWO6qu1Vsf8P2FeWyI/BZ23sTG5vS4Pa/xLLdA8DuRPOGrwFfreNAtJij/DtXH5e6u0nStZJ2LR2KrgKurzqoNnvG9kbEB+tlbH++zgNRSfOUzaffBL4M/BH4k6TqZgeldZGuRxqD9A7S7UhT/jdGmgfpaSSXy5E97h+KdO770rP/lsa/HN/j+DWl1STt1vS45q/RfHmix9dbDun3SM8jjUUajXQr0q5Nj9m1j6/Ve4xpgtovK7fRWNvjGjlHpS1mN0wzLyBpiO1nASQNAT5W7htXXVhpGlnC9goAks4ARgNDbI+pNqz2sd3YxNKV+dC295G0FRPrq95GTWtPNnlK0jXAH6hh96FejABOAfYuOaPDJa0MnCLpGdvbdzQaaRjRMGVm4m/MWGI5/TKknbDPnYKvcjqwaB9ffyiROjbnOBj/Ljw3LwwBDroN1pwF5gV+2+NZD1Mml4rnmr7e7MCNxIeXccCDwGLA2sDaSP/EvgJ4lajP3GxBJtbtrXMqyFTJmdHW9WyLeRHd0RbzQOCvkm6UdBPwF+A/Jc0BdGurvTqZUBy61JV9qs4D0WaSjpM0t6SZJV0vabSkHauOq0OeIn72WxEbmB6uNpy2Gwr8mVjhekrSSaV/e12tZ/tnjc1LEDnStps3rnXSL4iB6NNElY7FmDiI+znSzP0+W9qTWLHpqx7ut4A5AdaCh+a3F/t61AJnBlh3595XPL6LvVbTZZum+5YlBqIARxIl7prrtg4BwL6qx9dYCxhZHjOaWHlKvcjBaOsOIT4FPQDsCVwNHFZpRB1g+2pgKaLY//7AUNtX2X7b9onVRpemgZUkvVkuY4AVG9cl1XpDD7Bx2bS0GfA8sDRR/qeWJC0t6YeSHgZOImaCZHuY7ZMqDq+tbL9r+8LSiWgVouPYzRWH1Tb95Yba7mw3vdgg16jdOxx7DDFIvrwcW5BJNxv1fP5yRN7rbcDhfTxqxgkPj5Jt89O0cvmV3ht4XFyW3/+B9DukTzXd9yjwSrl+JNIIIp1lPLFL/6w+Yl0GaKQe/BL7nT7Pq8vlMn2LbH9ALBN0VVtMxXLF94FFbe8haSlJQ21fWXVsaerZnnHyj6qtxmzMpsAFtl/rUfqnbh4hVjY2t/0EgKQDqg2pcyR9gdiAuQlwF9F1K7Vf89L6qKbrrzRdH0IMNiclzUrMho4FtidKsPXmQmBfYOYRsNzj8MxiE3PD2aDMkjZ5C3gBmJ+YqV0C2AxpReyXsd8i6g5fSlQiWKU8719EMf2+BpkHlxjfov4VKqZKzowOUFmevqGPS92T/iHaI44jcmUgZpDqWig6dZcrSreW1YHrJS1AFAuvq/8gKmHcKOl0SRvS95t7rUh6iljZ+QuwvO1tbV9ccVjdoq/fsSn53fsJsDywO/1tOLPvJD5k3DIj/HsojH0Trnw/yhAyb9QQbtgGmJdoWLMIcGw5vgAQG52idONZxED050QKwNbxpfgxUXGkx9noU0STAYDTsP81BefXtXJmdOAO6uXYWsAPmPRTXl0taXs7SdtDLHep5tNHqTvYPkTSscCbtsdLepuJS2y1Y/tS4NKS770l0TLx45JOBS61PbzSANtrpbrXkZ2OPd10fcE+rj/bx3MbM5JnI53NpAPYQ5F2x16EuMO2v9DoNLYBzHt9aVZzB7zfKD6KfRcTrxvpPGJGExq5oPANoJFT/Fvst4FLkUaVuL8E/KpHrAcSqy1jibSC1I8cjA6Q7Xsa18syz+FE/sleXdJybFwp8N8oFr0kTV0tUhpsJG1g+4bm9pg9Pl/VuRMRjjfW84DzJM1HzBQdQpT1qhVJP7B9HHBMb5+hbe/b+ai6jP0S0n1E3ujGSHMRbXe3KI8YBdxDVHj4STm2IfYLTV9lDj5sZsqmJYBvwy7EJtvN54WZjinVIj4ADgcNB5DWAD4DXIA9rrzwmysLPFX+nbfp2GeBh4n3vvnLsbcniSReR7uXW2djv9jXf0cKWfS+BZK+RAxC3wN+bPvGikPqmFI54DDiBTycqLW6q+2bqowrpVZJOsr2EZLO7OVu2/5Wx4NKbSFpc9tXlHqqH2I7K4J0QqSEXENMiDVKOy1c7t0V++xSv7Pxmlwc++levs5iTBwwHoV9ZNN9o4lUxOeI0kpzfehx0pZEHuhY4AlgnqY4ngdWwR6NtDRwPzHx9AFR2mlxYvBrYFPsa5q+95HAEcQGp2UoOdmpbzkYHSBJdxG5JMfTS4J1N/S7LTsT1yKWSG63PbrikFJKKQ0msbJ4JLAGsfv9fuBY7EvK/bsyFYPRO6U7l4GlZoe5xsP7L8IL58NfDovvE53VIq/zQKKc2aeIweazRHWcY7FHNX2v1Ynl+7WIpfnXiGo6x2H/uelxcxBtk+cH/oD99Rb+d7pODkYHqNTWbPynmUlzVmy7q/rdKooLH2R7j6pjSWlqSPp/wHG2Xy+35wUOtF37km3dpmxOO5hY4Zm1cbzb/n7XmaQjytWhxIC3UTpqc+AW27v3+sRUiRyMpikiaUXgZ8AngcuIZO1TiK4ZP7edCdppUJN0r+1Vehwb4ShwnWpE0nCi+9JBwF7ALsCrtg/u94lp0Ck/6/9oNO9Q5KheZPvL1UaWmmVppzSlTgfOJ8rBvEq0l3sS+HQORFNNzChpQjHsslGvt+LYafCb3/ZvgX/bvrnkBa9VdVCpLYYwaavqcUTHpzQdyd30aUp9xPZZ5fqjkg4CDiktI1Oqg3OJ+qJnEik43yJb3NZVo+3tS5K+ArxI1JhM9fO/wJ2SLiVe11sB51QbUuopl+nTFCnFwJs7XpxH1F4TdMfGrVR/kr4MbET8Xg+3fW3FIaU2kLQZUfD+U0TK0dzAUbYv7/eJaVCStBoT64Tet1yMVgAACSVJREFUYvveKuNJH5aD0RZJut72hpM7VheS+itf1XUbt1I9SVoUWMr2n0vr2xkbuWYppcFL0oJMulmtr8L6qQK5TD9Ait64swMfK7ttGzOFcxObe2rJ9rCqY0ipnSTtAXwbmA9Ykqg3eBpQyw+Y3UjSD/u527Z/1LFgUkdI2oJo4flJoqD+EOARYLkq40qTyg1MA7cncA+wTPm3cfk/4OQK4+oISXtLmqfp9rySvltlTClNI3sTTRzeBLD9OJO2KEyD39u9XCB6kOdO+nr6EbE57THbixNpOH+rNqTUUy7Tt0jS92z37EVbe5Lus71yj2MfKomT0mAj6Q7bazZ+nyXNBIywvWLVsaVpr5T42Y8YiF5IlKgb1f+z0mAj6W7bq0saCaxi+wNJd9r+bNWxpYlyZrR1L5c/Zkg6TNIlkrqhHuEMamrqLGlGYJYK40lpWrlZ0qHAbKXt7UXAFRXHlKYxSfNJOoboxDMTsKrtg3MgWluvS5oTuAU4T9Ivgfcrjin1kDOjLZJ0v+0VJX0e+AlREP5Q22tWHFpbSTqeqNF2GlEmYy/gOdsHVhlXSlNL0gzELNnGRC74tcAZzj+StVH+fm0N/AY42fZbFYeU2kzRnvNdYvJtB+CjwHm2/1lpYGkSORhtUdNS3k+AB2yf3w3L1eUNe09iU4eA4cQbdtYbTYNeaROJ7VerjiVNe5I+AMYSM2PNb34iNjDNXUlgqS3Kyt21tjeqOpbUvxyMtkjSlcALRDL0asQnrzttr1RpYCmlASlpJ0cA+xCDEgHjgV/ZPrrK2FJKU0fS5cBOtt+oOpbUtxyMtqjUIPwyMSv6uKSFgBVsD684tLaQdKHtbSU9wKQzCgDkJo80WEk6ANgU+Lbtp8qxJYBTgWuy3W1Kg5ekC4nd9NcxsXoCtvetLKj0ITkYnQolX3Qp22eW5b05G29mdSNpIdsvlaLgH2L7mU7HlNK0IOle4Iu2R/c4vgDRhanWqTcp1ZmkXZpuNgY8sp2tfqcjWfS+RZKOAFYHhgJnAjMTva3XqTKudrH9Urn6XduT1OOTdCxZoy8NXjP3HIhC5I1KmrmKgFJKU0fSV4FFbJ9cbt8JLEAMSPP9ajqTpZ1atxWwBWXa3/aLwFyVRtQZX+zl2CYdjyKlaWdci/ellKZfPwAub7o9C7G/Y32iCkyajuTMaOvG2bYkw4TyEbUl6TvAd4ElJd3fdNdcZDeLNLitJOnNXo6Lpl7WKaVBZRbbzzXd/qvt14DX6v5+PRjlYLR1F0r6NTBP6Wn9LeD0imNqp/OBPxE1VQ9pOj6mvMBTGpRsz1h1DCmlaW7e5hu292m6uUCHY0mTkRuYpkLp0jKhQLbt6yoOqe0kLQk8b3uspPWBFYFzbL9ebWQppZRSkHQecJPt03sc3xNY3/b21USWepOD0RZ0cyFdSfcRG7cWIzrUXA4Mtb1plXGllFJKDZIWBC4jmhyMKIdXAz4CbGn7lapiSx+Wy/QtsD1e0juSPtqFhXQ/sP2+pK2BE23/qpTGSSmllKYLtkcBn5O0AbBcOXyV7RsqDCv1IQejrXsPeEBStxXS/bek7YGdgc3LsSx/k1JKabpTBp85AJ3O5WC0dVeVS7f5JlEW48e2n5K0OFFfNaWUUkppwDJnNKWUUkopVSZnRlskaSmizNFnaKpFaHuJyoJqo+xNn1JKKaV2yMFo684EjgBOAIYRy9eqNKL22q/8u1mlUaSUUkqpVnKZvkWS7rG9mqQHbK9Qjv3F9rpVx5ZSSimlNFjkzGjr3pM0A/C4pH2AF4AFK46p7SSN4cPL9G8AdwMH2n6y81GllFJKabDKmdEWSVoDeBiYB/gRMDdwvO3bKw2szSQdBbxItAcV8HXgE8CjwHdsr19ddCmllFIabHIwOpUkzWH77ck/sh4k3WF7zR7Hbre9lqSRtleqKraUUkopDT4zVB3AYCVpbUkPEbOjSFpJ0ikVh9UJH0jaVtIM5bJt0335ySallFJKA5KD0dadCHwJ+CeA7ZHAepVG1Bk7ADsBo8plJ2BHSbMB+1QZWEoppZQGn9zANBVsPydNUs1pfFWxdErZoLR5H3f/tZOxpJRSSmnwy5nR1j0n6XOAJc0i6SDKkn2dSVpE0qWSRkl6RdLFkhapOq6UUkopDU45GG3dXsDewMLA88DK5XbdnQlcDnySOPcryrGUUkoppQHL3fRpQCTdZ3vlyR1LKaWUUpoSmTM6QJJ+2M/dtv2jjgVTjdGSdgQuKLe3p2ziSimllFIaqJwZHSBJB/ZyeA5gN2B+23N2OKSOkjQEOAlYmyjldCuwr+1nKw0spZRSSoNSDkangqS5gP2IgeiFwM9tj6o2qs6TtL/tE6uOI6WUUkqDT25gaoGk+SQdA9xPpDqsavvgbhyIFt+vOoCUUkopDU6ZMzpAko4HtgZ+A6xg+62KQ5oeaPIPSSmllFL6sFymHyBJHwBjgfeZtP2liA1Mc1cSWIUkPWt7SNVxpJRSSmnwyZnRAbLdlakNksbQe+95AbN1OJyUUkop1UTOjKaUUkoppcp05SxfSimllFKaPuRgNKWUUkopVSYHoymllFJKqTI5GE0ppZRSSpXJwWhKKbWRpMUkPSzpdEkPShouaTZJe0i6S9JISRdLmr08/ixJp0q6UdKTkr4g6Xfla5zV9HU3lnSbpBGSLpJU61bEKaX6ysFoSim131LAybaXA14H/gO4xPYatlcCHibaCjfMC2wAHABcAZwALAesIGllSR8DDgM2sr0qcDfZCS2lNEhlndGUUmq/p2zfV67fAywGLF/aCs8DzAlc2/T4K2xb0gPAK7YfAJD0YHnuIsBngL9JApgFuK0D55FSStNcDkZTSqn9xjZdH080ijgL2NL2SEm7Auv38vgPejz3A+Lv9njgOtvbtynelFLqmFymTymlaswFvCRpZmCHAT73dmAdSZ8GkDS7pKWndYAppdQJORhNKaVqHA7cAVwHPDKQJ9p+FdgVuEDS/cTgdJlpHWBKKXVCtgNNKaWUUkqVyZnRlFJKKaVUmRyMppRSSimlyuRgNKWUUkopVSYHoymllFJKqTI5GE0ppZRSSpXJwWhKKaWUUqpMDkZTSimllFJlcjCaUkoppZQq8/8BPQyQDg6TjRAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 792x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(cv_scores)\n",
    "_, ax = plt.subplots(figsize=(11, 6))\n",
    "ax1 = sns.boxplot(x=\"name\", y=\"test_score\", data=df, order=order,ax=ax, showmeans=True)\n",
    "_, xtext = plt.xticks()\n",
    "for t in xtext:\n",
    "    t.set_rotation(\"vertical\")\n",
    "    \n",
    "medians = df.groupby(['name'],sort=False)['test_score'].median().values\n",
    "median_labels = [str(np.round(s, 5)) for s in medians]\n",
    "\n",
    "pos = range(len(medians))\n",
    "for tick,label in zip(pos,ax.get_xticklabels()):\n",
    "    ax1.text(pos[tick], medians[tick]-0.06, median_labels[tick], \n",
    "            horizontalalignment='center', size='x-large', color='red', weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6297830398606811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.43      0.19      0.26        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.59      0.63      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4839   12]\n",
      " [  38    9]]\n"
     ]
    }
   ],
   "source": [
    "import statistics as sta\n",
    "# Multi Voting Ensemble\n",
    "model1 = SGDClassifier(loss='modified_huber',penalty='none', alpha=0.01)\n",
    "model2 = DecisionTreeClassifier(max_depth=5, min_samples_split=70)\n",
    "model3 = AdaBoostClassifier(n_estimators=100, learning_rate=1)\n",
    "model4 = GaussianNB()\n",
    "model5 = QuadraticDiscriminantAnalysis()\n",
    "model6 = xgb.XGBClassifier(random_state=1,learning_rate=0.01, subsample= 0.8, \n",
    "                  colsample_bytree= 1.0, max_depth= 3, gamma=0.5, min_child_weight= 10)\n",
    "model7 = KNeighborsClassifier(2)\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "model4.fit(X_train,y_train)\n",
    "model5.fit(X_train,y_train)\n",
    "model6.fit(X_train,y_train)\n",
    "model7.fit(X_train,y_train)\n",
    "\n",
    "pred1 = model1.predict(X_test)\n",
    "pred2 = model2.predict(X_test)\n",
    "pred3 = model3.predict(X_test)\n",
    "pred4 = model4.predict(X_test)\n",
    "pred5 = model5.predict(X_test)\n",
    "pred6 = model6.predict(X_test)\n",
    "pred7 = model7.predict(X_test)\n",
    "\n",
    "#pred1[i], pred2[i], pred3[i], pred4[i], pred5[i], pred6[i], pred7[i]\n",
    "y_pred = np.array([])\n",
    "for i in range(0,len(X_test)):\n",
    "    y_pred = np.append(y_pred, sta.mode([pred1[i], pred2[i], pred3[i]]))\n",
    "    \n",
    "score = f1_score(y_test, y_pred, average='macro')\n",
    "print(score)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 执行反吹右侧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors\n",
      "0\n",
      "0.6098482928418842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.42      0.15      0.23        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.58      0.61      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4835   11]\n",
      " [  44    8]]\n",
      "1\n",
      "0.5766423833823402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.50      0.09      0.16        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.55      0.58      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4840    5]\n",
      " [  48    5]]\n",
      "2\n",
      "0.5530919957115811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.38      0.07      0.11        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4847    5]\n",
      " [  43    3]]\n",
      "3\n",
      "0.548125880139186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4853\n",
      "         1.0       0.21      0.07      0.10        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.60      0.53      0.55      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4842   11]\n",
      " [  42    3]]\n",
      "4\n",
      "0.5154613582701048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.20      0.02      0.04        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.59      0.51      0.52      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4844    4]\n",
      " [  49    1]]\n",
      "5\n",
      "0.6048841302434731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.50      0.14      0.21        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.57      0.60      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4848    6]\n",
      " [  38    6]]\n",
      "6\n",
      "0.5689645057201526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.40      0.09      0.14        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.54      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846    6]\n",
      " [  42    4]]\n",
      "7\n",
      "0.5403478370940391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4859\n",
      "         1.0       0.25      0.05      0.09        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.53      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4853    6]\n",
      " [  37    2]]\n",
      "8\n",
      "0.5481258801391861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4850\n",
      "         1.0       0.27      0.06      0.10        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.63      0.53      0.55      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4842    8]\n",
      " [  45    3]]\n",
      "9\n",
      "0.5885992664557493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.42      0.12      0.18        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.56      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4848    7]\n",
      " [  38    5]]\n",
      "10\n",
      "0.5617423464146292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.36      0.08      0.13        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.54      0.56      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4840    7]\n",
      " [  47    4]]\n",
      "11\n",
      "0.5292788165194164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4844\n",
      "         1.0       0.25      0.04      0.06        54\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.52      0.53      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4838    6]\n",
      " [  52    2]]\n",
      "12\n",
      "0.6050718164786606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.47      0.14      0.22        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.57      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4840    8]\n",
      " [  43    7]]\n",
      "13\n",
      "0.6089554962476333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.55      0.14      0.22        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.77      0.57      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4850    5]\n",
      " [  37    6]]\n",
      "14\n",
      "0.5942058763098418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4852\n",
      "         1.0       0.38      0.13      0.19        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.56      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4842   10]\n",
      " [  40    6]]\n",
      "15\n",
      "0.557742663656885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.43      0.07      0.12        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.53      0.56      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4851    4]\n",
      " [  40    3]]\n",
      "16\n",
      "0.5881341679902831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.38      0.12      0.18        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.56      0.59      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4838   10]\n",
      " [  44    6]]\n",
      "17\n",
      "0.5885992664557493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4856\n",
      "         1.0       0.38      0.12      0.18        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.56      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4848    8]\n",
      " [  37    5]]\n",
      "18\n",
      "0.5853063195003629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.42      0.11      0.18        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.55      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846    7]\n",
      " [  40    5]]\n",
      "19\n",
      "0.583742324771071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.45      0.11      0.17        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.55      0.58      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4845    6]\n",
      " [  42    5]]\n",
      "20\n",
      "0.6240356276476339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4842\n",
      "         1.0       0.60      0.16      0.25        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.80      0.58      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4836    6]\n",
      " [  47    9]]\n",
      "21\n",
      "0.5779741113622355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.38      0.10      0.16        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.55      0.58      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4841    8]\n",
      " [  44    5]]\n",
      "22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5746652772514842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4856\n",
      "         1.0       0.40      0.10      0.15        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.55      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4850    6]\n",
      " [  38    4]]\n",
      "23\n",
      "0.5975349219391947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.38      0.14      0.20        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.57      0.60      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4844   10]\n",
      " [  38    6]]\n",
      "24\n",
      "0.5869243179818129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.42      0.11      0.18        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.56      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4847    7]\n",
      " [  39    5]]\n",
      "25\n",
      "0.5500132403089045\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4853\n",
      "         1.0       0.25      0.07      0.11        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.53      0.55      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4844    9]\n",
      " [  42    3]]\n",
      "26\n",
      "0.5903343294022826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.62      0.11      0.19        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.81      0.55      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4849    3]\n",
      " [  41    5]]\n",
      "27\n",
      "0.6010863945722764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.55      0.13      0.21        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.77      0.56      0.60      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846    5]\n",
      " [  41    6]]\n",
      "28\n",
      "0.5628516338713616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.33      0.08      0.13        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.66      0.54      0.56      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4841    8]\n",
      " [  45    4]]\n",
      "29\n",
      "0.5822295872984927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4852\n",
      "         1.0       0.38      0.11      0.17        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.55      0.58      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4844    8]\n",
      " [  41    5]]\n",
      "30\n",
      "0.533745835316516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.25      0.04      0.07        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.52      0.53      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4845    6]\n",
      " [  45    2]]\n",
      "31\n",
      "0.5530919957115811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.43      0.06      0.11        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4847    4]\n",
      " [  44    3]]\n",
      "32\n",
      "0.5793477986309328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.45      0.10      0.16        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.55      0.58      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4842    6]\n",
      " [  45    5]]\n",
      "33\n",
      "0.4970736215217168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.00      0.00      0.00        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4841    6]\n",
      " [  51    0]]\n",
      "34\n",
      "0.5566693206799797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4844\n",
      "         1.0       0.31      0.07      0.12        54\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.65      0.54      0.56      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4835    9]\n",
      " [  50    4]]\n",
      "35\n",
      "0.6245696607352829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4849\n",
      "         1.0       0.57      0.16      0.25        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.78      0.58      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4843    6]\n",
      " [  41    8]]\n",
      "36\n",
      "0.5881341679902831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4843\n",
      "         1.0       0.55      0.11      0.18        55\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.77      0.55      0.59      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4838    5]\n",
      " [  49    6]]\n",
      "37\n",
      "0.5170937333373575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4854\n",
      "         1.0       0.14      0.02      0.04        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.57      0.51      0.52      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4848    6]\n",
      " [  43    1]]\n",
      "38\n",
      "0.583742324771071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.36      0.11      0.17        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.67      0.56      0.58      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4845    9]\n",
      " [  39    5]]\n",
      "39\n",
      "0.5728798779158492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.29      0.10      0.15        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.55      0.57      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4837   12]\n",
      " [  44    5]]\n",
      "40\n",
      "0.5942058763098418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.67      0.11      0.19        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.83      0.56      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4842    3]\n",
      " [  47    6]]\n",
      "41\n",
      "0.599281440878146\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.43      0.13      0.20        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.57      0.60      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4845    8]\n",
      " [  39    6]]\n",
      "42\n",
      "0.5455105814670228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.30      0.06      0.10        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.53      0.55      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4839    7]\n",
      " [  49    3]]\n",
      "43\n",
      "0.5330448811968319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.29      0.04      0.07        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.52      0.53      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4844    5]\n",
      " [  47    2]]\n",
      "44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5885992664557493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.50      0.11      0.18        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.56      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4848    5]\n",
      " [  40    5]]\n",
      "45\n",
      "0.5539555242207925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4839\n",
      "         1.0       0.36      0.07      0.11        59\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.53      0.55      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4832    7]\n",
      " [  55    4]]\n",
      "46\n",
      "0.6104376412574481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.44      0.15      0.23        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.58      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4843    9]\n",
      " [  39    7]]\n",
      "47\n",
      "0.5510046934584922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.50      0.06      0.11        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4845    3]\n",
      " [  47    3]]\n",
      "48\n",
      "0.624569660735283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4848\n",
      "         1.0       0.62      0.16      0.25        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.80      0.58      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4843    5]\n",
      " [  42    8]]\n",
      "49\n",
      "0.5869243179818129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.45      0.11      0.18        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.55      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4847    6]\n",
      " [  40    5]]\n",
      "LogisticRegression\n",
      "0\n",
      "0.5812816304199152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4859\n",
      "         1.0       0.44      0.10      0.17        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.55      0.58      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4854    5]\n",
      " [  35    4]]\n",
      "1\n",
      "0.5184738749829025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.20      0.02      0.04        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.60      0.51      0.52      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4851    4]\n",
      " [  42    1]]\n",
      "2\n",
      "0.5368041932011388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.33      0.04      0.08        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.66      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4849    4]\n",
      " [  43    2]]\n",
      "3\n",
      "0.5230524805248052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4863\n",
      "         1.0       0.20      0.03      0.05        35\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.60      0.51      0.52      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4859    4]\n",
      " [  34    1]]\n",
      "4\n",
      "0.5344708288662302\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4852\n",
      "         1.0       0.25      0.04      0.07        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.52      0.53      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4846    6]\n",
      " [  44    2]]\n",
      "5\n",
      "0.5310740265595326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.22      0.04      0.07        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.61      0.52      0.53      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4841    7]\n",
      " [  48    2]]\n",
      "6\n",
      "0.5778452698542993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4858\n",
      "         1.0       0.40      0.10      0.16        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.55      0.58      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4852    6]\n",
      " [  36    4]]\n",
      "7\n",
      "0.5317101153674549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4850\n",
      "         1.0       0.20      0.04      0.07        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.60      0.52      0.53      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4842    8]\n",
      " [  46    2]]\n",
      "8\n",
      "0.4972800985322795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4845    6]\n",
      " [  47    0]]\n",
      "9\n",
      "0.5553318807629152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.38      0.07      0.12        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.53      0.56      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4849    5]\n",
      " [  41    3]]\n",
      "10\n",
      "0.533745835316516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.25      0.04      0.07        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.52      0.53      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4845    6]\n",
      " [  45    2]]\n",
      "11\n",
      "0.542342095967365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4856\n",
      "         1.0       0.67      0.05      0.09        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.83      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4855    1]\n",
      " [  40    2]]\n",
      "12\n",
      "0.5631661092530658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4860\n",
      "         1.0       0.38      0.08      0.13        38\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.54      0.56      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4855    5]\n",
      " [  35    3]]\n",
      "13\n",
      "0.5490541851686603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4844\n",
      "         1.0       0.75      0.06      0.10        54\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.87      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.98      4898\n",
      "\n",
      "[[4843    1]\n",
      " [  51    3]]\n",
      "14\n",
      "0.6143043001917283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.47      0.16      0.23        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.58      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4845    8]\n",
      " [  38    7]]\n",
      "15\n",
      "0.5676597799046337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.50      0.08      0.14        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.54      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4845    4]\n",
      " [  45    4]]\n",
      "16\n",
      "0.5541917854908895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.30      0.07      0.11        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.65      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4848    7]\n",
      " [  40    3]]\n",
      "17\n",
      "0.5184738749829025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.20      0.02      0.04        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.60      0.51      0.52      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4851    4]\n",
      " [  42    1]]\n",
      "18\n",
      "0.5939986737400531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4857\n",
      "         1.0       0.45      0.12      0.19        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.56      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4851    6]\n",
      " [  36    5]]\n",
      "19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49722849517552864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4844    2]\n",
      " [  52    0]]\n",
      "20\n",
      "0.5158496620208795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.25      0.02      0.04        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.51      0.52      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4845    3]\n",
      " [  49    1]]\n",
      "21\n",
      "0.5368041932011388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.40      0.04      0.08        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4849    3]\n",
      " [  44    2]]\n",
      "22\n",
      "0.5200173201608952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4858\n",
      "         1.0       0.20      0.03      0.04        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.60      0.51      0.52      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4854    4]\n",
      " [  39    1]]\n",
      "23\n",
      "0.5510046934584922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.33      0.06      0.11        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.66      0.53      0.55      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4845    6]\n",
      " [  44    3]]\n",
      "24\n",
      "0.5394097934619067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.50      0.05      0.08        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4852    2]\n",
      " [  42    2]]\n",
      "25\n",
      "0.5368041932011388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.25      0.05      0.08        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4849    6]\n",
      " [  41    2]]\n",
      "26\n",
      "0.5959355727924828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4857\n",
      "         1.0       0.50      0.12      0.20        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.56      0.60      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4852    5]\n",
      " [  36    5]]\n",
      "27\n",
      "0.5352212231713528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4853\n",
      "         1.0       0.25      0.04      0.08        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.52      0.54      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4847    6]\n",
      " [  43    2]]\n",
      "28\n",
      "0.5520303123629271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4850\n",
      "         1.0       0.43      0.06      0.11        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846    4]\n",
      " [  45    3]]\n",
      "29\n",
      "0.5731623478104261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4856\n",
      "         1.0       0.36      0.10      0.15        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.55      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4849    7]\n",
      " [  38    4]]\n",
      "30\n",
      "0.5490541851686602\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.27      0.06      0.10        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.63      0.53      0.55      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4843    8]\n",
      " [  44    3]]\n",
      "31\n",
      "0.5434036840927735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4861\n",
      "         1.0       0.29      0.05      0.09        37\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.53      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4856    5]\n",
      " [  35    2]]\n",
      "32\n",
      "0.5423420959673652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4860\n",
      "         1.0       0.29      0.05      0.09        38\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.53      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4855    5]\n",
      " [  36    2]]\n",
      "33\n",
      "0.5403478370940391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.67      0.05      0.09        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.83      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4853    1]\n",
      " [  42    2]]\n",
      "34\n",
      "0.5376400574594705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.29      0.05      0.08        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4850    5]\n",
      " [  41    2]]\n",
      "35\n",
      "0.5317101153674549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.29      0.04      0.07        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.52      0.53      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4842    5]\n",
      " [  49    2]]\n",
      "36\n",
      "0.5565146530649202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.43      0.07      0.12        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.53      0.56      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4850    4]\n",
      " [  41    3]]\n",
      "37\n",
      "0.5530919957115811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.43      0.06      0.11        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4847    4]\n",
      " [  44    3]]\n",
      "38\n",
      "0.5337458353165159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4852\n",
      "         1.0       0.22      0.04      0.07        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.61      0.52      0.53      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4845    7]\n",
      " [  44    2]]\n",
      "39\n",
      "0.5170937333373575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4856\n",
      "         1.0       0.11      0.02      0.04        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.55      0.51      0.52      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4848    8]\n",
      " [  41    1]]\n",
      "40\n",
      "0.5646668717738352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4861\n",
      "         1.0       0.38      0.08      0.13        37\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.54      0.56      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4856    5]\n",
      " [  34    3]]\n",
      "41\n",
      "0.5586096772408559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4842\n",
      "         1.0       0.44      0.07      0.12        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.54      0.56      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4837    5]\n",
      " [  52    4]]\n",
      "42\n",
      "0.5530919957115811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.43      0.06      0.11        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4847    4]\n",
      " [  44    3]]\n",
      "43\n",
      "0.5359984842743464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.33      0.04      0.08        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.66      0.52      0.54      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4848    4]\n",
      " [  44    2]]\n",
      "44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5500132403089044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.43      0.06      0.11        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.53      0.55      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4844    4]\n",
      " [  47    3]]\n",
      "45\n",
      "0.5628516338713616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.50      0.08      0.13        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.74      0.54      0.56      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4841    4]\n",
      " [  49    4]]\n",
      "46\n",
      "0.5793477986309329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4850\n",
      "         1.0       0.38      0.10      0.16        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.55      0.58      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4842    8]\n",
      " [  43    5]]\n",
      "47\n",
      "0.5590186828809702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4858\n",
      "         1.0       0.33      0.07      0.12        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.66      0.54      0.56      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4852    6]\n",
      " [  37    3]]\n",
      "48\n",
      "0.5731623478104261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.40      0.09      0.15        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.55      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4849    6]\n",
      " [  39    4]]\n",
      "49\n",
      "0.49728009853227956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4850\n",
      "         1.0       0.00      0.00      0.00        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4845    5]\n",
      " [  48    0]]\n",
      "SGD\n",
      "0\n",
      "0.6802502799580189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4850\n",
      "         1.0       0.44      0.31      0.37        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.65      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4831   19]\n",
      " [  33   15]]\n",
      "1\n",
      "0.7111216267187874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.50      0.37      0.43        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.68      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4839   16]\n",
      " [  27   16]]\n",
      "2\n",
      "0.6708130164935021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.46      0.28      0.35        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.64      0.67      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4836   15]\n",
      " [  34   13]]\n",
      "3\n",
      "0.6187192343796506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4852\n",
      "         1.0       0.25      0.24      0.24        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.62      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4819   33]\n",
      " [  35   11]]\n",
      "4\n",
      "0.7294425445798622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4859\n",
      "         1.0       0.44      0.49      0.46        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.74      0.73      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   24]\n",
      " [  20   19]]\n",
      "5\n",
      "0.663991219043699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4850\n",
      "         1.0       0.43      0.27      0.33        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.63      0.66      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4833   17]\n",
      " [  35   13]]\n",
      "6\n",
      "0.7133338951942165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      4859\n",
      "         1.0       0.39      0.49      0.43        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.74      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4829   30]\n",
      " [  20   19]]\n",
      "7\n",
      "0.6107852217762685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4850\n",
      "         1.0       0.29      0.19      0.23        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.59      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4828   22]\n",
      " [  39    9]]\n",
      "8\n",
      "0.5357118675670806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4855\n",
      "         1.0       0.07      0.09      0.08        43\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.53      0.54      0.54      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4803   52]\n",
      " [  39    4]]\n",
      "9\n",
      "0.6618637632277089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4860\n",
      "         1.0       0.34      0.32      0.33        38\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.67      0.66      0.66      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4837   23]\n",
      " [  26   12]]\n",
      "10\n",
      "0.6898380483480299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.44      0.34      0.38        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.67      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   19]\n",
      " [  29   15]]\n",
      "11\n",
      "0.6950021659085986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.52      0.32      0.39        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.66      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4837   14]\n",
      " [  32   15]]\n",
      "12\n",
      "0.6246114051684909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4850\n",
      "         1.0       0.29      0.23      0.26        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.61      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4823   27]\n",
      " [  37   11]]\n",
      "13\n",
      "0.6768392553503031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4854\n",
      "         1.0       0.36      0.36      0.36        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.67      0.68      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4825   29]\n",
      " [  28   16]]\n",
      "14\n",
      "0.6536922941431121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4853\n",
      "         1.0       0.34      0.29      0.31        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.67      0.64      0.65      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4828   25]\n",
      " [  32   13]]\n",
      "15\n",
      "0.7383966244725739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.58      0.41      0.48        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.79      0.71      0.74      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4838   14]\n",
      " [  27   19]]\n",
      "16\n",
      "0.6832658731109142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4852\n",
      "         1.0       0.40      0.35      0.37        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.67      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4828   24]\n",
      " [  30   16]]\n",
      "17\n",
      "0.6973741118319431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4854\n",
      "         1.0       0.41      0.39      0.40        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.69      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4830   24]\n",
      " [  27   17]]\n",
      "18\n",
      "0.7076915564863091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.47      0.38      0.42        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.69      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4823   23]\n",
      " [  32   20]]\n",
      "19\n",
      "0.6037449988232525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4850\n",
      "         1.0       0.25      0.19      0.21        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.59      0.60      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4823   27]\n",
      " [  39    9]]\n",
      "20\n",
      "0.6904006068097539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.44      0.35      0.39        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.67      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4827   22]\n",
      " [  32   17]]\n",
      "21\n",
      "0.6923872505722489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.45      0.34      0.39        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.67      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4836   18]\n",
      " [  29   15]]\n",
      "22\n",
      "0.6261680204982827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4842\n",
      "         1.0       0.38      0.20      0.26        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.60      0.63      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4824   18]\n",
      " [  45   11]]\n",
      "23\n",
      "0.6439406096766451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4859\n",
      "         1.0       0.31      0.28      0.29        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.65      0.64      0.64      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4834   25]\n",
      " [  28   11]]\n",
      "24\n",
      "0.7074576034260371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4849\n",
      "         1.0       0.53      0.35      0.42        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.67      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4834   15]\n",
      " [  32   17]]\n",
      "25\n",
      "0.6363075023155295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4854\n",
      "         1.0       0.31      0.25      0.28        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.65      0.62      0.64      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4830   24]\n",
      " [  33   11]]\n",
      "26\n",
      "0.5767595926345026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4854\n",
      "         1.0       0.19      0.14      0.16        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.59      0.57      0.58      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4829   25]\n",
      " [  38    6]]\n",
      "27\n",
      "0.5797295442064799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4850\n",
      "         1.0       0.19      0.15      0.17        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.59      0.57      0.58      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4821   29]\n",
      " [  41    7]]\n",
      "28\n",
      "0.6488763038101724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4842\n",
      "         1.0       0.39      0.25      0.30        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.62      0.65      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4820   22]\n",
      " [  42   14]]\n",
      "29\n",
      "0.6203173150848567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4844\n",
      "         1.0       0.37      0.19      0.25        54\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.59      0.62      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4827   17]\n",
      " [  44   10]]\n",
      "30\n",
      "0.645974301806435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4854\n",
      "         1.0       0.37      0.25      0.30        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.62      0.65      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   19]\n",
      " [  33   11]]\n",
      "31\n",
      "0.6510678043915336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4853\n",
      "         1.0       0.36      0.27      0.31        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.63      0.65      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4832   21]\n",
      " [  33   12]]\n",
      "32\n",
      "0.72110947560983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.49      0.41      0.45        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.74      0.70      0.72      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4832   20]\n",
      " [  27   19]]\n",
      "33\n",
      "0.7001132036636822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.46      0.36      0.41        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.68      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   19]\n",
      " [  28   16]]\n",
      "34\n",
      "0.6284163029139844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4842\n",
      "         1.0       0.34      0.21      0.26        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.67      0.60      0.63      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4819   23]\n",
      " [  44   12]]\n",
      "35\n",
      "0.6546752445580328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.48      0.23      0.31        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.74      0.62      0.65      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4839   12]\n",
      " [  36   11]]\n",
      "36\n",
      "0.6901457368648898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.47      0.33      0.39        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.66      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4831   18]\n",
      " [  33   16]]\n",
      "37\n",
      "0.710856175839745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4854\n",
      "         1.0       0.42      0.43      0.43        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.71      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4828   26]\n",
      " [  25   19]]\n",
      "38\n",
      "0.705446735395189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.47      0.38      0.42        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.69      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4822   23]\n",
      " [  33   20]]\n",
      "39\n",
      "0.7128743439333128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.52      0.37      0.43        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.68      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4836   16]\n",
      " [  29   17]]\n",
      "40\n",
      "0.7390618729156382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.51      0.46      0.48        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.73      0.74      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4832   20]\n",
      " [  25   21]]\n",
      "41\n",
      "0.7048464122689405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.45      0.39      0.41        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.69      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4833   21]\n",
      " [  27   17]]\n",
      "42\n",
      "0.6463902640264027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4845\n",
      "         1.0       0.32      0.28      0.30        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.66      0.64      0.65      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4813   32]\n",
      " [  38   15]]\n",
      "43\n",
      "0.6810756224524468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.47      0.30      0.37        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.65      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4827   18]\n",
      " [  37   16]]\n",
      "44\n",
      "0.6868234208287696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.45      0.33      0.38        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.66      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4838   17]\n",
      " [  29   14]]\n",
      "45\n",
      "0.654544566756547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4854\n",
      "         1.0       0.29      0.34      0.32        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.67      0.65      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4818   36]\n",
      " [  29   15]]\n",
      "46\n",
      "0.6779945892909639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4843\n",
      "         1.0       0.54      0.27      0.36        55\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.64      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4830   13]\n",
      " [  40   15]]\n",
      "47\n",
      "0.6419590643274854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4855\n",
      "         1.0       0.33      0.26      0.29        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.66      0.63      0.64      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4833   22]\n",
      " [  32   11]]\n",
      "48\n",
      "0.7001132036636822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.44      0.37      0.41        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.68      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   20]\n",
      " [  27   16]]\n",
      "49\n",
      "0.7074576034260371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.45      0.40      0.42        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.70      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4834   21]\n",
      " [  26   17]]\n",
      "RBF SVM\n",
      "0\n",
      "0.5577426636568849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.60      0.07      0.12        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.80      0.53      0.56      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4851    2]\n",
      " [  42    3]]\n",
      "1\n",
      "0.5500132403089045\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.75      0.06      0.11        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.87      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4844    1]\n",
      " [  50    3]]\n",
      "2\n",
      "0.5510046934584922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.43      0.06      0.11        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.53      0.55      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4845    4]\n",
      " [  46    3]]\n",
      "3\n",
      "0.6180504822491278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4856\n",
      "         1.0       0.75      0.14      0.24        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.87      0.57      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4854    2]\n",
      " [  36    6]]\n",
      "4\n",
      "0.5713767798877374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4863\n",
      "         1.0       0.50      0.09      0.15        35\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.54      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4860    3]\n",
      " [  32    3]]\n",
      "5\n",
      "0.6143043001917283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.41      0.16      0.23        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.58      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4845   10]\n",
      " [  36    7]]\n",
      "6\n",
      "0.5639961654341277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.44      0.08      0.13        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.54      0.56      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4842    5]\n",
      " [  47    4]]\n",
      "7\n",
      "0.5639961654341277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4852\n",
      "         1.0       0.29      0.09      0.13        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.54      0.56      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4842   10]\n",
      " [  42    4]]\n",
      "8\n",
      "0.5565146530649202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.50      0.07      0.12        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.53      0.56      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4850    3]\n",
      " [  42    3]]\n",
      "9\n",
      "0.5359984842743464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.40      0.04      0.08        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4848    3]\n",
      " [  45    2]]\n",
      "10\n",
      "0.5703147894093382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4848\n",
      "         1.0       0.80      0.08      0.15        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.90      0.54      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4847    1]\n",
      " [  46    4]]\n",
      "11\n",
      "0.5166650877857775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       1.00      0.02      0.04        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.99      0.51      0.52      4898\n",
      "weighted avg       0.99      0.99      0.98      4898\n",
      "\n",
      "[[4847    0]\n",
      " [  50    1]]\n",
      "12\n",
      "0.5689645057201526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4847\n",
      "         1.0       0.80      0.08      0.14        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.90      0.54      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846    1]\n",
      " [  47    4]]\n",
      "13\n",
      "0.5472267871815941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4842\n",
      "         1.0       0.75      0.05      0.10        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.87      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.98      4898\n",
      "\n",
      "[[4841    1]\n",
      " [  53    3]]\n",
      "14\n",
      "0.5732574825748258\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4862\n",
      "         1.0       0.75      0.08      0.15        36\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.87      0.54      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4861    1]\n",
      " [  33    3]]\n",
      "15\n",
      "0.5170937333373575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4853\n",
      "         1.0       0.17      0.02      0.04        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.58      0.51      0.52      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4848    5]\n",
      " [  44    1]]\n",
      "16\n",
      "0.5330448811968319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.50      0.04      0.07        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.74      0.52      0.53      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4844    2]\n",
      " [  50    2]]\n",
      "17\n",
      "0.6068494983277593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4859\n",
      "         1.0       0.71      0.13      0.22        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.85      0.56      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4857    2]\n",
      " [  34    5]]\n",
      "18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5921329101299627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.62      0.11      0.19        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.81      0.56      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4850    3]\n",
      " [  40    5]]\n",
      "19\n",
      "0.5140221729798793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4843\n",
      "         1.0       0.25      0.02      0.03        55\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.51      0.51      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4840    3]\n",
      " [  54    1]]\n",
      "20\n",
      "0.5520303123629271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.60      0.06      0.11        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.80      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846    2]\n",
      " [  47    3]]\n",
      "21\n",
      "0.5413244147157191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.67      0.05      0.09        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.83      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4854    1]\n",
      " [  41    2]]\n",
      "22\n",
      "0.5689645057201526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.44      0.09      0.14        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.54      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846    5]\n",
      " [  43    4]]\n",
      "23\n",
      "0.5376400574594706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.40      0.04      0.08        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4850    3]\n",
      " [  43    2]]\n",
      "24\n",
      "0.49738327347357614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4847    4]\n",
      " [  47    0]]\n",
      "25\n",
      "0.5330448811968319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.67      0.04      0.07        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.83      0.52      0.53      4898\n",
      "weighted avg       0.99      0.99      0.98      4898\n",
      "\n",
      "[[4844    1]\n",
      " [  51    2]]\n",
      "26\n",
      "0.5523633070512873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4867\n",
      "         1.0       0.33      0.06      0.11        31\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.66      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4863    4]\n",
      " [  29    2]]\n",
      "27\n",
      "0.5376400574594705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.50      0.04      0.08        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4850    2]\n",
      " [  44    2]]\n",
      "28\n",
      "0.6068837435021606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.50      0.14      0.22        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.57      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4849    6]\n",
      " [  37    6]]\n",
      "29\n",
      "0.5890633156834961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4860\n",
      "         1.0       0.67      0.11      0.18        38\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.83      0.55      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4858    2]\n",
      " [  34    4]]\n",
      "30\n",
      "0.5143660455662497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.20      0.02      0.03        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.59      0.51      0.51      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4841    4]\n",
      " [  52    1]]\n",
      "31\n",
      "0.5762251129287015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.67      0.09      0.16        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.83      0.54      0.58      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4851    2]\n",
      " [  41    4]]\n",
      "32\n",
      "0.5869916475803052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4863\n",
      "         1.0       0.40      0.11      0.18        35\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.56      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4857    6]\n",
      " [  31    4]]\n",
      "33\n",
      "0.5304574089290606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4844\n",
      "         1.0       0.33      0.04      0.07        54\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.66      0.52      0.53      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4840    4]\n",
      " [  52    2]]\n",
      "34\n",
      "0.5646668717738351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4857\n",
      "         1.0       0.75      0.07      0.13        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.87      0.54      0.56      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4856    1]\n",
      " [  38    3]]\n",
      "35\n",
      "0.5576255878414151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4841\n",
      "         1.0       0.44      0.07      0.12        57\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.53      0.56      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4836    5]\n",
      " [  53    4]]\n",
      "36\n",
      "0.5853063195003629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4849\n",
      "         1.0       0.62      0.10      0.18        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.81      0.55      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846    3]\n",
      " [  44    5]]\n",
      "37\n",
      "0.5394097934619067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.40      0.05      0.08        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4852    3]\n",
      " [  41    2]]\n",
      "38\n",
      "0.513688030676527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4842\n",
      "         1.0       0.25      0.02      0.03        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.51      0.51      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4839    3]\n",
      " [  55    1]]\n",
      "39\n",
      "0.6089554962476333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4859\n",
      "         1.0       0.40      0.15      0.22        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.58      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4850    9]\n",
      " [  33    6]]\n",
      "40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5703147894093382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4850\n",
      "         1.0       0.57      0.08      0.15        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.78      0.54      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4847    3]\n",
      " [  44    4]]\n",
      "41\n",
      "0.5731623478104261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.50      0.09      0.15        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.54      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4849    4]\n",
      " [  41    4]]\n",
      "42\n",
      "0.5445122431023013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4858\n",
      "         1.0       0.67      0.05      0.09        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.83      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4857    1]\n",
      " [  38    2]]\n",
      "43\n",
      "0.5376400574594705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4850\n",
      "         1.0       1.00      0.04      0.08        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       1.00      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4850    0]\n",
      " [  46    2]]\n",
      "44\n",
      "0.5639961654341277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.40      0.08      0.13        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.54      0.56      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4842    6]\n",
      " [  46    4]]\n",
      "45\n",
      "0.5376400574594705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4850\n",
      "         1.0       1.00      0.04      0.08        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       1.00      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4850    0]\n",
      " [  46    2]]\n",
      "46\n",
      "0.5703147894093382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.33      0.09      0.15        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.66      0.55      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4847    8]\n",
      " [  39    4]]\n",
      "47\n",
      "0.5481549815498156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4862\n",
      "         1.0       0.50      0.06      0.10        36\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4860    2]\n",
      " [  34    2]]\n",
      "48\n",
      "0.5689645057201526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4848\n",
      "         1.0       0.67      0.08      0.14        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.83      0.54      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846    2]\n",
      " [  46    4]]\n",
      "49\n",
      "0.5663982549698657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.57      0.08      0.14        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.78      0.54      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4844    3]\n",
      " [  47    4]]\n",
      "Decision Tree\n",
      "0\n",
      "0.6594003966718266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4857\n",
      "         1.0       0.41      0.27      0.32        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.63      0.66      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4841   16]\n",
      " [  30   11]]\n",
      "1\n",
      "0.5565146530649201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4860\n",
      "         1.0       0.23      0.08      0.12        38\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.61      0.54      0.56      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4850   10]\n",
      " [  35    3]]\n",
      "2\n",
      "0.6868234208287696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4859\n",
      "         1.0       0.40      0.36      0.38        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.68      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4838   21]\n",
      " [  25   14]]\n",
      "3\n",
      "0.72110947560983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00      4859\n",
      "         1.0       0.41      0.49      0.45        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.74      0.72      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4832   27]\n",
      " [  20   19]]\n",
      "4\n",
      "0.6777589178804985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4844\n",
      "         1.0       0.42      0.31      0.36        54\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.66      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4821   23]\n",
      " [  37   17]]\n",
      "5\n",
      "0.7084323557020858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4842\n",
      "         1.0       0.56      0.34      0.42        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.78      0.67      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4827   15]\n",
      " [  37   19]]\n",
      "6\n",
      "0.5500132403089045\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.30      0.06      0.11        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.65      0.53      0.55      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4844    7]\n",
      " [  44    3]]\n",
      "7\n",
      "0.6829734988693228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4847\n",
      "         1.0       0.37      0.37      0.37        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.68      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4815   32]\n",
      " [  32   19]]\n",
      "8\n",
      "0.6972182155367813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4843\n",
      "         1.0       0.51      0.33      0.40        55\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.66      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4826   17]\n",
      " [  37   18]]\n",
      "9\n",
      "0.636215092097445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.53      0.19      0.28        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.59      0.64      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4836    9]\n",
      " [  43   10]]\n",
      "10\n",
      "0.7048779865093265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4851\n",
      "         1.0       0.39      0.45      0.42        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.72      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4818   33]\n",
      " [  26   21]]\n",
      "11\n",
      "0.5566693206799797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.29      0.08      0.12        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.54      0.56      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4835   10]\n",
      " [  49    4]]\n",
      "12\n",
      "0.6825603781856999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4852\n",
      "         1.0       0.43      0.33      0.37        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.66      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4832   20]\n",
      " [  31   15]]\n",
      "13\n",
      "0.7294425445798622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4855\n",
      "         1.0       0.49      0.44      0.46        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.74      0.72      0.73      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   20]\n",
      " [  24   19]]\n",
      "14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6104376412574481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.47      0.15      0.23        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.57      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4843    8]\n",
      " [  40    7]]\n",
      "15\n",
      "0.6978408389882789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4858\n",
      "         1.0       0.47      0.35      0.40        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.67      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4842   16]\n",
      " [  26   14]]\n",
      "16\n",
      "0.49784703711297934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4857\n",
      "         1.0       0.00      0.00      0.00        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4856    1]\n",
      " [  41    0]]\n",
      "17\n",
      "0.7240718832741818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.48      0.43      0.45        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.74      0.71      0.72      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4823   24]\n",
      " [  29   22]]\n",
      "18\n",
      "0.7171444784244013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.46      0.42      0.44        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.71      0.72      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4834   21]\n",
      " [  25   18]]\n",
      "19\n",
      "0.6898380483480299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.44      0.34      0.38        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.67      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   19]\n",
      " [  29   15]]\n",
      "20\n",
      "0.6825603781856998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4854\n",
      "         1.0       0.41      0.34      0.37        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.67      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4832   22]\n",
      " [  29   15]]\n",
      "21\n",
      "0.6459743018064351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.50      0.21      0.30        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.60      0.65      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   11]\n",
      " [  41   11]]\n",
      "22\n",
      "0.6906111511903534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4843\n",
      "         1.0       0.47      0.33      0.39        55\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.66      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4823   20]\n",
      " [  37   18]]\n",
      "23\n",
      "0.5403478370940391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4857\n",
      "         1.0       0.33      0.05      0.09        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.66      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4853    4]\n",
      " [  39    2]]\n",
      "24\n",
      "0.6873520633940516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.50      0.31      0.38        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.65      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4834   15]\n",
      " [  34   15]]\n",
      "25\n",
      "0.6810756224524467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.40      0.34      0.37        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.67      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4827   24]\n",
      " [  31   16]]\n",
      "26\n",
      "0.697685423310359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4858\n",
      "         1.0       0.43      0.38      0.40        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.69      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4838   20]\n",
      " [  25   15]]\n",
      "27\n",
      "0.6453324576692179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4856\n",
      "         1.0       0.47      0.21      0.30        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.61      0.65      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846   10]\n",
      " [  33    9]]\n",
      "28\n",
      "0.7084323557020857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4852\n",
      "         1.0       0.43      0.41      0.42        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.70      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4827   25]\n",
      " [  27   19]]\n",
      "29\n",
      "0.5368041932011388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4849\n",
      "         1.0       1.00      0.04      0.08        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       1.00      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4849    0]\n",
      " [  47    2]]\n",
      "30\n",
      "0.6849269246603541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.45      0.32      0.38        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.66      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4833   18]\n",
      " [  32   15]]\n",
      "31\n",
      "0.7387503271605933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4854\n",
      "         1.0       0.51      0.45      0.48        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.73      0.74      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   19]\n",
      " [  24   20]]\n",
      "32\n",
      "0.521153896594727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4861\n",
      "         1.0       0.17      0.03      0.05        37\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.58      0.51      0.52      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4856    5]\n",
      " [  36    1]]\n",
      "33\n",
      "0.5651777337188394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.40      0.08      0.14        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.54      0.57      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4843    6]\n",
      " [  45    4]]\n",
      "34\n",
      "0.6855064299429998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.47      0.31      0.38        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.66      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4829   18]\n",
      " [  35   16]]\n",
      "35\n",
      "0.7479415397282833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4858\n",
      "         1.0       0.50      0.50      0.50        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.75      0.75      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4838   20]\n",
      " [  20   20]]\n",
      "36\n",
      "0.7420747761979989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00      4859\n",
      "         1.0       0.43      0.56      0.49        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.78      0.74      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4830   29]\n",
      " [  17   22]]\n",
      "37\n",
      "0.7398389529819194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4869\n",
      "         1.0       0.48      0.48      0.48        29\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.74      0.74      0.74      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4854   15]\n",
      " [  15   14]]\n",
      "38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5864507311307064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4843\n",
      "         1.0       0.30      0.13      0.18        55\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.65      0.56      0.59      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4827   16]\n",
      " [  48    7]]\n",
      "39\n",
      "0.7276725398511039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4857\n",
      "         1.0       0.52      0.41      0.46        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.71      0.73      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4841   16]\n",
      " [  24   17]]\n",
      "40\n",
      "0.553091995711581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4850\n",
      "         1.0       0.50      0.06      0.11        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4847    3]\n",
      " [  45    3]]\n",
      "41\n",
      "0.7738536231935531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00      4860\n",
      "         1.0       0.49      0.63      0.55        38\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.74      0.81      0.77      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   25]\n",
      " [  14   24]]\n",
      "42\n",
      "0.6756652422796392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4862\n",
      "         1.0       0.35      0.36      0.36        36\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.67      0.68      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4838   24]\n",
      " [  23   13]]\n",
      "43\n",
      "0.5252338105089411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4863\n",
      "         1.0       0.50      0.03      0.05        35\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.51      0.53      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4862    1]\n",
      " [  34    1]]\n",
      "44\n",
      "0.6789339626175226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4851\n",
      "         1.0       0.39      0.34      0.36        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.67      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4826   25]\n",
      " [  31   16]]\n",
      "45\n",
      "0.6261680204982827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4842\n",
      "         1.0       0.38      0.20      0.26        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.60      0.63      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4824   18]\n",
      " [  45   11]]\n",
      "46\n",
      "0.7397945631419902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      4850\n",
      "         1.0       0.47      0.50      0.48        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.75      0.74      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4823   27]\n",
      " [  24   24]]\n",
      "47\n",
      "0.6665976320648829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4858\n",
      "         1.0       0.39      0.30      0.34        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.65      0.67      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4839   19]\n",
      " [  28   12]]\n",
      "48\n",
      "0.6690637760347816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4857\n",
      "         1.0       0.41      0.29      0.34        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.64      0.67      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4840   17]\n",
      " [  29   12]]\n",
      "49\n",
      "0.7201654554595731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4858\n",
      "         1.0       0.50      0.40      0.44        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.70      0.72      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4842   16]\n",
      " [  24   16]]\n",
      "AdaBoost\n",
      "0\n",
      "0.7526273037571392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4843\n",
      "         1.0       0.58      0.45      0.51        55\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.79      0.73      0.75      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4825   18]\n",
      " [  30   25]]\n",
      "1\n",
      "0.7308711584873601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4859\n",
      "         1.0       0.50      0.44      0.47        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.72      0.73      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4842   17]\n",
      " [  22   17]]\n",
      "2\n",
      "0.6644056183624529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.48      0.26      0.33        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.74      0.63      0.66      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4843   12]\n",
      " [  32   11]]\n",
      "3\n",
      "0.6204593260719182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.41      0.18      0.25        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.59      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4834   13]\n",
      " [  42    9]]\n",
      "4\n",
      "0.7199062160462057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.50      0.40      0.44        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.70      0.72      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   18]\n",
      " [  27   18]]\n",
      "5\n",
      "0.7329594797203887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      4850\n",
      "         1.0       0.43      0.52      0.47        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.76      0.73      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4817   33]\n",
      " [  23   25]]\n",
      "6\n",
      "0.6445340300408285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4855\n",
      "         1.0       0.29      0.30      0.30        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.65      0.64      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4823   32]\n",
      " [  30   13]]\n",
      "7\n",
      "0.6598040859339449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.41      0.27      0.33        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.63      0.66      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4826   20]\n",
      " [  38   14]]\n",
      "8\n",
      "0.6921820010055304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00      4866\n",
      "         1.0       0.35      0.44      0.39        32\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.67      0.72      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4840   26]\n",
      " [  18   14]]\n",
      "9\n",
      "0.6738874570446736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4845\n",
      "         1.0       0.40      0.32      0.35        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.66      0.67      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4819   26]\n",
      " [  36   17]]\n",
      "10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7981454770245209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4853\n",
      "         1.0       0.60      0.60      0.60        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.80      0.80      0.80      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   18]\n",
      " [  18   27]]\n",
      "11\n",
      "0.6029528590960922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4856\n",
      "         1.0       0.40      0.14      0.21        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.57      0.60      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4847    9]\n",
      " [  36    6]]\n",
      "12\n",
      "0.5840265330478587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.30      0.12      0.17        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.65      0.56      0.58      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4835   14]\n",
      " [  43    6]]\n",
      "13\n",
      "0.6757913626735703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.44      0.30      0.36        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.65      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4829   19]\n",
      " [  35   15]]\n",
      "14\n",
      "0.6170682028597881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.35      0.18      0.24        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.67      0.59      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4832   17]\n",
      " [  40    9]]\n",
      "15\n",
      "0.6825603781856998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.48      0.30      0.37        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.74      0.65      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4832   16]\n",
      " [  35   15]]\n",
      "16\n",
      "0.6010863945722764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.46      0.13      0.21        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.57      0.60      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846    7]\n",
      " [  39    6]]\n",
      "17\n",
      "0.6898380483480299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00      4863\n",
      "         1.0       0.35      0.43      0.38        35\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.67      0.71      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   28]\n",
      " [  20   15]]\n",
      "18\n",
      "0.6205591962245954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4853\n",
      "         1.0       0.40      0.18      0.25        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.59      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4841   12]\n",
      " [  37    8]]\n",
      "19\n",
      "0.6825603781856999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.52      0.29      0.37        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.64      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4832   14]\n",
      " [  37   15]]\n",
      "20\n",
      "0.5762251129287015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.57      0.09      0.16        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.78      0.55      0.58      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4851    3]\n",
      " [  40    4]]\n",
      "21\n",
      "0.6318101137850679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.53      0.18      0.27        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.59      0.63      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4840    8]\n",
      " [  41    9]]\n",
      "22\n",
      "0.6789339626175225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.41      0.33      0.36        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.66      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4826   23]\n",
      " [  33   16]]\n",
      "23\n",
      "0.7448448393877167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4850\n",
      "         1.0       0.57      0.44      0.49        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.78      0.72      0.74      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4834   16]\n",
      " [  27   21]]\n",
      "24\n",
      "0.705477154803217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.50      0.36      0.42        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.68      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4837   16]\n",
      " [  29   16]]\n",
      "25\n",
      "0.7256354842029433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.56      0.38      0.46        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.78      0.69      0.73      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4837   14]\n",
      " [  29   18]]\n",
      "26\n",
      "0.6531175378793447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4842\n",
      "         1.0       0.57      0.21      0.31        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.78      0.61      0.65      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4833    9]\n",
      " [  44   12]]\n",
      "27\n",
      "0.6618637632277089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4853\n",
      "         1.0       0.43      0.27      0.33        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.63      0.66      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4837   16]\n",
      " [  33   12]]\n",
      "28\n",
      "0.7108561758397449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.51      0.37      0.43        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.68      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4828   18]\n",
      " [  33   19]]\n",
      "29\n",
      "0.711317116707503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.76      0.30      0.43        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.88      0.65      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4850    4]\n",
      " [  31   13]]\n",
      "30\n",
      "0.6848697144082639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4841\n",
      "         1.0       0.43      0.33      0.38        57\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.66      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4816   25]\n",
      " [  38   19]]\n",
      "31\n",
      "0.6310736784442618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4861\n",
      "         1.0       0.35      0.22      0.27        37\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.67      0.61      0.63      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846   15]\n",
      " [  29    8]]\n",
      "32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668480615118042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.52      0.25      0.34        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.63      0.67      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   12]\n",
      " [  38   13]]\n",
      "33\n",
      "0.6240356276476339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.45      0.18      0.25        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.59      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4836   11]\n",
      " [  42    9]]\n",
      "34\n",
      "0.6050718164786606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4858\n",
      "         1.0       0.28      0.17      0.22        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.59      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4840   18]\n",
      " [  33    7]]\n",
      "35\n",
      "0.6595906748138799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4858\n",
      "         1.0       0.35      0.30      0.32        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.67      0.65      0.66      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4836   22]\n",
      " [  28   12]]\n",
      "36\n",
      "0.679297346341281\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4850\n",
      "         1.0       0.48      0.29      0.36        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.74      0.64      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   15]\n",
      " [  34   14]]\n",
      "37\n",
      "0.645214540325194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4850\n",
      "         1.0       0.36      0.25      0.30        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.62      0.65      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4829   21]\n",
      " [  36   12]]\n",
      "38\n",
      "0.6459743018064351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4855\n",
      "         1.0       0.35      0.26      0.30        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.67      0.63      0.65      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   20]\n",
      " [  32   11]]\n",
      "39\n",
      "0.668480615118042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.45      0.28      0.34        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.64      0.67      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4835   16]\n",
      " [  34   13]]\n",
      "40\n",
      "0.7060606575289728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      4855\n",
      "         1.0       0.40      0.44      0.42        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.72      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4826   29]\n",
      " [  24   19]]\n",
      "41\n",
      "0.6670213354624002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.52      0.25      0.34        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.62      0.67      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4844   10]\n",
      " [  33   11]]\n",
      "42\n",
      "0.6066578470199879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4853\n",
      "         1.0       0.29      0.18      0.22        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.64      0.59      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4833   20]\n",
      " [  37    8]]\n",
      "43\n",
      "0.6330673858485971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4856\n",
      "         1.0       0.26      0.29      0.27        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.63      0.64      0.63      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4822   34]\n",
      " [  30   12]]\n",
      "44\n",
      "0.6745909231244211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4852\n",
      "         1.0       0.42      0.30      0.35        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.65      0.67      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4833   19]\n",
      " [  32   14]]\n",
      "45\n",
      "0.7622301241519922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4847\n",
      "         1.0       0.53      0.53      0.53        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.76      0.76      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4823   24]\n",
      " [  24   27]]\n",
      "46\n",
      "0.6524102972591332\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.52      0.22      0.31        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.61      0.65      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4838   10]\n",
      " [  39   11]]\n",
      "47\n",
      "0.623546362045899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4843\n",
      "         1.0       0.42      0.18      0.25        55\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.59      0.62      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4829   14]\n",
      " [  45   10]]\n",
      "48\n",
      "0.6205591962245955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4852\n",
      "         1.0       0.42      0.17      0.25        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.59      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4841   11]\n",
      " [  38    8]]\n",
      "49\n",
      "0.7308606360326946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00      4854\n",
      "         1.0       0.46      0.48      0.47        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.74      0.73      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4829   25]\n",
      " [  23   21]]\n",
      "Naive Bayes\n",
      "0\n",
      "0.6196814292915899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4851\n",
      "         1.0       0.17      0.47      0.25        47\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.58      0.72      0.62      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4746  105]\n",
      " [  25   22]]\n",
      "1\n",
      "0.6192576939795764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4848\n",
      "         1.0       0.18      0.42      0.25        50\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.59      0.70      0.62      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4752   96]\n",
      " [  29   21]]\n",
      "2\n",
      "0.6251541862119261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4863\n",
      "         1.0       0.17      0.51      0.26        35\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.59      0.75      0.63      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4778   85]\n",
      " [  17   18]]\n",
      "3\n",
      "0.6061386039631145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4856\n",
      "         1.0       0.16      0.38      0.22        42\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.58      0.68      0.61      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4771   85]\n",
      " [  26   16]]\n",
      "4\n",
      "0.6647706578995612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4846\n",
      "         1.0       0.25      0.56      0.34        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.62      0.77      0.66      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4757   89]\n",
      " [  23   29]]\n",
      "5\n",
      "0.6038315770012942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4851\n",
      "         1.0       0.15      0.43      0.22        47\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.57      0.70      0.60      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4738  113]\n",
      " [  27   20]]\n",
      "6\n",
      "0.6606388138294187\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4844\n",
      "         1.0       0.24      0.54      0.33        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.62      0.76      0.66      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4753   91]\n",
      " [  25   29]]\n",
      "7\n",
      "0.6005646682995555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.98      4861\n",
      "         1.0       0.14      0.54      0.22        37\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.57      0.76      0.60      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4733  128]\n",
      " [  17   20]]\n",
      "8\n",
      "0.6510543885360689\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4847\n",
      "         1.0       0.22      0.57      0.32        51\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.61      0.77      0.65      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4743  104]\n",
      " [  22   29]]\n",
      "9\n",
      "0.6374644314627052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4847\n",
      "         1.0       0.20      0.53      0.29        51\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.60      0.75      0.64      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4738  109]\n",
      " [  24   27]]\n",
      "10\n",
      "0.6299306757805504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.98      4846\n",
      "         1.0       0.18      0.60      0.28        52\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.59      0.78      0.63      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4705  141]\n",
      " [  21   31]]\n",
      "11\n",
      "0.5881753615447011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4853\n",
      "         1.0       0.13      0.36      0.19        45\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.56      0.67      0.59      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4746  107]\n",
      " [  29   16]]\n",
      "12\n",
      "0.6151506748012572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4849\n",
      "         1.0       0.17      0.45      0.24        49\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.58      0.71      0.62      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4740  109]\n",
      " [  27   22]]\n",
      "13\n",
      "0.6547877588954432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4848\n",
      "         1.0       0.23      0.56      0.32        50\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.61      0.77      0.65      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4752   96]\n",
      " [  22   28]]\n",
      "14\n",
      "0.63144144777223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4864\n",
      "         1.0       0.17      0.68      0.28        34\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.59      0.83      0.63      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4754  110]\n",
      " [  11   23]]\n",
      "15\n",
      "0.6417305032450261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4851\n",
      "         1.0       0.21      0.49      0.29        47\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.60      0.74      0.64      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4765   86]\n",
      " [  24   23]]\n",
      "16\n",
      "0.5694960487730822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4849\n",
      "         1.0       0.11      0.27      0.15        49\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.55      0.62      0.57      4898\n",
      "weighted avg       0.98      0.97      0.98      4898\n",
      "\n",
      "[[4742  107]\n",
      " [  36   13]]\n",
      "17\n",
      "0.6122826539289656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4854\n",
      "         1.0       0.16      0.50      0.24        44\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.58      0.74      0.61      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4736  118]\n",
      " [  22   22]]\n",
      "18\n",
      "0.6434484193011647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4851\n",
      "         1.0       0.20      0.57      0.30        47\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.60      0.78      0.64      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4745  106]\n",
      " [  20   27]]\n",
      "19\n",
      "0.6147406462585033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.98      4851\n",
      "         1.0       0.16      0.51      0.24        47\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.58      0.74      0.61      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4726  125]\n",
      " [  23   24]]\n",
      "20\n",
      "0.6095275213917482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4847\n",
      "         1.0       0.16      0.43      0.23        51\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.58      0.70      0.61      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4732  115]\n",
      " [  29   22]]\n",
      "21\n",
      "0.6487378083763626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4849\n",
      "         1.0       0.22      0.53      0.31        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.61      0.76      0.65      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4756   93]\n",
      " [  23   26]]\n",
      "22\n",
      "0.6002878509110332\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4854\n",
      "         1.0       0.15      0.41      0.21        44\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.57      0.69      0.60      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4748  106]\n",
      " [  26   18]]\n",
      "23\n",
      "0.6034021367078103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4845\n",
      "         1.0       0.17      0.32      0.22        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.58      0.65      0.60      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4760   85]\n",
      " [  36   17]]\n",
      "24\n",
      "0.6353938317924757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4853\n",
      "         1.0       0.20      0.47      0.28        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.60      0.72      0.64      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4770   83]\n",
      " [  24   21]]\n",
      "25\n",
      "0.6234016869267025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4852\n",
      "         1.0       0.18      0.46      0.26        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.59      0.72      0.62      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4757   95]\n",
      " [  25   21]]\n",
      "26\n",
      "0.6357274258849156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4862\n",
      "         1.0       0.18      0.67      0.28        36\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.59      0.82      0.64      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4753  109]\n",
      " [  12   24]]\n",
      "27\n",
      "0.6686738529734609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4838\n",
      "         1.0       0.26      0.53      0.35        60\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.63      0.76      0.67      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4747   91]\n",
      " [  28   32]]\n",
      "28\n",
      "0.6501193357536641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4853\n",
      "         1.0       0.22      0.51      0.31        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.61      0.75      0.65      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4773   80]\n",
      " [  22   23]]\n",
      "29\n",
      "0.5840363097464336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.98      4860\n",
      "         1.0       0.12      0.45      0.18        38\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.56      0.71      0.58      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4730  130]\n",
      " [  21   17]]\n",
      "30\n",
      "0.6155143424357832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4854\n",
      "         1.0       0.17      0.45      0.24        44\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.58      0.72      0.62      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4754  100]\n",
      " [  24   20]]\n",
      "31\n",
      "0.6412701991301628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4840\n",
      "         1.0       0.23      0.41      0.29        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.61      0.70      0.64      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4759   81]\n",
      " [  34   24]]\n",
      "32\n",
      "0.6280094174831017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4850\n",
      "         1.0       0.19      0.48      0.27        48\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.59      0.73      0.63      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4750  100]\n",
      " [  25   23]]\n",
      "33\n",
      "0.5929357988780387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4854\n",
      "         1.0       0.13      0.39      0.20        44\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.56      0.68      0.59      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4745  109]\n",
      " [  27   17]]\n",
      "34\n",
      "0.6257722281647711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4855\n",
      "         1.0       0.18      0.47      0.26        43\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.59      0.72      0.63      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4766   89]\n",
      " [  23   20]]\n",
      "35\n",
      "0.5717425827533129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4857\n",
      "         1.0       0.11      0.29      0.16        41\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.55      0.64      0.57      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4757  100]\n",
      " [  29   12]]\n",
      "36\n",
      "0.5933582399335824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4862\n",
      "         1.0       0.13      0.44      0.20        36\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.56      0.71      0.59      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4754  108]\n",
      " [  20   16]]\n",
      "37\n",
      "0.6074523471049559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4858\n",
      "         1.0       0.16      0.38      0.23        40\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.58      0.68      0.61      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4780   78]\n",
      " [  25   15]]\n",
      "38\n",
      "0.6409641777306895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4853\n",
      "         1.0       0.22      0.44      0.29        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.61      0.71      0.64      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4781   72]\n",
      " [  25   20]]\n",
      "39\n",
      "0.6114906799009572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4862\n",
      "         1.0       0.16      0.47      0.23        36\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.58      0.73      0.61      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4770   92]\n",
      " [  19   17]]\n",
      "40\n",
      "0.6212569351814263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4852\n",
      "         1.0       0.17      0.48      0.26        46\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.58      0.73      0.62      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4748  104]\n",
      " [  24   22]]\n",
      "41\n",
      "0.6051855019030329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4849\n",
      "         1.0       0.16      0.41      0.22        49\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.57      0.69      0.61      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4740  109]\n",
      " [  29   20]]\n",
      "42\n",
      "0.6121906670831598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.98      4855\n",
      "         1.0       0.15      0.53      0.24        43\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.58      0.75      0.61      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4729  126]\n",
      " [  20   23]]\n",
      "43\n",
      "0.5649163632724042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4853\n",
      "         1.0       0.10      0.27      0.14        45\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.55      0.62      0.56      4898\n",
      "weighted avg       0.98      0.97      0.98      4898\n",
      "\n",
      "[[4744  109]\n",
      " [  33   12]]\n",
      "44\n",
      "0.6416216126150862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4852\n",
      "         1.0       0.22      0.46      0.29        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.61      0.72      0.64      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4776   76]\n",
      " [  25   21]]\n",
      "45\n",
      "0.6208870975354207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4853\n",
      "         1.0       0.17      0.47      0.25        45\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.58      0.72      0.62      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4754   99]\n",
      " [  24   21]]\n",
      "46\n",
      "0.5913599659656639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4860\n",
      "         1.0       0.13      0.42      0.20        38\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.56      0.70      0.59      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4751  109]\n",
      " [  22   16]]\n",
      "47\n",
      "0.6148462687740819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4853\n",
      "         1.0       0.17      0.42      0.24        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.58      0.70      0.61      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4760   93]\n",
      " [  26   19]]\n",
      "48\n",
      "0.6434484193011647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4842\n",
      "         1.0       0.22      0.48      0.30        56\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.61      0.73      0.64      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4745   97]\n",
      " [  29   27]]\n",
      "49\n",
      "0.6266960542984561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4852\n",
      "         1.0       0.19      0.43      0.26        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.59      0.71      0.63      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4767   85]\n",
      " [  26   20]]\n",
      "XGBoost\n",
      "0\n",
      "0.7078282309430861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4857\n",
      "         1.0       0.62      0.32      0.42        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.81      0.66      0.71      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4849    8]\n",
      " [  28   13]]\n",
      "1\n",
      "0.5703147894093382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4850\n",
      "         1.0       0.57      0.08      0.15        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.78      0.54      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4847    3]\n",
      " [  44    4]]\n",
      "2\n",
      "0.5651777337188394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.50      0.08      0.14        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.54      0.57      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4843    4]\n",
      " [  47    4]]\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4974864060736637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.00      0.00      0.00        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4849    0]\n",
      " [  49    0]]\n",
      "4\n",
      "0.6950021659085986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4850\n",
      "         1.0       0.54      0.31      0.39        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.65      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4837   13]\n",
      " [  33   15]]\n",
      "5\n",
      "0.6228439425051335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.64      0.16      0.25        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.81      0.58      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4849    4]\n",
      " [  38    7]]\n",
      "6\n",
      "0.6690637760347816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.48      0.27      0.34        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.74      0.63      0.67      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4840   13]\n",
      " [  33   12]]\n",
      "7\n",
      "0.6143043001917283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.47      0.16      0.23        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.58      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4845    8]\n",
      " [  38    7]]\n",
      "8\n",
      "0.6258981816045357\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4855\n",
      "         1.0       0.33      0.21      0.26        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.66      0.60      0.63      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4837   18]\n",
      " [  34    9]]\n",
      "9\n",
      "0.4975894963586009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4851    1]\n",
      " [  46    0]]\n",
      "10\n",
      "0.6156460326562642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4857\n",
      "         1.0       0.60      0.15      0.24        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.80      0.57      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4853    4]\n",
      " [  35    6]]\n",
      "11\n",
      "0.5317101153674549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4843\n",
      "         1.0       0.67      0.04      0.07        55\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.83      0.52      0.53      4898\n",
      "weighted avg       0.99      0.99      0.98      4898\n",
      "\n",
      "[[4842    1]\n",
      " [  53    2]]\n",
      "12\n",
      "0.6424087740235979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4850\n",
      "         1.0       0.48      0.21      0.29        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.60      0.64      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4839   11]\n",
      " [  38   10]]\n",
      "13\n",
      "0.6424087740235979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.50      0.20      0.29        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.60      0.64      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4839   10]\n",
      " [  39   10]]\n",
      "14\n",
      "0.6297830398606811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4853\n",
      "         1.0       0.39      0.20      0.26        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.60      0.63      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4839   14]\n",
      " [  36    9]]\n",
      "15\n",
      "0.6360465759705304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4850\n",
      "         1.0       0.53      0.19      0.28        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.59      0.64      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4842    8]\n",
      " [  39    9]]\n",
      "16\n",
      "0.5344708288662302\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4853\n",
      "         1.0       0.22      0.04      0.07        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.61      0.52      0.53      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4846    7]\n",
      " [  43    2]]\n",
      "17\n",
      "0.6010863945722764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.46      0.13      0.21        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.57      0.60      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846    7]\n",
      " [  39    6]]\n",
      "18\n",
      "0.5385079239452013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.50      0.04      0.08        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4851    2]\n",
      " [  43    2]]\n",
      "19\n",
      "0.5385079239452014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.33      0.05      0.08        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.66      0.52      0.54      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4851    4]\n",
      " [  41    2]]\n",
      "20\n",
      "0.6979960949542698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4857\n",
      "         1.0       0.54      0.32      0.40        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.77      0.66      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846   11]\n",
      " [  28   13]]\n",
      "21\n",
      "0.6665976320648829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.50      0.26      0.34        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.63      0.67      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4839   12]\n",
      " [  35   12]]\n",
      "22\n",
      "0.6756652422796392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4859\n",
      "         1.0       0.38      0.33      0.36        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.66      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4838   21]\n",
      " [  26   13]]\n",
      "23\n",
      "0.6781902737785092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4860\n",
      "         1.0       0.38      0.34      0.36        38\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.69      0.67      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4839   21]\n",
      " [  25   13]]\n",
      "24\n",
      "0.6591329361002671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4855\n",
      "         1.0       0.53      0.23      0.32        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.62      0.66      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4846    9]\n",
      " [  33   10]]\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4972800985322796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.00      0.00      0.00        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4845    0]\n",
      " [  53    0]]\n",
      "26\n",
      "0.7171444784244012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4849\n",
      "         1.0       0.55      0.37      0.44        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.77      0.68      0.72      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4834   15]\n",
      " [  31   18]]\n",
      "27\n",
      "0.617068202859788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.36      0.18      0.24        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.59      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4832   16]\n",
      " [  41    9]]\n",
      "28\n",
      "0.6995172023432644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.47      0.35      0.40        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.67      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4827   20]\n",
      " [  33   18]]\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4976410256410256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4852    0]\n",
      " [  46    0]]\n",
      "30\n",
      "0.6402867130812843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4855\n",
      "         1.0       0.37      0.23      0.29        43\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.61      0.64      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4838   17]\n",
      " [  33   10]]\n",
      "31\n",
      "0.7044484563235205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4859\n",
      "         1.0       0.54      0.33      0.41        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.77      0.67      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4848   11]\n",
      " [  26   13]]\n",
      "32\n",
      "0.6123401281500753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.50      0.15      0.23        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.75      0.57      0.61      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4844    7]\n",
      " [  40    7]]\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49702197576504414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4840\n",
      "         1.0       0.00      0.00      0.00        58\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4840    0]\n",
      " [  58    0]]\n",
      "34\n",
      "0.6297830398606811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4852\n",
      "         1.0       0.41      0.20      0.26        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.60      0.63      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4839   13]\n",
      " [  37    9]]\n",
      "35\n",
      "0.6345152326060107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4842\n",
      "         1.0       0.46      0.20      0.28        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.72      0.60      0.63      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4829   13]\n",
      " [  45   11]]\n",
      "36\n",
      "0.6228439425051335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.70      0.15      0.25        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.85      0.58      0.62      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4849    3]\n",
      " [  39    7]]\n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49733169129720856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4846    0]\n",
      " [  52    0]]\n",
      "38\n",
      "0.7032682003834997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4857\n",
      "         1.0       0.47      0.37      0.41        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.73      0.68      0.70      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4840   17]\n",
      " [  26   15]]\n",
      "39\n",
      "0.6735390174790092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4857\n",
      "         1.0       0.62      0.24      0.35        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.81      0.62      0.67      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4851    6]\n",
      " [  31   10]]\n",
      "40\n",
      "0.6670213354624002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.52      0.25      0.34        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.62      0.67      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4844   10]\n",
      " [  33   11]]\n",
      "41\n",
      "0.678190273778509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.52      0.28      0.36        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.76      0.64      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4839   12]\n",
      " [  34   13]]\n",
      "42\n",
      "0.5753506473489518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4842\n",
      "         1.0       0.62      0.09      0.16        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.81      0.54      0.58      4898\n",
      "weighted avg       0.99      0.99      0.98      4898\n",
      "\n",
      "[[4839    3]\n",
      " [  51    5]]\n",
      "43\n",
      "0.5926181424999878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4844\n",
      "         1.0       0.67      0.11      0.19        54\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.83      0.56      0.59      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4841    3]\n",
      " [  48    6]]\n",
      "44\n",
      "0.654675244558033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4848\n",
      "         1.0       0.55      0.22      0.31        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.77      0.61      0.65      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4839    9]\n",
      " [  39   11]]\n",
      "45\n",
      "0.5510046934584922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       1.00      0.06      0.11        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.99      0.53      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4845    0]\n",
      " [  50    3]]\n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4976410256410256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4852    0]\n",
      " [  46    0]]\n",
      "47\n",
      "0.6890177534829722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.54      0.30      0.38        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.77      0.65      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4843   11]\n",
      " [  31   13]]\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4972800985322796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.00      0.00      0.00        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4845    0]\n",
      " [  53    0]]\n",
      "49\n",
      "0.6360465759705304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4858\n",
      "         1.0       0.36      0.23      0.28        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.61      0.64      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4842   16]\n",
      " [  31    9]]\n",
      "GradientBoost\n",
      "0\n",
      "0.4982585535750871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4864\n",
      "         1.0       0.00      0.00      0.00        34\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4864    0]\n",
      " [  34    0]]\n",
      "1\n",
      "0.4974864060736637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.00      0.00      0.00        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4849    0]\n",
      " [  49    0]]\n",
      "2\n",
      "0.4975894963586009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4851    0]\n",
      " [  47    0]]\n",
      "3\n",
      "0.4976410256410256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4852    0]\n",
      " [  46    0]]\n",
      "4\n",
      "0.4974864060736637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.00      0.00      0.00        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4849    0]\n",
      " [  49    0]]\n",
      "5\n",
      "0.4970736215217168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4841\n",
      "         1.0       0.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4841    0]\n",
      " [  57    0]]\n",
      "6\n",
      "0.4972800985322796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.00      0.00      0.00        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4845    0]\n",
      " [  53    0]]\n",
      "7\n",
      "0.4975894963586009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4851    0]\n",
      " [  47    0]]\n",
      "8\n",
      "0.4975894963586009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4851    0]\n",
      " [  47    0]]\n",
      "9\n",
      "0.4975894963586009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4851    0]\n",
      " [  47    0]]\n",
      "10\n",
      "0.4976925443544252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.00      0.00      0.00        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4853    0]\n",
      " [  45    0]]\n",
      "11\n",
      "0.49830994571340775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4865\n",
      "         1.0       0.00      0.00      0.00        33\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4865    0]\n",
      " [  33    0]]\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4976410256410256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4852    0]\n",
      " [  46    0]]\n",
      "13\n",
      "0.4974864060736637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.00      0.00      0.00        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4849    0]\n",
      " [  49    0]]\n",
      "14\n",
      "0.49733169129720856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4846    0]\n",
      " [  52    0]]\n",
      "15\n",
      "0.4978470371129793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4856\n",
      "         1.0       0.00      0.00      0.00        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4856    0]\n",
      " [  42    0]]\n",
      "16\n",
      "0.4976925443544252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.00      0.00      0.00        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4853    0]\n",
      " [  45    0]]\n",
      "17\n",
      "0.4975894963586009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4851    0]\n",
      " [  47    0]]\n",
      "18\n",
      "0.49733169129720856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4846    0]\n",
      " [  52    0]]\n",
      "19\n",
      "0.4973832734735762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.00      0.00      0.00        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4847    0]\n",
      " [  51    0]]\n",
      "20\n",
      "0.4976925443544252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.00      0.00      0.00        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4853    0]\n",
      " [  45    0]]\n",
      "21\n",
      "0.4972800985322796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.00      0.00      0.00        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4845    0]\n",
      " [  53    0]]\n",
      "22\n",
      "0.4976410256410256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4852    0]\n",
      " [  46    0]]\n",
      "23\n",
      "0.4976925443544252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.00      0.00      0.00        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4853    0]\n",
      " [  45    0]]\n",
      "24\n",
      "0.49733169129720856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4846    0]\n",
      " [  52    0]]\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4972800985322796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.00      0.00      0.00        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4845    0]\n",
      " [  53    0]]\n",
      "26\n",
      "0.4978470371129793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4856\n",
      "         1.0       0.00      0.00      0.00        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4856    0]\n",
      " [  42    0]]\n",
      "27\n",
      "0.4972800985322796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4845\n",
      "         1.0       0.00      0.00      0.00        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4845    0]\n",
      " [  53    0]]\n",
      "28\n",
      "0.4975894963586009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4851    0]\n",
      " [  47    0]]\n",
      "29\n",
      "0.49830994571340775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4865\n",
      "         1.0       0.00      0.00      0.00        33\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4865    0]\n",
      " [  33    0]]\n",
      "30\n",
      "0.4978985135827781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4857\n",
      "         1.0       0.00      0.00      0.00        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4857    0]\n",
      " [  41    0]]\n",
      "31\n",
      "0.4967118783394986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4834\n",
      "         1.0       0.00      0.00      0.00        64\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.97      0.99      0.98      4898\n",
      "\n",
      "[[4834    0]\n",
      " [  64    0]]\n",
      "32\n",
      "0.4974348450646419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4848\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4848    0]\n",
      " [  50    0]]\n",
      "33\n",
      "0.4976925443544252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.00      0.00      0.00        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4853    0]\n",
      " [  45    0]]\n",
      "34\n",
      "0.49733169129720856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4846    0]\n",
      " [  52    0]]\n",
      "35\n",
      "0.49733169129720856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4846    0]\n",
      " [  52    0]]\n",
      "36\n",
      "0.4974864060736637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.00      0.00      0.00        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4849    0]\n",
      " [  49    0]]\n",
      "37\n",
      "0.4976925443544252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4853\n",
      "         1.0       0.00      0.00      0.00        45\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4853    0]\n",
      " [  45    0]]\n",
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4974864060736637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.00      0.00      0.00        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4849    0]\n",
      " [  49    0]]\n",
      "39\n",
      "0.4975894963586009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4851    0]\n",
      " [  47    0]]\n",
      "40\n",
      "0.49774405250205084\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4854\n",
      "         1.0       0.00      0.00      0.00        44\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4854    0]\n",
      " [  44    0]]\n",
      "41\n",
      "0.49794997949979497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4858\n",
      "         1.0       0.00      0.00      0.00        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4858    0]\n",
      " [  40    0]]\n",
      "42\n",
      "0.4974864060736637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4849\n",
      "         1.0       0.00      0.00      0.00        49\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4849    0]\n",
      " [  49    0]]\n",
      "43\n",
      "0.49753795650389826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4850\n",
      "         1.0       0.00      0.00      0.00        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4850    0]\n",
      " [  48    0]]\n",
      "44\n",
      "0.49794997949979497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4858\n",
      "         1.0       0.00      0.00      0.00        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4858    0]\n",
      " [  40    0]]\n",
      "45\n",
      "0.4976410256410256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4852\n",
      "         1.0       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4852    0]\n",
      " [  46    0]]\n",
      "46\n",
      "0.4975894963586009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4851\n",
      "         1.0       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4851    0]\n",
      " [  47    0]]\n",
      "47\n",
      "0.49800143486727483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4859\n",
      "         1.0       0.00      0.00      0.00        39\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4859    0]\n",
      " [  39    0]]\n",
      "48\n",
      "0.4973832734735762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4847\n",
      "         1.0       0.00      0.00      0.00        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4847    0]\n",
      " [  51    0]]\n",
      "49\n",
      "0.49794997949979497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4858\n",
      "         1.0       0.00      0.00      0.00        40\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.50      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4858    0]\n",
      " [  40    0]]\n",
      "QDA\n",
      "0\n",
      "0.5634372662305623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4842\n",
      "         1.0       0.12      0.16      0.14        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.56      0.57      0.56      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4777   65]\n",
      " [  47    9]]\n",
      "1\n",
      "0.6382035751218792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4855\n",
      "         1.0       0.22      0.42      0.29        43\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.61      0.70      0.64      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4790   65]\n",
      " [  25   18]]\n",
      "2\n",
      "0.5819298781336681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      4853\n",
      "         1.0       0.11      0.47      0.18        45\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      4898\n",
      "   macro avg       0.55      0.72      0.58      4898\n",
      "weighted avg       0.99      0.96      0.97      4898\n",
      "\n",
      "[[4690  163]\n",
      " [  24   21]]\n",
      "3\n",
      "0.6651739647024995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      4862\n",
      "         1.0       0.27      0.44      0.34        36\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.63      0.72      0.67      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4819   43]\n",
      " [  20   16]]\n",
      "4\n",
      "0.5453589108910891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4858\n",
      "         1.0       0.08      0.12      0.10        40\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.54      0.56      0.55      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4803   55]\n",
      " [  35    5]]\n",
      "5\n",
      "0.6538247386249041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4855\n",
      "         1.0       0.21      0.67      0.32        43\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.60      0.83      0.65      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4746  109]\n",
      " [  14   29]]\n",
      "6\n",
      "0.5940132262805119\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4854\n",
      "         1.0       0.19      0.20      0.20        44\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.59      0.60      0.59      4898\n",
      "weighted avg       0.99      0.98      0.99      4898\n",
      "\n",
      "[[4815   39]\n",
      " [  35    9]]\n",
      "7\n",
      "0.5765284066820625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4842\n",
      "         1.0       0.19      0.14      0.16        56\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.59      0.57      0.58      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4807   35]\n",
      " [  48    8]]\n",
      "8\n",
      "0.6596962620781747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4839\n",
      "         1.0       0.32      0.34      0.33        59\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.65      0.67      0.66      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4796   43]\n",
      " [  39   20]]\n",
      "9\n",
      "0.6344018245905039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4850\n",
      "         1.0       0.21      0.44      0.28        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.60      0.71      0.63      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4769   81]\n",
      " [  27   21]]\n",
      "10\n",
      "0.5463554691117903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4852\n",
      "         1.0       0.20      0.07      0.10        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.60      0.53      0.55      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4840   12]\n",
      " [  43    3]]\n",
      "11\n",
      "0.5376282416642919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4844\n",
      "         1.0       0.08      0.09      0.09        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.54      0.54      0.54      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4787   57]\n",
      " [  49    5]]\n",
      "12\n",
      "0.5756551873510938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4850\n",
      "         1.0       0.21      0.12      0.16        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.60      0.56      0.58      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4828   22]\n",
      " [  42    6]]\n",
      "13\n",
      "0.5850768138837374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4862\n",
      "         1.0       0.15      0.22      0.18        36\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.57      0.61      0.59      4898\n",
      "weighted avg       0.99      0.98      0.99      4898\n",
      "\n",
      "[[4816   46]\n",
      " [  28    8]]\n",
      "14\n",
      "0.5166383768207476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4853\n",
      "         1.0       0.04      0.04      0.04        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.52      0.52      0.52      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4806   47]\n",
      " [  43    2]]\n",
      "15\n",
      "0.6692536937164054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      4850\n",
      "         1.0       0.27      0.50      0.35        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.63      0.74      0.67      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4784   66]\n",
      " [  24   24]]\n",
      "16\n",
      "0.5491336365605372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4864\n",
      "         1.0       0.10      0.12      0.11        34\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.54      0.55      0.55      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4826   38]\n",
      " [  30    4]]\n",
      "17\n",
      "0.5959780118908377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4852\n",
      "         1.0       0.15      0.33      0.20        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.57      0.65      0.60      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4766   86]\n",
      " [  31   15]]\n",
      "18\n",
      "0.5797295442064799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4841\n",
      "         1.0       0.26      0.12      0.17        57\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.56      0.58      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4821   20]\n",
      " [  50    7]]\n",
      "19\n",
      "0.6054164433749795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4846\n",
      "         1.0       0.20      0.25      0.22        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.59      0.62      0.61      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4793   53]\n",
      " [  39   13]]\n",
      "20\n",
      "0.6335370490859309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4847\n",
      "         1.0       0.26      0.29      0.28        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.63      0.64      0.63      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4804   43]\n",
      " [  36   15]]\n",
      "21\n",
      "0.6948108339661585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4852\n",
      "         1.0       0.35      0.46      0.40        46\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.67      0.72      0.69      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4813   39]\n",
      " [  25   21]]\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6477584528235085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4852\n",
      "         1.0       0.26      0.37      0.30        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.63      0.68      0.65      4898\n",
      "weighted avg       0.99      0.98      0.99      4898\n",
      "\n",
      "[[4803   49]\n",
      " [  29   17]]\n",
      "23\n",
      "0.5078785232560015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4856\n",
      "         1.0       0.02      0.02      0.02        42\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.51      0.51      0.51      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4816   40]\n",
      " [  41    1]]\n",
      "24\n",
      "0.6807860546603948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      4851\n",
      "         1.0       0.28      0.53      0.37        47\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.64      0.76      0.68      4898\n",
      "weighted avg       0.99      0.98      0.99      4898\n",
      "\n",
      "[[4788   63]\n",
      " [  22   25]]\n",
      "25\n",
      "0.5586096772408559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4856\n",
      "         1.0       0.17      0.10      0.12        42\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.58      0.55      0.56      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4837   19]\n",
      " [  38    4]]\n",
      "26\n",
      "0.5561201371245715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4858\n",
      "         1.0       0.10      0.15      0.12        40\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.55      0.57      0.56      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4805   53]\n",
      " [  34    6]]\n",
      "27\n",
      "0.589729381443299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4854\n",
      "         1.0       0.17      0.20      0.19        44\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.58      0.60      0.59      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4811   43]\n",
      " [  35    9]]\n",
      "28\n",
      "0.5984173207308028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4852\n",
      "         1.0       0.18      0.24      0.21        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.59      0.61      0.60      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4802   50]\n",
      " [  35   11]]\n",
      "29\n",
      "0.5697292269532864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4850\n",
      "         1.0       0.12      0.19      0.15        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.56      0.59      0.57      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4787   63]\n",
      " [  39    9]]\n",
      "30\n",
      "0.5901957960429312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.25      0.15      0.19        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.62      0.57      0.59      4898\n",
      "weighted avg       0.98      0.99      0.99      4898\n",
      "\n",
      "[[4830   21]\n",
      " [  40    7]]\n",
      "31\n",
      "0.6190139393749854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4863\n",
      "         1.0       0.17      0.46      0.25        35\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.58      0.72      0.62      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4785   78]\n",
      " [  19   16]]\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6124069505992272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      4853\n",
      "         1.0       0.17      0.40      0.24        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.58      0.69      0.61      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n",
      "[[4764   89]\n",
      " [  27   18]]\n",
      "33\n",
      "0.6101065790055574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4847\n",
      "         1.0       0.22      0.24      0.23        51\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.61      0.61      0.61      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4805   42]\n",
      " [  39   12]]\n",
      "34\n",
      "0.6147285283449265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.98      4848\n",
      "         1.0       0.16      0.58      0.25        50\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      4898\n",
      "   macro avg       0.58      0.77      0.61      4898\n",
      "weighted avg       0.99      0.96      0.97      4898\n",
      "\n",
      "[[4693  155]\n",
      " [  21   29]]\n",
      "35\n",
      "0.6677450799729729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4856\n",
      "         1.0       0.22      0.81      0.35        42\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.61      0.89      0.67      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4737  119]\n",
      " [   8   34]]\n",
      "36\n",
      "0.6178214731585518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4852\n",
      "         1.0       0.17      0.50      0.25        46\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.58      0.74      0.62      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4737  115]\n",
      " [  23   23]]\n",
      "37\n",
      "0.5432275627797708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4844\n",
      "         1.0       0.10      0.09      0.10        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.54      0.54      0.54      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4799   45]\n",
      " [  49    5]]\n",
      "38\n",
      "0.6834583586936915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4845\n",
      "         1.0       0.37      0.38      0.37        53\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.68      0.69      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4811   34]\n",
      " [  33   20]]\n",
      "39\n",
      "0.6611032096867192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4850\n",
      "         1.0       0.27      0.42      0.33        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.63      0.70      0.66      4898\n",
      "weighted avg       0.99      0.98      0.99      4898\n",
      "\n",
      "[[4797   53]\n",
      " [  28   20]]\n",
      "40\n",
      "0.7234223182818311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4848\n",
      "         1.0       0.43      0.48      0.45        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.71      0.74      0.72      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4816   32]\n",
      " [  26   24]]\n",
      "41\n",
      "0.617144024226348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4854\n",
      "         1.0       0.19      0.34      0.24        44\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.59      0.66      0.62      4898\n",
      "weighted avg       0.99      0.98      0.98      4898\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4790   64]\n",
      " [  29   15]]\n",
      "42\n",
      "0.587354171855427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98      4866\n",
      "         1.0       0.11      0.69      0.19        32\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      4898\n",
      "   macro avg       0.56      0.83      0.59      4898\n",
      "weighted avg       0.99      0.96      0.98      4898\n",
      "\n",
      "[[4693  173]\n",
      " [  10   22]]\n",
      "43\n",
      "0.7147364476136455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4856\n",
      "         1.0       0.30      0.86      0.44        42\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.65      0.92      0.71      4898\n",
      "weighted avg       0.99      0.98      0.99      4898\n",
      "\n",
      "[[4770   86]\n",
      " [   6   36]]\n",
      "44\n",
      "0.5606039018263755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4857\n",
      "         1.0       0.14      0.12      0.13        41\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.56      0.56      0.56      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4825   32]\n",
      " [  36    5]]\n",
      "45\n",
      "0.6138456629061627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4846\n",
      "         1.0       0.22      0.25      0.24        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.61      0.62      0.61      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4801   45]\n",
      " [  39   13]]\n",
      "46\n",
      "0.6443261538072957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.99      4858\n",
      "         1.0       0.19      0.75      0.30        40\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4898\n",
      "   macro avg       0.59      0.86      0.64      4898\n",
      "weighted avg       0.99      0.97      0.98      4898\n",
      "\n",
      "[[4730  128]\n",
      " [  10   30]]\n",
      "47\n",
      "0.7101432122144633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      4850\n",
      "         1.0       0.33      0.62      0.43        48\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.66      0.81      0.71      4898\n",
      "weighted avg       0.99      0.98      0.99      4898\n",
      "\n",
      "[[4788   62]\n",
      " [  18   30]]\n",
      "48\n",
      "0.6013975770267851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4840\n",
      "         1.0       0.27      0.17      0.21        58\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4898\n",
      "   macro avg       0.63      0.58      0.60      4898\n",
      "weighted avg       0.98      0.98      0.98      4898\n",
      "\n",
      "[[4813   27]\n",
      " [  48   10]]\n",
      "49\n",
      "0.5347570725220447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      4851\n",
      "         1.0       0.10      0.06      0.08        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.54      0.53      0.53      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4823   28]\n",
      " [  44    3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1944x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = .02  # step size in the mesh\n",
    "maxiteration = 50\n",
    "\n",
    "names = [\"Nearest Neighbors\", \n",
    "         \"LogisticRegression\",\n",
    "         \"SGD\",\n",
    "         #\"Linear SVM\", \n",
    "         \"RBF SVM\", \n",
    "         #\"Gaussian Process\",\n",
    "         \"Decision Tree\", \n",
    "         #\"Random Forest\", \n",
    "         #\"Neural Net\", \n",
    "         \"AdaBoost\",\n",
    "         \"Naive Bayes\",\n",
    "         \"XGBoost\",\n",
    "         \"GradientBoost\",\n",
    "         \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(2),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(loss='modified_huber',penalty='none', alpha=0.01),\n",
    "    #SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5, min_samples_split=70),\n",
    "    #RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    #MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(n_estimators=16, learning_rate=1),\n",
    "    GaussianNB(),\n",
    "    xgb.XGBClassifier(random_state=1,learning_rate=0.01, subsample= 0.8, colsample_bytree= 1.0, max_depth= 3, \n",
    "                      gamma=1, min_child_weight= 10),\n",
    "    GradientBoostingClassifier(learning_rate=0.01,random_state=1, loss='deviance', min_samples_leaf= 0.1, \n",
    "                               n_estimators= 10, min_samples_split= 0.1, max_features='log2', max_depth= 3),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "\n",
    "datasets = [[data1[col], data1[u\"执行反吹右侧\"]]]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 5))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "    cv_scores = {\"name\": [], \"test_score\": []}\n",
    "    order = []\n",
    "    \n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "\n",
    "        print(name)\n",
    "        order.append(name)\n",
    "        #ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        \n",
    "        for j in range(maxiteration):\n",
    "            print(j)\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=.3)\n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            #score = clf.score(X_test, y_test)\n",
    "            \n",
    "            #X_test = StandardScaler().fit_transform(X_test)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            score = f1_score(y_test, y_pred, average='macro')\n",
    "            print(score)\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "            cv_scores[\"name\"].append(name)\n",
    "            cv_scores[\"test_score\"].append(score)\n",
    "            \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Hyper Parameter Tuning\n",
    "#K nearest neighbour\n",
    "#None\n",
    "\n",
    "#SGD\n",
    "#https://www.kaggle.com/nsrose7224/sgdclassifier\n",
    "\n",
    "#Decision Tree\n",
    "#https://discuss.analyticsvidhya.com/t/extracting-the-best-fitted-decisiontreeclassifier-after-grid-search/10029\n",
    "\n",
    "#Adaboost\n",
    "#https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781787286382/9/ch09lvl1sec95/tuning-an-adaboost-regressor\n",
    "#http://www.davidsbatista.net/blog/2018/02/23/model_optimization/\n",
    "\n",
    "#Naive Bayes\n",
    "#None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3420364168756205\n",
      "{'penalty': 'none', 'alpha': 0.0001, 'loss': 'modified_huber'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "    \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"penalty\" : [\"l2\", \"l1\", \"none\"],\n",
    "}\n",
    "\n",
    "model = SGDClassifier(max_iter=1000)\n",
    "clf = GridSearchCV(model, param_grid=params, cv=3, n_jobs=-1,scoring='f1')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32805364141959187\n",
      "{'min_samples_split': 10, 'max_depth': 13}\n"
     ]
    }
   ],
   "source": [
    "parameters={'min_samples_split' : range(10,500,20),'max_depth': range(1,20,2)}\n",
    "clf_tree=DecisionTreeClassifier()\n",
    "clf=GridSearchCV(clf_tree, parameters, cv=3, n_jobs=-1, scoring='f1')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36610173615898667\n",
      "{'n_estimators': 50, 'learning_rate': 1}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    " 'n_estimators': [16, 32, 50, 100],\n",
    " 'learning_rate' : [0.01,0.05,0.1,0.3,1],\n",
    " }\n",
    "clf_ada = AdaBoostClassifier()\n",
    "clf=GridSearchCV(clf_ada, parameters, cv=3, n_jobs=-1, scoring='f1')\n",
    "\n",
    "y_train = y_train.rename(\"ResultRight\")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 864 candidates, totalling 2592 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 992 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1888 tasks      | elapsed:    8.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "{'loss': 'deviance', 'min_samples_leaf': 0.1, 'n_estimators': 10, 'min_samples_split': 0.1, 'max_features': 'log2', 'max_depth': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2592 out of 2592 | elapsed:   11.5s finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    #\"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    #\"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    #\"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "    }\n",
    "\n",
    "clf_gbc = GradientBoostingClassifier()\n",
    "clf=GridSearchCV(clf_gbc, parameters, cv=3, n_jobs=-1, scoring='f1',verbose=3)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "#model= GradientBoostingClassifier(learning_rate=0.01,random_state=1)\n",
    "#model.fit(X_train, y_train)\n",
    "#y_pred = model.predict(X_test)\n",
    "#score = f1_score(y_test, y_pred, average='macro')\n",
    "#print(score)\n",
    "#print(classification_report(y_test, y_pred))\n",
    "#print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49733169129720856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4846\n",
      "         1.0       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.49      0.50      0.50      4898\n",
      "weighted avg       0.98      0.99      0.98      4898\n",
      "\n",
      "[[4846    0]\n",
      " [  52    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model= GradientBoostingClassifier(learning_rate=0.01,random_state=1, loss='deviance', min_samples_leaf= 0.1, n_estimators= 10, min_samples_split= 0.1, max_features='log2', max_depth= 3)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "score = f1_score(y_test, y_pred, average='macro')\n",
    "print(score)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 405 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 472 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 760 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1112 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1215 out of 1215 | elapsed:   32.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2990455983508292\n",
      "{'subsample': 0.6, 'colsample_bytree': 1.0, 'max_depth': 3, 'gamma': 5, 'min_child_weight': 10}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "clf_xgb = xgb.XGBClassifier()\n",
    "clf=GridSearchCV(clf_xgb, parameters, cv=3, n_jobs=-1, scoring='f1',verbose=3)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "#model=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "#model.fit(X_train, y_train)\n",
    "#y_pred = model.predict(X_test)\n",
    "#score = f1_score(y_test, y_pred, average='macro')\n",
    "#print(score)\n",
    "#print(classification_report(y_test, y_pred))\n",
    "#print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6842492199019305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      4848\n",
      "         1.0       0.56      0.28      0.37        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.78      0.64      0.68      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4837   11]\n",
      " [  36   14]]\n"
     ]
    }
   ],
   "source": [
    "model=xgb.XGBClassifier(random_state=1,learning_rate=0.01, subsample= 0.8, colsample_bytree= 1.0, max_depth= 3, gamma=0.5, min_child_weight= 10)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "score = f1_score(y_test, y_pred, average='macro')\n",
    "print(score)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(cv_scores)\n",
    "_, ax = plt.subplots(figsize=(11, 6))\n",
    "ax1 = sns.boxplot(x=\"name\", y=\"test_score\", data=df, order=order,ax=ax, showmeans=True)\n",
    "_, xtext = plt.xticks()\n",
    "for t in xtext:\n",
    "    t.set_rotation(\"vertical\")\n",
    "    \n",
    "medians = df.groupby(['name'],sort=False)['test_score'].median().values\n",
    "median_labels = [str(np.round(s, 5)) for s in medians]\n",
    "\n",
    "pos = range(len(medians))\n",
    "for tick,label in zip(pos,ax.get_xticklabels()):\n",
    "    ax1.text(pos[tick], medians[tick]-0.06, median_labels[tick], \n",
    "            horizontalalignment='center', size='x-large', color='red', weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.627813213779663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4851\n",
      "         1.0       0.41      0.19      0.26        47\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4898\n",
      "   macro avg       0.70      0.59      0.63      4898\n",
      "weighted avg       0.99      0.99      0.99      4898\n",
      "\n",
      "[[4838   13]\n",
      " [  38    9]]\n"
     ]
    }
   ],
   "source": [
    "import statistics as sta\n",
    "# Multi Voting Ensemble\n",
    "model1 = SGDClassifier(loss='modified_huber',penalty='none', alpha=0.01)\n",
    "model2 = DecisionTreeClassifier(max_depth=5, min_samples_split=70)\n",
    "model3 = AdaBoostClassifier(n_estimators=100, learning_rate=1)\n",
    "model4 = GaussianNB()\n",
    "model5 = xgb.XGBClassifier(random_state=1,learning_rate=0.01, subsample= 0.8, \n",
    "                  colsample_bytree= 1.0, max_depth= 3, gamma=0.5, min_child_weight= 10)\n",
    "model6 = QuadraticDiscriminantAnalysis()\n",
    "model7 = KNeighborsClassifier(2)\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "model4.fit(X_train,y_train)\n",
    "model5.fit(X_train,y_train)\n",
    "model6.fit(X_train,y_train)\n",
    "model7.fit(X_train,y_train)\n",
    "\n",
    "pred1 = model1.predict(X_test)\n",
    "pred2 = model2.predict(X_test)\n",
    "pred3 = model3.predict(X_test)\n",
    "pred4 = model4.predict(X_test)\n",
    "pred5 = model5.predict(X_test)\n",
    "pred6 = model6.predict(X_test)\n",
    "pred7 = model7.predict(X_test)\n",
    "\n",
    "#pred1[i], pred2[i], pred3[i], pred4[i], pred5[i], pred6[i], pred7[i]\n",
    "y_pred = np.array([])\n",
    "for i in range(0,len(X_test)):\n",
    "    y_pred = np.append(y_pred, sta.mode([pred1[i], pred2[i], pred3[i]]))\n",
    "    \n",
    "score = f1_score(y_test, y_pred, average='macro')\n",
    "print(score)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cross Validation Tuning\n",
    "#https://www.kaggle.com/dansbecker/cross-validation\n",
    "#https://www.pythonforengineers.com/cross-validation-and-model-selection/\n",
    "#https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Model Ensemble\n",
    "# https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/\n",
    "# https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.71      0.83      3213\n",
      "         1.0       0.05      0.87      0.09        52\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      3265\n",
      "   macro avg       0.52      0.79      0.46      3265\n",
      "weighted avg       0.98      0.71      0.82      3265\n",
      "\n",
      "[[2288  925]\n",
      " [   7   45]]\n",
      "Linear SVM\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.52      0.68      3213\n",
      "         1.0       0.03      0.98      0.06        52\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      3265\n",
      "   macro avg       0.52      0.75      0.37      3265\n",
      "weighted avg       0.98      0.52      0.67      3265\n",
      "\n",
      "[[1663 1550]\n",
      " [   1   51]]\n",
      "RBF SVM\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.73      0.84      3211\n",
      "         1.0       0.02      0.30      0.03        54\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      3265\n",
      "   macro avg       0.50      0.51      0.43      3265\n",
      "weighted avg       0.97      0.72      0.82      3265\n",
      "\n",
      "[[2329  882]\n",
      " [  38   16]]\n",
      "Gaussian Process\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.62      0.77      3209\n",
      "         1.0       0.04      1.00      0.08        56\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      3265\n",
      "   macro avg       0.52      0.81      0.43      3265\n",
      "weighted avg       0.98      0.63      0.76      3265\n",
      "\n",
      "[[1999 1210]\n",
      " [   0   56]]\n",
      "Decision Tree\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.68      0.81      3216\n",
      "         1.0       0.04      0.98      0.08        49\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      3265\n",
      "   macro avg       0.52      0.83      0.45      3265\n",
      "weighted avg       0.99      0.68      0.80      3265\n",
      "\n",
      "[[2181 1035]\n",
      " [   1   48]]\n",
      "Random Forest\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.69      0.81      3216\n",
      "         1.0       0.05      1.00      0.09        49\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      3265\n",
      "   macro avg       0.52      0.84      0.45      3265\n",
      "weighted avg       0.99      0.69      0.80      3265\n",
      "\n",
      "[[2206 1010]\n",
      " [   0   49]]\n",
      "Neural Net\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.56      0.72      3213\n",
      "         1.0       0.04      1.00      0.07        52\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      3265\n",
      "   macro avg       0.52      0.78      0.39      3265\n",
      "weighted avg       0.98      0.57      0.71      3265\n",
      "\n",
      "[[1809 1404]\n",
      " [   0   52]]\n",
      "AdaBoost\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.64      0.78      3215\n",
      "         1.0       0.04      1.00      0.08        50\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      3265\n",
      "   macro avg       0.52      0.82      0.43      3265\n",
      "weighted avg       0.99      0.65      0.77      3265\n",
      "\n",
      "[[2057 1158]\n",
      " [   0   50]]\n",
      "Naive Bayes\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.54      0.70      3212\n",
      "         1.0       0.03      0.94      0.06        53\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      3265\n",
      "   macro avg       0.52      0.74      0.38      3265\n",
      "weighted avg       0.98      0.54      0.69      3265\n",
      "\n",
      "[[1727 1485]\n",
      " [   3   50]]\n",
      "QDA\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3213\n",
      "         1.0       0.02      1.00      0.03        52\n",
      "\n",
      "   micro avg       0.02      0.02      0.02      3265\n",
      "   macro avg       0.01      0.50      0.02      3265\n",
      "weighted avg       0.00      0.02      0.00      3265\n",
      "\n",
      "[[   0 3213]\n",
      " [   0   52]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1944x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = .02  # step size in the mesh\n",
    "maxiteration = 1\n",
    "\n",
    "names = [\"Nearest Neighbors\", \n",
    "         \"Linear SVM\", \n",
    "         \"RBF SVM\", \n",
    "         \"Gaussian Process\",\n",
    "         \"Decision Tree\", \n",
    "         \"Random Forest\", \n",
    "         \"Neural Net\", \n",
    "         \"AdaBoost\",\n",
    "         \"Naive Bayes\", \n",
    "         \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(2),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "\n",
    "datasets = [[data1[col], data1[u\"执行反吹左侧\"]]]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 5))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    #X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    cv_scores = {\"name\": [], \"test_score\": []}\n",
    "    order = []\n",
    "    \n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "\n",
    "        print(name)\n",
    "        order.append(name)\n",
    "        #ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        \n",
    "        for j in range(maxiteration):\n",
    "            print(j)\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=.2)\n",
    "            \n",
    "            # concatenate our training data back together\n",
    "            X_t = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "            # separate minority and majority classes\n",
    "            not_fraud = X_t[X_t[u\"执行反吹左侧\"]==0]\n",
    "            fraud = X_t[X_t[u\"执行反吹左侧\"]==1]\n",
    "            \n",
    "            # upsample minority\n",
    "            not_fraud_undersampled = resample(not_fraud,\n",
    "                                      replace=False, # sample with replacement\n",
    "                                      n_samples=len(fraud), # match number in majority class\n",
    "                                      random_state=27) # reproducible results\n",
    "\n",
    "            # combine majority and upsampled minority\n",
    "            undersampled = pd.concat([not_fraud_undersampled, fraud])\n",
    "            \n",
    "            y_train = undersampled[u\"执行反吹左侧\"]\n",
    "            X_train = undersampled.drop(u'执行反吹左侧', axis=1)\n",
    "            \n",
    "            X_train = StandardScaler().fit_transform(X_train)\n",
    "            \n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            #score = clf.score(X_test, y_test)\n",
    "            \n",
    "            X_test = StandardScaler().fit_transform(X_test)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            score = f1_score(y_test, y_pred, average='macro')\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "            cv_scores[\"name\"].append(name)\n",
    "            cv_scores[\"test_score\"].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(cv_scores)\n",
    "_, ax = plt.subplots(figsize=(11, 6))\n",
    "ax1 = sns.boxplot(x=\"name\", y=\"test_score\", data=df, order=order,ax=ax, showmeans=True)\n",
    "_, xtext = plt.xticks()\n",
    "for t in xtext:\n",
    "    t.set_rotation(\"vertical\")\n",
    "    \n",
    "medians = df.groupby(['name'],sort=False)['test_score'].median().values\n",
    "median_labels = [str(np.round(s, 5)) for s in medians]\n",
    "\n",
    "pos = range(len(medians))\n",
    "for tick,label in zip(pos,ax.get_xticklabels()):\n",
    "    ax1.text(pos[tick], medians[tick]-0.06, median_labels[tick], \n",
    "            horizontalalignment='center', size='x-large', color='red', weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44994755817764664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.68      0.81      3213\n",
      "         1.0       0.05      0.98      0.09        52\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      3265\n",
      "   macro avg       0.52      0.83      0.45      3265\n",
      "weighted avg       0.98      0.69      0.80      3265\n",
      "\n",
      "[[2186 1027]\n",
      " [   1   51]]\n"
     ]
    }
   ],
   "source": [
    "import statistics as sta\n",
    "# Multi Voting Ensemble\n",
    "model1 = SGDClassifier(loss='modified_huber',penalty='none', alpha=0.01)\n",
    "model2 = DecisionTreeClassifier(max_depth=5, min_samples_split=70)\n",
    "model3 = AdaBoostClassifier(n_estimators=100, learning_rate=1)\n",
    "model4 = GaussianNB()\n",
    "model5 = xgb.XGBClassifier(random_state=1,learning_rate=0.01, subsample= 0.8, \n",
    "                  colsample_bytree= 1.0, max_depth= 3, gamma=0.5, min_child_weight= 10)\n",
    "model6 = QuadraticDiscriminantAnalysis()\n",
    "model7 = KNeighborsClassifier(2)\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "model4.fit(X_train,y_train)\n",
    "model5.fit(X_train,y_train)\n",
    "model6.fit(X_train,y_train)\n",
    "model7.fit(X_train,y_train)\n",
    "\n",
    "pred1 = model1.predict(X_test)\n",
    "pred2 = model2.predict(X_test)\n",
    "pred3 = model3.predict(X_test)\n",
    "pred4 = model4.predict(X_test)\n",
    "pred5 = model5.predict(X_test)\n",
    "pred6 = model6.predict(X_test)\n",
    "pred7 = model7.predict(X_test)\n",
    "\n",
    "y_pred = np.array([])\n",
    "for i in range(0,len(X_test)):\n",
    "    y_pred = np.append(y_pred, sta.mode([pred1[i], pred2[i], pred3[i], pred4[i], pred5[i]]))\n",
    "    \n",
    "score = f1_score(y_test, y_pred, average='macro')\n",
    "print(score)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.92      0.95      3204\n",
      "         1.0       0.09      0.38      0.14        61\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      3265\n",
      "   macro avg       0.54      0.65      0.55      3265\n",
      "weighted avg       0.97      0.91      0.94      3265\n",
      "\n",
      "[[2961  243]\n",
      " [  38   23]]\n",
      "Linear SVM\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.58      0.73      3214\n",
      "         1.0       0.04      1.00      0.07        51\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      3265\n",
      "   macro avg       0.52      0.79      0.40      3265\n",
      "weighted avg       0.98      0.58      0.72      3265\n",
      "\n",
      "[[1854 1360]\n",
      " [   0   51]]\n",
      "RBF SVM\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.91      0.94      3200\n",
      "         1.0       0.01      0.05      0.02        65\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      3265\n",
      "   macro avg       0.49      0.48      0.48      3265\n",
      "weighted avg       0.96      0.90      0.93      3265\n",
      "\n",
      "[[2921  279]\n",
      " [  62    3]]\n",
      "Decision Tree\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.70      0.82      3205\n",
      "         1.0       0.06      0.97      0.11        60\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      3265\n",
      "   macro avg       0.53      0.83      0.46      3265\n",
      "weighted avg       0.98      0.70      0.81      3265\n",
      "\n",
      "[[2230  975]\n",
      " [   2   58]]\n",
      "Random Forest\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.70      0.82      3214\n",
      "         1.0       0.05      0.92      0.09        51\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      3265\n",
      "   macro avg       0.52      0.81      0.46      3265\n",
      "weighted avg       0.98      0.70      0.81      3265\n",
      "\n",
      "[[2254  960]\n",
      " [   4   47]]\n",
      "Neural Net\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.64      0.78      3207\n",
      "         1.0       0.05      0.95      0.09        58\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      3265\n",
      "   macro avg       0.52      0.80      0.44      3265\n",
      "weighted avg       0.98      0.65      0.77      3265\n",
      "\n",
      "[[2064 1143]\n",
      " [   3   55]]\n",
      "AdaBoost\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.75      0.85      3217\n",
      "         1.0       0.03      0.44      0.05        48\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      3265\n",
      "   macro avg       0.51      0.59      0.45      3265\n",
      "weighted avg       0.97      0.75      0.84      3265\n",
      "\n",
      "[[2420  797]\n",
      " [  27   21]]\n",
      "Naive Bayes\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.54      0.70      3213\n",
      "         1.0       0.03      0.94      0.06        52\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      3265\n",
      "   macro avg       0.52      0.74      0.38      3265\n",
      "weighted avg       0.98      0.54      0.69      3265\n",
      "\n",
      "[[1728 1485]\n",
      " [   3   49]]\n",
      "QDA\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3214\n",
      "         1.0       0.02      1.00      0.03        51\n",
      "\n",
      "   micro avg       0.02      0.02      0.02      3265\n",
      "   macro avg       0.01      0.50      0.02      3265\n",
      "weighted avg       0.00      0.02      0.00      3265\n",
      "\n",
      "[[   0 3214]\n",
      " [   0   51]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1944x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = .02  # step size in the mesh\n",
    "maxiteration = 1\n",
    "\n",
    "names = [\"Nearest Neighbors\", \n",
    "         \"Linear SVM\", \n",
    "         \"RBF SVM\", \n",
    "         #\"Gaussian Process\",\n",
    "         \"Decision Tree\", \n",
    "         \"Random Forest\", \n",
    "         \"Neural Net\", \n",
    "         \"AdaBoost\",\n",
    "         \"Naive Bayes\", \n",
    "         \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(2),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "\n",
    "datasets = [[data1[col], data1[u\"执行反吹左侧\"]]]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 5))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    #X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "    cv_scores = {\"name\": [], \"test_score\": []}\n",
    "    order = []\n",
    "    \n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "\n",
    "        print(name)\n",
    "        order.append(name)\n",
    "        #ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        \n",
    "        for j in range(maxiteration):\n",
    "            print(j)\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=.2)\n",
    "            \n",
    "            # concatenate our training data back together\n",
    "            X_t = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "            # separate minority and majority classes\n",
    "            not_fraud = X_t[X_t[u\"执行反吹左侧\"]==0]\n",
    "            fraud = X_t[X_t[u\"执行反吹左侧\"]==1]\n",
    "            \n",
    "            # upsample minority\n",
    "            fraud_upsampled = resample(fraud,\n",
    "                                      replace=True, # sample with replacement\n",
    "                                      n_samples=len(not_fraud), # match number in majority class\n",
    "                                      random_state=27) # reproducible results\n",
    "\n",
    "            # combine majority and upsampled minority\n",
    "            upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "            \n",
    "            y_train = upsampled[u\"执行反吹左侧\"]\n",
    "            X_train = upsampled.drop(u'执行反吹左侧', axis=1)\n",
    "            \n",
    "            X_train = StandardScaler().fit_transform(X_train)\n",
    "            \n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            #score = clf.score(X_test, y_test)\n",
    "            \n",
    "            X_test = StandardScaler().fit_transform(X_test)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            score = f1_score(y_test, y_pred, average='macro')\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "            cv_scores[\"name\"].append(name)\n",
    "            cv_scores[\"test_score\"].append(score)\n",
    "            \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(cv_scores)\n",
    "_, ax = plt.subplots(figsize=(11, 6))\n",
    "ax1 = sns.boxplot(x=\"name\", y=\"test_score\", data=df, order=order,ax=ax, showmeans=True)\n",
    "_, xtext = plt.xticks()\n",
    "for t in xtext:\n",
    "    t.set_rotation(\"vertical\")\n",
    "    \n",
    "medians = df.groupby(['name'],sort=False)['test_score'].median().values\n",
    "median_labels = [str(np.round(s, 5)) for s in medians]\n",
    "\n",
    "pos = range(len(medians))\n",
    "for tick,label in zip(pos,ax.get_xticklabels()):\n",
    "    ax1.text(pos[tick], medians[tick]-0.06, median_labels[tick], \n",
    "            horizontalalignment='center', size='x-large', color='red', weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4534095718976736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.69      0.81      3214\n",
      "         1.0       0.05      1.00      0.09        51\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      3265\n",
      "   macro avg       0.52      0.84      0.45      3265\n",
      "weighted avg       0.99      0.69      0.80      3265\n",
      "\n",
      "[[2209 1005]\n",
      " [   0   51]]\n"
     ]
    }
   ],
   "source": [
    "import statistics as sta\n",
    "# Multi Voting Ensemble\n",
    "model1 = SGDClassifier(loss='modified_huber',penalty='none', alpha=0.01)\n",
    "model2 = DecisionTreeClassifier(max_depth=5, min_samples_split=70)\n",
    "model3 = AdaBoostClassifier(n_estimators=100, learning_rate=1)\n",
    "model4 = GaussianNB()\n",
    "model5 = xgb.XGBClassifier(random_state=1,learning_rate=0.01, subsample= 0.8, \n",
    "                  colsample_bytree= 1.0, max_depth= 3, gamma=0.5, min_child_weight= 10)\n",
    "model6 = QuadraticDiscriminantAnalysis()\n",
    "model7 = KNeighborsClassifier(2)\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "model4.fit(X_train,y_train)\n",
    "model5.fit(X_train,y_train)\n",
    "model6.fit(X_train,y_train)\n",
    "model7.fit(X_train,y_train)\n",
    "\n",
    "pred1 = model1.predict(X_test)\n",
    "pred2 = model2.predict(X_test)\n",
    "pred3 = model3.predict(X_test)\n",
    "pred4 = model4.predict(X_test)\n",
    "pred5 = model5.predict(X_test)\n",
    "pred6 = model6.predict(X_test)\n",
    "pred7 = model7.predict(X_test)\n",
    "\n",
    "y_pred = np.array([])\n",
    "for i in range(0,len(X_test)):\n",
    "    y_pred = np.append(y_pred, sta.mode([pred1[i], pred2[i], pred3[i], pred4[i], pred5[i]]))\n",
    "    \n",
    "score = f1_score(y_test, y_pred, average='macro')\n",
    "print(score)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = [\"AirConditionDaily/空调数据采集7.15-7.16.csv\", \"AirConditionDaily/空调数据采集7.16-7.17.csv\",\n",
    "            \"AirConditionDaily/空调数据采集7.17-7.18.csv\", \"AirConditionDaily/空调数据采集7.18-7.19.csv\",\n",
    "            \"AirConditionDaily/空调数据采集7.19-7.20.csv\", \"AirConditionDaily/空调数据采集7.20-7.21.csv\",\n",
    "            \"AirConditionDaily/空调数据采集7.21-7.22.csv\", \"AirConditionDaily/空调数据采集7.22-7.23.csv\",\n",
    "            \"AirConditionDaily/空调数据采集7.23-7.24.csv\", \"AirConditionDaily/空调数据采集7.24-7.25.csv\",\n",
    "            \"AirConditionDaily/空调数据采集7.25-7.26.csv\", \"AirConditionDaily/空调数据采集7.26-7.27.csv\",\n",
    "            \"AirConditionDaily/空调数据采集7.27-7.28.csv\", \"AirConditionDaily/空调数据采集7.28-7.29.csv\",\n",
    "            \"AirConditionDaily/空调数据采集7.29-7.30.csv\", \"AirConditionDaily/空调数据采集7.30-7.31.csv\",\n",
    "            \"AirConditionDaily/空调数据采集7.31-8.1.csv\", \"AirConditionDaily/空调数据采集8.3-8.4.csv\"]\n",
    "\n",
    "data_train = []\n",
    "index = 1\n",
    "\n",
    "for file_ in datalist:\n",
    "    temp = pd.read_csv(file_, encoding = \"GB18030\")\n",
    "    #if len(temp.columns)>17:\n",
    "    #    temp.drop(u'更换散热器左侧', axis=1, inplace=True)\n",
    "    #    temp.drop(u'更换散热器右侧', axis=1, inplace=True)\n",
    "    #    temp[u'换件'] = 0\n",
    "    \n",
    "    #if index==12:\n",
    "    #    index += 1\n",
    "    temp[\"index\"] = index\n",
    "    data_train.append(temp)\n",
    "    index += 1\n",
    "\n",
    "#data_train01 = pd.read_csv(\"AirConditionDaily/空调数据采集7.15-7.16.csv\", encoding = \"GB18030\")\n",
    "#data_train02 = pd.read_csv(\"AirConditionDaily/空调数据采集7.16-7.17.csv\", encoding = \"GB18030\")\n",
    "#data_train03 = pd.read_csv(\"AirConditionDaily/空调数据采集7.17-7.18.csv\", encoding = \"GB18030\")\n",
    "#data_train04 = pd.read_csv(\"AirConditionDaily/空调数据采集7.18-7.19.csv\", encoding = \"GB18030\")\n",
    "#data_train05 = pd.read_csv(\"AirConditionDaily/空调数据采集7.19-7.20.csv\", encoding = \"GB18030\")\n",
    "\n",
    "data_train_new = pd.concat(data_train)\n",
    "\n",
    "data_train_new.drop(u'执行反吹左侧 (机器输出结果)', axis=1, inplace=True)\n",
    "data_train_new.drop(u'执行反吹右侧 (机器输出结果)', axis=1, inplace=True)\n",
    "data_train_new.drop(u'换件', axis=1, inplace=True)\n",
    "\n",
    "data_train_new.loc[data_train_new[u\"执行反吹左侧\"]==data_train_new[u\"执行反吹左侧\"],u\"执行反吹左侧\"] = 1\n",
    "data_train_new.loc[data_train_new[u\"执行反吹右侧\"]==data_train_new[u\"执行反吹右侧\"],u\"执行反吹右侧\"] = 1\n",
    "\n",
    "data_train_new[u\"执行反吹左侧\"].fillna(0,inplace=True)\n",
    "data_train_new[u\"执行反吹右侧\"].fillna(0,inplace=True)\n",
    "\n",
    "data_train_new[u\"左温差\"] = data_train_new[u\"左边L PACK\"] - data_train_new[u\"环境温度(℃)\"]\n",
    "data_train_new[u\"右温差\"] = data_train_new[u\"右边L PACK\"] - data_train_new[u\"环境温度(℃)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_new.drop_duplicates(subset=[u'日期', u'飞机号'], keep='first', inplace=True)\n",
    "data_train_new.drop_duplicates(subset=['index', u'飞机号'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>日期</th>\n",
       "      <th>地点</th>\n",
       "      <th>飞机号</th>\n",
       "      <th>机型</th>\n",
       "      <th>环境温度(℃)</th>\n",
       "      <th>左边CONT CABIN DUCT</th>\n",
       "      <th>左边L PACK</th>\n",
       "      <th>左边SUPPLY DUCT</th>\n",
       "      <th>右边FWD DUCT</th>\n",
       "      <th>右边AFT DUCT</th>\n",
       "      <th>右边L PACK</th>\n",
       "      <th>右边SUPPLY DUCT</th>\n",
       "      <th>执行反吹左侧</th>\n",
       "      <th>执行反吹右侧</th>\n",
       "      <th>index</th>\n",
       "      <th>左温差</th>\n",
       "      <th>右温差</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-16 11:44</td>\n",
       "      <td>XNN</td>\n",
       "      <td>7399</td>\n",
       "      <td>737-800</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-16 11:42</td>\n",
       "      <td>XNN</td>\n",
       "      <td>7398</td>\n",
       "      <td>737-800</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-16 11:06</td>\n",
       "      <td>CTU</td>\n",
       "      <td>6800</td>\n",
       "      <td>737-800</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-16 11:00</td>\n",
       "      <td>HHA</td>\n",
       "      <td>7377</td>\n",
       "      <td>737-800</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-16 09:14</td>\n",
       "      <td>XIY</td>\n",
       "      <td>1483</td>\n",
       "      <td>737-800</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-07-16 09:00</td>\n",
       "      <td>XMN</td>\n",
       "      <td>5522</td>\n",
       "      <td>737-800</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-07-16 08:59</td>\n",
       "      <td>XMN</td>\n",
       "      <td>1497</td>\n",
       "      <td>737-800</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-07-16 08:58</td>\n",
       "      <td>XMN</td>\n",
       "      <td>1785</td>\n",
       "      <td>737-800</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-07-16 08:58</td>\n",
       "      <td>XMN</td>\n",
       "      <td>1141</td>\n",
       "      <td>737-800</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-07-16 08:31</td>\n",
       "      <td>KMG</td>\n",
       "      <td>5292</td>\n",
       "      <td>737-700</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-20</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-07-16 08:27</td>\n",
       "      <td>PE?K</td>\n",
       "      <td>5687</td>\n",
       "      <td>737-800</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-07-16 08:20</td>\n",
       "      <td>URC</td>\n",
       "      <td>1569</td>\n",
       "      <td>737-800</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-07-16 08:07</td>\n",
       "      <td>KMG</td>\n",
       "      <td>6016</td>\n",
       "      <td>737-800</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-07-16 07:53</td>\n",
       "      <td>CGO</td>\n",
       "      <td>5406</td>\n",
       "      <td>737-800</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-07-16 07:31</td>\n",
       "      <td>HHA</td>\n",
       "      <td>7397</td>\n",
       "      <td>737-800</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-07-16 07:24</td>\n",
       "      <td>XIY</td>\n",
       "      <td>5581</td>\n",
       "      <td>737-800</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-07-16 07:22</td>\n",
       "      <td>PEK</td>\n",
       "      <td>5852</td>\n",
       "      <td>737-800</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-07-16 07:13</td>\n",
       "      <td>HAK</td>\n",
       "      <td>1215</td>\n",
       "      <td>737-800</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-07-16 07:12</td>\n",
       "      <td>HAK</td>\n",
       "      <td>5439</td>\n",
       "      <td>737-800</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-07-16 06:55</td>\n",
       "      <td>HAK</td>\n",
       "      <td>1928</td>\n",
       "      <td>737-800</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-07-16 06:54</td>\n",
       "      <td>ZGC</td>\n",
       "      <td>6060</td>\n",
       "      <td>737-800</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-07-16 06:54</td>\n",
       "      <td>ZGC</td>\n",
       "      <td>1501</td>\n",
       "      <td>737-800</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-07-16 06:52</td>\n",
       "      <td>ZGC</td>\n",
       "      <td>6065</td>\n",
       "      <td>737-800</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-07-16 06:50</td>\n",
       "      <td>FOC</td>\n",
       "      <td>1480</td>\n",
       "      <td>737-800</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-07-16 06:30</td>\n",
       "      <td>CGO</td>\n",
       "      <td>1587</td>\n",
       "      <td>737-800</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-07-16 06:09</td>\n",
       "      <td>PEK</td>\n",
       "      <td>1799</td>\n",
       "      <td>737-800</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-07-16 05:50</td>\n",
       "      <td>KMG</td>\n",
       "      <td>7988</td>\n",
       "      <td>737-800</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-07-16 05:38</td>\n",
       "      <td>KMG</td>\n",
       "      <td>5449</td>\n",
       "      <td>737-800</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-07-16 05:38</td>\n",
       "      <td>KMG</td>\n",
       "      <td>6015</td>\n",
       "      <td>737-800</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-07-16 05:37</td>\n",
       "      <td>CGO</td>\n",
       "      <td>1208</td>\n",
       "      <td>737-800</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2019-08-03 23:16</td>\n",
       "      <td>URC</td>\n",
       "      <td>7886</td>\n",
       "      <td>737-800</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-3</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2019-08-03 23:09</td>\n",
       "      <td>XIY</td>\n",
       "      <td>1997</td>\n",
       "      <td>737-800</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2019-08-03 22:54</td>\n",
       "      <td>SZX</td>\n",
       "      <td>1347</td>\n",
       "      <td>737-800</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2019-08-03 22:50</td>\n",
       "      <td>HAK</td>\n",
       "      <td>1548</td>\n",
       "      <td>737-800</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2019-08-03 22:50</td>\n",
       "      <td>HAK</td>\n",
       "      <td>5373</td>\n",
       "      <td>737-800</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2019-08-03 22:49</td>\n",
       "      <td>SZX</td>\n",
       "      <td>206G</td>\n",
       "      <td>737-800</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2019-08-03 22:48</td>\n",
       "      <td>HAK</td>\n",
       "      <td>7378</td>\n",
       "      <td>737-800</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2019-08-03 22:41</td>\n",
       "      <td>KMG</td>\n",
       "      <td>7167</td>\n",
       "      <td>737-800</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2019-08-03 22:38</td>\n",
       "      <td>HAK</td>\n",
       "      <td>5686</td>\n",
       "      <td>737-800</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2019-08-03 22:14</td>\n",
       "      <td>HAK</td>\n",
       "      <td>5090</td>\n",
       "      <td>737-800</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2019-08-03 22:12</td>\n",
       "      <td>XNN</td>\n",
       "      <td>7171</td>\n",
       "      <td>737-800</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2019-08-03 21:42</td>\n",
       "      <td>ZGC</td>\n",
       "      <td>5416</td>\n",
       "      <td>737-800</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2019-08-03 21:39</td>\n",
       "      <td>XUZ</td>\n",
       "      <td>7988</td>\n",
       "      <td>737-800</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2019-08-03 20:18</td>\n",
       "      <td>HAK</td>\n",
       "      <td>5083</td>\n",
       "      <td>737-800</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2019-08-03 19:24</td>\n",
       "      <td>URC</td>\n",
       "      <td>1568</td>\n",
       "      <td>737-800</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2019-08-03 18:43</td>\n",
       "      <td>XIY</td>\n",
       "      <td>5465</td>\n",
       "      <td>737-800</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2019-08-03 15:52</td>\n",
       "      <td>HAK</td>\n",
       "      <td>5418</td>\n",
       "      <td>737-800</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2019-08-03 15:00</td>\n",
       "      <td>CTU</td>\n",
       "      <td>6800</td>\n",
       "      <td>737-800</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2019-08-03 14:56</td>\n",
       "      <td>HAK</td>\n",
       "      <td>5638</td>\n",
       "      <td>737-800</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2019-08-03 08:09</td>\n",
       "      <td>PEK</td>\n",
       "      <td>7619</td>\n",
       "      <td>737-800</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2019-08-03 07:49</td>\n",
       "      <td>URC</td>\n",
       "      <td>1323</td>\n",
       "      <td>737-800</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2019-08-03 06:43</td>\n",
       "      <td>URC</td>\n",
       "      <td>206P</td>\n",
       "      <td>737-800</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2019-08-03 03:34</td>\n",
       "      <td>XUZ</td>\n",
       "      <td>1798</td>\n",
       "      <td>737-800</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2019-08-03 03:02</td>\n",
       "      <td>HAK</td>\n",
       "      <td>5611</td>\n",
       "      <td>737-800</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2019-08-03 02:30</td>\n",
       "      <td>XIY</td>\n",
       "      <td>1163</td>\n",
       "      <td>737-800</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2019-08-03 02:30</td>\n",
       "      <td>SYX</td>\n",
       "      <td>206F</td>\n",
       "      <td>737-800</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2019-08-03 01:46</td>\n",
       "      <td>PEK</td>\n",
       "      <td>5483</td>\n",
       "      <td>737-800</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2019-08-03 01:18</td>\n",
       "      <td>HAK</td>\n",
       "      <td>5623</td>\n",
       "      <td>737-800</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2019-08-03 00:57</td>\n",
       "      <td>XIY</td>\n",
       "      <td>1498</td>\n",
       "      <td>737-800</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2019-08-03 00:19</td>\n",
       "      <td>URC</td>\n",
       "      <td>2157</td>\n",
       "      <td>737-800</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3544 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   日期    地点   飞机号       机型  环境温度(℃)  左边CONT CABIN DUCT  \\\n",
       "0    2019-07-16 11:44   XNN  7399  737-800       20                  4   \n",
       "1    2019-07-16 11:42   XNN  7398  737-800       18                  5   \n",
       "2    2019-07-16 11:06   CTU  6800  737-800       23                  3   \n",
       "3    2019-07-16 11:00   HHA  7377  737-800       28                  6   \n",
       "4    2019-07-16 09:14   XIY  1483  737-800       25                  4   \n",
       "5    2019-07-16 09:00   XMN  5522  737-800       22                  9   \n",
       "6    2019-07-16 08:59   XMN  1497  737-800       29                  9   \n",
       "7    2019-07-16 08:58   XMN  1785  737-800       30                  4   \n",
       "8    2019-07-16 08:58   XMN  1141  737-800       30                  4   \n",
       "9    2019-07-16 08:31   KMG  5292  737-700       20                  0   \n",
       "10   2019-07-16 08:27  PE?K  5687  737-800       25                  5   \n",
       "11   2019-07-16 08:20   URC  1569  737-800       28                  4   \n",
       "12   2019-07-16 08:07   KMG  6016  737-800       20                  4   \n",
       "13   2019-07-16 07:53   CGO  5406  737-800       29                  6   \n",
       "14   2019-07-16 07:31   HHA  7397  737-800       30                  4   \n",
       "15   2019-07-16 07:24   XIY  5581  737-800       30                  7   \n",
       "16   2019-07-16 07:22   PEK  5852  737-800       27                  5   \n",
       "17   2019-07-16 07:13   HAK  1215  737-800       30                  4   \n",
       "18   2019-07-16 07:12   HAK  5439  737-800       28                  5   \n",
       "19   2019-07-16 06:55   HAK  1928  737-800       27                  6   \n",
       "20   2019-07-16 06:54   ZGC  6060  737-800       20                  6   \n",
       "21   2019-07-16 06:54   ZGC  1501  737-800       20                  4   \n",
       "22   2019-07-16 06:52   ZGC  6065  737-800       15                  4   \n",
       "23   2019-07-16 06:50   FOC  1480  737-800       28                  4   \n",
       "24   2019-07-16 06:30   CGO  1587  737-800       28                  4   \n",
       "25   2019-07-16 06:09  PEK   1799  737-800       32                  3   \n",
       "26   2019-07-16 05:50   KMG  7988  737-800       19                  3   \n",
       "27   2019-07-16 05:38   KMG  5449  737-800       20                  4   \n",
       "28   2019-07-16 05:38   KMG  6015  737-800       20                  4   \n",
       "29   2019-07-16 05:37   CGO  1208  737-800       32                  4   \n",
       "..                ...   ...   ...      ...      ...                ...   \n",
       "182  2019-08-03 23:16   URC  7886  737-800       35                  4   \n",
       "183  2019-08-03 23:09   XIY  1997  737-800       26                  6   \n",
       "184  2019-08-03 22:54   SZX  1347  737-800       28                  5   \n",
       "185  2019-08-03 22:50   HAK  1548  737-800       27                  4   \n",
       "186  2019-08-03 22:50   HAK  5373  737-800       27                  6   \n",
       "187  2019-08-03 22:49   SZX  206G  737-800       27                  4   \n",
       "188  2019-08-03 22:48   HAK  7378  737-800       26                  8   \n",
       "189  2019-08-03 22:41   KMG  7167  737-800       20                  5   \n",
       "190  2019-08-03 22:38   HAK  5686  737-800       27                  4   \n",
       "191  2019-08-03 22:14   HAK  5090  737-800       27                  2   \n",
       "192  2019-08-03 22:12   XNN  7171  737-800       15                  4   \n",
       "193  2019-08-03 21:42   ZGC  5416  737-800       25                  5   \n",
       "194  2019-08-03 21:39   XUZ  7988  737-800       29                  5   \n",
       "195  2019-08-03 20:18   HAK  5083  737-800       30                  6   \n",
       "196  2019-08-03 19:24   URC  1568  737-800       35                  6   \n",
       "197  2019-08-03 18:43   XIY  5465  737-800       28                  2   \n",
       "198  2019-08-03 15:52   HAK  5418  737-800       33                  4   \n",
       "200  2019-08-03 15:00   CTU  6800  737-800       30                  4   \n",
       "201  2019-08-03 14:56   HAK  5638  737-800       37                  8   \n",
       "212  2019-08-03 08:09   PEK  7619  737-800       27                  5   \n",
       "214  2019-08-03 07:49   URC  1323  737-800       26                  4   \n",
       "216  2019-08-03 06:43   URC  206P  737-800       27                  5   \n",
       "233  2019-08-03 03:34   XUZ  1798  737-800       27                  4   \n",
       "235  2019-08-03 03:02   HAK  5611  737-800       28                  6   \n",
       "238  2019-08-03 02:30   XIY  1163  737-800       24                  6   \n",
       "239  2019-08-03 02:30   SYX  206F  737-800       27                  3   \n",
       "244  2019-08-03 01:46   PEK  5483  737-800       30                  4   \n",
       "247  2019-08-03 01:18   HAK  5623  737-800       26                  5   \n",
       "251  2019-08-03 00:57   XIY  1498  737-800       25                  4   \n",
       "258  2019-08-03 00:19   URC  2157  737-800       29                  4   \n",
       "\n",
       "     左边L PACK  左边SUPPLY DUCT  右边FWD DUCT  右边AFT DUCT  右边L PACK  右边SUPPLY DUCT  \\\n",
       "0          22              0           5           4        23              0   \n",
       "1          23              0           4           6        23              0   \n",
       "2          29              0           4           3        28              0   \n",
       "3          34              0           7           6        30              0   \n",
       "4          28              0           4           4        32              0   \n",
       "5          36              0           8           9        37              0   \n",
       "6          37              0           4           3        36              0   \n",
       "7          30              0           8           8        32              0   \n",
       "8          34              0           5           5        32              0   \n",
       "9           0              6           0           0         0              5   \n",
       "10         32              0           5           5        32              0   \n",
       "11         28              0           3           3        27              0   \n",
       "12         29              0           4           4        26              0   \n",
       "13         22              0           6           6        24              0   \n",
       "14         34              0           5           4        32              0   \n",
       "15         26              0           5           4        24              0   \n",
       "16         31              0           5           4        30              0   \n",
       "17         34              0           5           5        37              0   \n",
       "18         35              0           6           6        35              0   \n",
       "19         28              0           8           8        34              0   \n",
       "20         26              0           6           8        24              0   \n",
       "21         28              0           8           8        24              0   \n",
       "22         26              0           5           6        24              0   \n",
       "23         30              0           5           4        32              0   \n",
       "24         32              0           5           4        33              0   \n",
       "25         33              0           3           3        31              0   \n",
       "26         31              0           5           4        32              0   \n",
       "27         28              0           4           5        26              0   \n",
       "28         24              0           3           4        23              0   \n",
       "29         31              0           4           4        28              0   \n",
       "..        ...            ...         ...         ...       ...            ...   \n",
       "182        32              0           4           4        27              0   \n",
       "183        30              0           4           4        31              0   \n",
       "184        35              0           4           4        31              0   \n",
       "185        34              0           4           3        32              0   \n",
       "186        33              0           9           8        34              0   \n",
       "187        34              0           4           4        34              0   \n",
       "188        36              0           5           6        35              0   \n",
       "189        28              0           6           6        25              0   \n",
       "190        34              0           6           5        33              0   \n",
       "191        32              0           2           4        31              0   \n",
       "192        24              0           2           4        26              0   \n",
       "193        24              0           4           3        23              0   \n",
       "194        35              0           5           4        35              0   \n",
       "195        28              0           6           5        35              0   \n",
       "196        30              0           6           7        30              0   \n",
       "197        28              0           3           3        30              0   \n",
       "198        35              0           4           5        35              0   \n",
       "200        32              0           4           4        29              0   \n",
       "201        37              0           8           8        37              0   \n",
       "212        28              0           5           4        28              0   \n",
       "214        28              0           5           4        28              0   \n",
       "216        27              0           5           5        26              0   \n",
       "233        36              0           4           4        30              0   \n",
       "235        36              0           7           6        33              0   \n",
       "238        35              0           4           4        33              0   \n",
       "239        33              0           3           3        31              0   \n",
       "244        28              0           4           4        27              0   \n",
       "247        34              0           8           6        32              0   \n",
       "251        23              0           4           5        24              0   \n",
       "258        27              0           4           6        26              0   \n",
       "\n",
       "     执行反吹左侧  执行反吹右侧  index  左温差  右温差  \n",
       "0         0       0      1    2    3  \n",
       "1         0       0      1    5    5  \n",
       "2         0       0      1    6    5  \n",
       "3         0       0      1    6    2  \n",
       "4         0       0      1    3    7  \n",
       "5         1       1      1   14   15  \n",
       "6         0       0      1    8    7  \n",
       "7         0       0      1    0    2  \n",
       "8         0       0      1    4    2  \n",
       "9         0       0      1  -20  -20  \n",
       "10        0       0      1    7    7  \n",
       "11        0       0      1    0   -1  \n",
       "12        0       0      1    9    6  \n",
       "13        0       0      1   -7   -5  \n",
       "14        0       0      1    4    2  \n",
       "15        0       0      1   -4   -6  \n",
       "16        0       0      1    4    3  \n",
       "17        0       0      1    4    7  \n",
       "18        0       0      1    7    7  \n",
       "19        0       0      1    1    7  \n",
       "20        0       0      1    6    4  \n",
       "21        0       0      1    8    4  \n",
       "22        0       0      1   11    9  \n",
       "23        0       0      1    2    4  \n",
       "24        0       0      1    4    5  \n",
       "25        0       0      1    1   -1  \n",
       "26        0       1      1   12   13  \n",
       "27        0       0      1    8    6  \n",
       "28        0       0      1    4    3  \n",
       "29        0       0      1   -1   -4  \n",
       "..      ...     ...    ...  ...  ...  \n",
       "182       0       0     18   -3   -8  \n",
       "183       0       0     18    4    5  \n",
       "184       0       0     18    7    3  \n",
       "185       0       0     18    7    5  \n",
       "186       0       0     18    6    7  \n",
       "187       0       0     18    7    7  \n",
       "188       1       1     18   10    9  \n",
       "189       0       0     18    8    5  \n",
       "190       0       0     18    7    6  \n",
       "191       0       0     18    5    4  \n",
       "192       0       0     18    9   11  \n",
       "193       0       0     18   -1   -2  \n",
       "194       0       0     18    6    6  \n",
       "195       0       0     18   -2    5  \n",
       "196       0       0     18   -5   -5  \n",
       "197       0       0     18    0    2  \n",
       "198       0       0     18    2    2  \n",
       "200       0       0     18    2   -1  \n",
       "201       0       0     18    0    0  \n",
       "212       0       0     18    1    1  \n",
       "214       0       0     18    2    2  \n",
       "216       0       0     18    0   -1  \n",
       "233       0       0     18    9    3  \n",
       "235       0       0     18    8    5  \n",
       "238       1       0     18   11    9  \n",
       "239       0       0     18    6    4  \n",
       "244       0       0     18   -2   -3  \n",
       "247       0       0     18    8    6  \n",
       "251       0       0     18   -2   -1  \n",
       "258       0       0     18   -2   -3  \n",
       "\n",
       "[3544 rows x 17 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_new.columns = ['Date','Location','PlaneNo','PlaneModel','EnvTemp','LEFT CONT CABIN DUCT', 'LEFT L PACK',\n",
    "                          'LEFT SUPPLY DUCT','RIGHT FWD DUCT','RIGHT AFT DUCT','RIGHT L PACK','RIGHT SUPPLY DUCT','Left Handle',\n",
    "                          'Right Handle', 'index','Left Temp Diff','Right Temp Diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_new_1 = data_train_new.copy()\n",
    "data_train_new_1[\"index\"] = data_train_new[\"index\"]+1\n",
    "data_train_new_2 = data_train_new.copy()\n",
    "data_train_new_2[\"index\"] = data_train_new[\"index\"]+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train_new.join(data_train_new, on=['index',''], rsuffix='_other')\n",
    "tmp = pd.merge(data_train_new, data_train_new_1, how='left', left_on = ['index', 'PlaneNo'], right_on = ['index','PlaneNo'],\n",
    "              suffixes =['','_Today-1'])\n",
    "data_train_new = pd.merge(tmp, data_train_new_2, how='left', left_on = ['index', 'PlaneNo'], right_on = ['index','PlaneNo'],\n",
    "                         suffixes =['','_Today-2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1.drop(u'更换部件', axis=1, inplace=True)\n",
    "#data1.drop(u'Fail', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.concat([data_train_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data1[data1[\"index\"]==index-1]#pd.read_csv(\"AirConditionDaily/空调数据采集7.22-7.23.csv\", encoding = \"GB18030\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test.loc[data_test[u\"执行反吹左侧\"]==data_test[u\"执行反吹左侧\"],u\"执行反吹左侧\"] = 1\n",
    "#data_test.loc[data_test[u\"执行反吹右侧\"]==data_test[u\"执行反吹右侧\"],u\"执行反吹右侧\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test[u\"执行反吹左侧\"].fillna(0,inplace=True)\n",
    "#data_test[u\"执行反吹右侧\"].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test[u\"执行反吹左侧\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test[u\"执行反吹右侧\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test[u\"左温差\"] = data_test[u\"左边L PACK\"] - data_test[u\"环境温度(℃)\"]\n",
    "#data_test[u\"右温差\"] = data_test[u\"右边L PACK\"] - data_test[u\"环境温度(℃)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1[data1[\"index\"]<index-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "col = [\"EnvTemp\", \"Left Temp Diff\",\"LEFT CONT CABIN DUCT\",\"LEFT L PACK\", \"LEFT SUPPLY DUCT\", \"Left Temp Diff_Today-1\", \n",
    "       \"Left Temp Diff_Today-2\", \"EnvTemp_Today-1\", \"EnvTemp_Today-2\", \"LEFT L PACK_Today-1\", \"LEFT L PACK_Today-2\",\n",
    "       \"Left Handle_Today-1\",\"Left Handle_Today-2\"]\n",
    "\n",
    "data1.dropna(inplace=True)\n",
    "data_test.fillna(0, inplace=True)\n",
    "\n",
    "X_train, y_train = data1[col], data1[\"Left Handle\"]\n",
    "X_test, y_test = data_test[col], data_test[\"Left Handle\"]\n",
    "\n",
    "\n",
    "\n",
    "#Under Sample\n",
    "# concatenate our training data back together\n",
    "X_t = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "not_fraud = X_t[X_t[\"Left Handle\"]==0]\n",
    "fraud = X_t[X_t[\"Left Handle\"]==1]\n",
    "\n",
    "# upsample minority\n",
    "not_fraud_undersampled = resample(not_fraud,\n",
    "                          replace=False, # sample with replacement\n",
    "                          n_samples=len(fraud)*10, # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "undersampled = pd.concat([not_fraud_undersampled, fraud])\n",
    "\n",
    "y_train = undersampled[\"Left Handle\"]\n",
    "X_train = undersampled.drop('Left Handle', axis=1)\n",
    "\n",
    "\n",
    "'''\n",
    "# Up Sample\n",
    "# concatenate our training data back together\n",
    "X_t = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "not_fraud = X_t[X_t[u\"执行反吹左侧\"]==0]\n",
    "fraud = X_t[X_t[u\"执行反吹左侧\"]==1]\n",
    "\n",
    "# upsample minority\n",
    "fraud_upsampled = resample(fraud,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(fraud)*8, # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "\n",
    "y_train = upsampled[u\"执行反吹左侧\"]\n",
    "X_train = upsampled.drop(u'执行反吹左侧', axis=1)\n",
    "'''\n",
    "\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8067920443782979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       196\n",
      "           1       0.55      0.75      0.63         8\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       204\n",
      "   macro avg       0.77      0.86      0.81       204\n",
      "weighted avg       0.97      0.97      0.97       204\n",
      "\n",
      "[[191   5]\n",
      " [  2   6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "import statistics as sta\n",
    "# Multi Voting Ensemble\n",
    "#model1 = SGDClassifier(loss='modified_huber',penalty='none', alpha=0.01)\n",
    "#model2 = DecisionTreeClassifier(max_depth=5, min_samples_split=70)\n",
    "#model3 = AdaBoostClassifier(n_estimators=100, learning_rate=1)\n",
    "#model4 = GaussianNB()\n",
    "#model5 = QuadraticDiscriminantAnalysis()\n",
    "#model6 = xgb.XGBClassifier(random_state=1,learning_rate=0.01, subsample= 0.8, \n",
    "#                  colsample_bytree= 1.0, max_depth= 3, gamma=0.5, min_child_weight= 10)\n",
    "#model7 = KNeighborsClassifier(2)\n",
    "\n",
    "model1 = SGDClassifier(loss='squared_hinge',penalty='none', alpha=0.001)\n",
    "model2 = DecisionTreeClassifier(max_depth=17, min_samples_split=10)\n",
    "model3 = AdaBoostClassifier(n_estimators=50, learning_rate=1)\n",
    "model4 = GaussianNB()\n",
    "model5 = QuadraticDiscriminantAnalysis()\n",
    "model6 = xgb.XGBClassifier(random_state=1,learning_rate=0.01, subsample= 0.6, \n",
    "                  colsample_bytree= 1.0, max_depth= 5, gamma=1, min_child_weight= 1)\n",
    "model7 = KNeighborsClassifier(2)\n",
    "\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "model4.fit(X_train,y_train)\n",
    "model5.fit(X_train,y_train)\n",
    "model6.fit(X_train,y_train)\n",
    "model7.fit(X_train,y_train)\n",
    "\n",
    "pred1 = model1.predict(X_test)\n",
    "pred2 = model2.predict(X_test)\n",
    "pred3 = model3.predict(X_test)\n",
    "pred4 = model4.predict(X_test)\n",
    "pred5 = model5.predict(X_test)\n",
    "pred6 = model6.predict(X_test)\n",
    "pred7 = model7.predict(X_test)\n",
    "\n",
    "#pred1[i], pred2[i], pred3[i], pred4[i], pred5[i], pred6[i], pred7[i]\n",
    "y_pred = np.array([])\n",
    "for i in range(0,len(X_test)):\n",
    "    y_pred = np.append(y_pred, sta.mode([pred1[i], pred2[i], pred3[i], pred4[i], pred5[i]]))\n",
    "    \n",
    "score = f1_score(y_test, y_pred, average='macro')\n",
    "print(score)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"pred\"] = y_pred\n",
    "data_test.to_csv(\"AirConditionDaily/left20190804.csv\",encoding = \"GB18030\")\n",
    "\n",
    "#pd.DataFrame(y_pred).to_csv(\"AirConditionDaily/left20190723.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "col = [\"EnvTemp\", \"Right Temp Diff\",\"RIGHT FWD DUCT\",\"RIGHT AFT DUCT\",\"RIGHT L PACK\", \"RIGHT SUPPLY DUCT\", \n",
    "       \"EnvTemp_Today-1\", \"EnvTemp_Today-2\", \"RIGHT L PACK_Today-1\", \"RIGHT L PACK_Today-2\", \"Right Temp Diff_Today-1\", \n",
    "       \"Right Temp Diff_Today-2\", \"Right Handle_Today-1\",\"Right Handle_Today-2\"]\n",
    "\n",
    "data1.dropna(inplace=True)\n",
    "data_test.fillna(0,inplace=True)\n",
    "\n",
    "X_train, y_train = data1[col], data1[\"Right Handle\"]\n",
    "X_test, y_test = data_test[col], data_test[\"Right Handle\"]\n",
    "\n",
    "\n",
    "# concatenate our training data back together\n",
    "X_t = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "not_fraud = X_t[X_t[\"Right Handle\"]==0]\n",
    "fraud = X_t[X_t[\"Right Handle\"]==1]\n",
    "\n",
    "# upsample minority\n",
    "not_fraud_undersampled = resample(not_fraud,\n",
    "                          replace=False, # sample with replacement\n",
    "                          n_samples=len(fraud)*12, # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "undersampled = pd.concat([not_fraud_undersampled, fraud])\n",
    "\n",
    "y_train = undersampled[\"Right Handle\"]\n",
    "X_train = undersampled.drop('Right Handle', axis=1)\n",
    "\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7949748743718592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       201\n",
      "           1       0.43      1.00      0.60         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       204\n",
      "   macro avg       0.71      0.99      0.79       204\n",
      "weighted avg       0.99      0.98      0.98       204\n",
      "\n",
      "[[197   4]\n",
      " [  0   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "import statistics as sta\n",
    "# Multi Voting Ensemble\n",
    "#model1 = SGDClassifier(loss='modified_huber',penalty='none', alpha=0.01)\n",
    "#model2 = DecisionTreeClassifier(max_depth=5, min_samples_split=70)\n",
    "#model3 = AdaBoostClassifier(n_estimators=100, learning_rate=1)\n",
    "#model4 = GaussianNB()\n",
    "#model5 = xgb.XGBClassifier(random_state=1,learning_rate=0.01, subsample= 0.8, \n",
    "#                  colsample_bytree= 1.0, max_depth= 3, gamma=0.5, min_child_weight= 10)\n",
    "#model6 = QuadraticDiscriminantAnalysis()\n",
    "#model7 = KNeighborsClassifier(2)\n",
    "\n",
    "\n",
    "#Right\n",
    "model1 = SGDClassifier(loss='modified_huber',penalty='none', alpha=0.0001)\n",
    "model2 = DecisionTreeClassifier(max_depth=13, min_samples_split=10)\n",
    "model3 = AdaBoostClassifier(n_estimators=50, learning_rate=1)\n",
    "model4 = GaussianNB()\n",
    "model5 = xgb.XGBClassifier(random_state=1,learning_rate=0.01, subsample= 0.6, \n",
    "                  colsample_bytree= 1.0, max_depth= 3, gamma=5, min_child_weight= 10)\n",
    "model6 = QuadraticDiscriminantAnalysis()\n",
    "model7 = KNeighborsClassifier(2)\n",
    "\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "model4.fit(X_train,y_train)\n",
    "model5.fit(X_train,y_train)\n",
    "model6.fit(X_train,y_train)\n",
    "model7.fit(X_train,y_train)\n",
    "\n",
    "pred1 = model1.predict(X_test)\n",
    "pred2 = model2.predict(X_test)\n",
    "pred3 = model3.predict(X_test)\n",
    "pred4 = model4.predict(X_test)\n",
    "pred5 = model5.predict(X_test)\n",
    "pred6 = model6.predict(X_test)\n",
    "pred7 = model7.predict(X_test)\n",
    "\n",
    "#pred1[i], pred2[i], pred3[i], pred4[i], pred5[i], pred6[i], pred7[i]\n",
    "y_pred = np.array([])\n",
    "for i in range(0,len(X_test)):\n",
    "    y_pred = np.append(y_pred, sta.mode([pred1[i], pred2[i], pred3[i], pred4[i], pred5[i]]))\n",
    "    \n",
    "score = f1_score(y_test, y_pred, average='macro')\n",
    "print(score)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"pred\"] = y_pred\n",
    "#pd.DataFrame(y_pred).to_csv(\"AirConditionDaily/right20190723.csv\")\n",
    "data_test.to_csv(\"AirConditionDaily/right20190804.csv\",encoding = \"GB18030\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
